@article{alegretThreeDimensionalConductiveScaffolds2018,
  title = {Three-{{Dimensional Conductive Scaffolds}} as {{Neural Prostheses Based}} on {{Carbon Nanotubes}} and {{Polypyrrole}}},
  author = {Alegret, Nuria and Dominguez-Alfaro, Antonio and González-Domínguez, Jose M. and Arnaiz, Blanca and Cossío, Unai and Bosi, Susanna and Vázquez, Ester and Ramos-Cabrer, Pedro and Mecerreyes, David and Prato, Maurizio},
  date = {2018-12-19},
  journaltitle = {ACS Applied Materials \& Interfaces},
  shortjournal = {ACS Appl. Mater. Interfaces},
  volume = {10},
  number = {50},
  pages = {43904--43914},
  publisher = {American Chemical Society},
  issn = {1944-8244},
  doi = {10.1021/acsami.8b16462},
  url = {https://doi.org/10.1021/acsami.8b16462},
  urldate = {2024-05-17},
  abstract = {Three-dimensional scaffolds for cellular organization need to enjoy a series of specific properties. On the one hand, the morphology, shape and porosity are critical parameters and eventually related with the mechanical properties. On the other hand, electrical conductivity is an important asset~when dealing with electroactive cells, so it is a desirable property even if the conductivity values are not particularly high. Here, we construct three-dimensional (3D) porous and conductive composites, where C8-D1A astrocytic cells were incubated to study their biocompatibility. The manufactured scaffolds are composed exclusively of carbon nanotubes (CNTs), a most promising material to interface with neuronal tissue, and polypyrrole (PPy), a conjugated polymer demonstrated to reduce gliosis, improve adaptability, and increase charge-transfer efficiency in brain-machine interfaces. We developed a new and easy strategy, based on the vapor phase polymerization (VPP) technique, where the monomer vapor is polymerized inside a sucrose sacrificial template containing CNT and an oxidizing agent. After removing the sucrose template, a 3D porous scaffold was obtained and its physical, chemical, and electrical properties were evaluated. The obtained scaffold showed very low density, high and homogeneous porosity, electrical conductivity, and Young’s Modulus similar to the in vivo tissue. Its high biocompatibility was demonstrated even after 6 days of incubation, thus paving the way for the development of new conductive 3D scaffolds potentially useful in the field of electroactive tissues.},
  file = {C:\Users\marc_\Zotero\storage\ZUKWG9JW\Alegret e.a. - 2018 - Three-Dimensional Conductive Scaffolds as Neural P.pdf}
}

@article{alfaridStructuredMethodologicalReview2022,
  title = {A {{Structured}} and {{Methodological Review}} on {{Vision-Based Hand Gesture Recognition System}}},
  author = {Al Farid, Fahmid and Hashim, Noramiza and Abdullah, Junaidi and Bhuiyan, Md Roman and Shahida Mohd Isa, Wan Noor and Uddin, Jia and Haque, Mohammad Ahsanul and Husen, Mohd Nizam},
  date = {2022-06},
  journaltitle = {Journal of Imaging},
  volume = {8},
  number = {6},
  pages = {153},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2313-433X},
  doi = {10.3390/jimaging8060153},
  url = {https://www.mdpi.com/2313-433X/8/6/153},
  urldate = {2024-05-22},
  abstract = {Researchers have recently focused their attention on vision-based hand gesture recognition. However, due to several constraints, achieving an effective vision-driven hand gesture recognition system in real time has remained a challenge. This paper aims to uncover the limitations faced in image acquisition through the use of cameras, image segmentation and tracking, feature extraction, and gesture classification stages of vision-driven hand gesture recognition in various camera orientations. This paper looked at research on vision-based hand gesture recognition systems from 2012 to 2022. Its goal is to find areas that are getting better and those that need more work. We used specific keywords to find 108 articles in well-known online databases. In this article, we put together a collection of the most notable research works related to gesture recognition. We suggest different categories for gesture recognition-related research with subcategories to create a valuable resource in this domain. We summarize and analyze the methodologies in tabular form. After comparing similar types of methodologies in the gesture recognition field, we have drawn conclusions based on our findings. Our research also looked at how well the vision-based system recognized hand gestures in terms of recognition accuracy. There is a wide variation in identification accuracy, from 68\% to 97\%, with the average being 86.6 percent. The limitations considered comprise multiple text and interpretations of gestures and complex non-rigid hand characteristics. In comparison to current research, this paper is unique in that it discusses all types of gesture recognition techniques.},
  issue = {6},
  langid = {english},
  keywords = {deep learning,feature extraction,gesture classification,gesture recognition,recognition accuracy},
  file = {C:\Users\marc_\Zotero\storage\7NJ52I3Z\Al Farid e.a. - 2022 - A Structured and Methodological Review on Vision-B.pdf}
}

@article{allenRetinalProsthesesWhere2021,
  title = {Retinal Prostheses: {{Where}} to from Here?},
  shorttitle = {Retinal Prostheses},
  author = {Allen, Penelope J.},
  date = {2021},
  journaltitle = {Clinical \& Experimental Ophthalmology},
  volume = {49},
  number = {5},
  pages = {418--429},
  issn = {1442-9071},
  doi = {10.1111/ceo.13950},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ceo.13950},
  urldate = {2024-06-03},
  abstract = {Researchers have been working towards the development of retinal prostheses, so called “bionic eyes” since the 1960s in an effort to restore functional vision to severely visually impaired patients. Groups from all around the world are involved in this research but in particular, groups from the United States, Germany, France, Japan and Australia have conducted clinical trials of these devices and three of these devices have achieved either FDA HDE (U.S. Food and Drug Administration Humanitarian Device Exception) or CE mark approval for commercial production. Despite this, all three of these devices are now not in commercial production. There are many challenges to overcome to develop devices suitable to implant in human patients and then reach commercial distribution. This is an exacting process and many hurdles need to be overcome to reach this point so that leaving the market after achieving this goal is a significant decision. Ongoing research is exploring the possibility of less complicated surgery with better visual processing algorithms to provide more useful visual information for our patients to provide a commercial alternative.},
  langid = {english},
  keywords = {research,retinal prostheses,retinitis pigmentosa},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\6M72FRJS\\Allen - 2021 - Retinal prostheses Where to from here.pdf;C\:\\Users\\marc_\\Zotero\\storage\\G8FSDVSQ\\Allen - 2021 - Retinal prostheses Where to from here.pdf;C\:\\Users\\marc_\\Zotero\\storage\\SBY9TTYD\\ceo.html}
}

@article{almuflehHighlyFlexiblePolyanilineBased2021,
  title = {Highly {{Flexible Polyaniline-Based Implantable Electrode Materials}} for {{Neural Sensing}}/{{Stimulation Applications}}},
  author = {Almufleh, Nader and Al-Othman, Amani and Alani, Zaid and Al-Sayah, Mohammad H. and Al-Nashash, Hasan},
  date = {2021-09},
  journaltitle = {Electronic Materials},
  volume = {2},
  number = {3},
  pages = {413--427},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2673-3978},
  doi = {10.3390/electronicmat2030028},
  url = {https://www.mdpi.com/2673-3978/2/3/28},
  urldate = {2024-05-17},
  abstract = {Implantable bioelectrodes have the potential to advance neural sensing and muscle stimulation, mainly in patients with peripheral nerve injuries. They function as the transducer at the interface between the damaged nerve and the muscle which is controlled by that nerve. This work reports the fabrication and characterization of novel, low-cost, flexible bioelectrodes based on polyaniline (PANI) and supported with silicone polymer. The fabricated electrodes were evaluated for their electrical and mechanical characteristics. PANI was used as the main transducer component in this fabrication. The characterization methods included electrical conductivity, capacitive behavior, long-term electrical impedance, and mechanical evaluation. The results of the fabricated PANI-silicone-based samples displayed a bulk impedance of 0.6 kΩ with an impedance of 1.6 kΩ at the frequency of 1 kHz. Furthermore, the bioelectrodes showed a charge storage capacity range from 0.0730 to 4.3124 C/cm2. The samples were stable when subjected to cyclic voltammetry tests. The bioelectrodes revealed very flexible mechanical properties as observed from the value of Young’s modulus (in the order of MPa) which was less than that of skin. Hence, the PANI-based bioelectrodes reported herein showed promising electrochemical characteristics with high flexibility.},
  issue = {3},
  langid = {english},
  keywords = {conductive polymers,electrochemical properties,flexible polyaniline,implantable electrodes,neural sensing},
  file = {C:\Users\marc_\Zotero\storage\ME4XUMKD\Almufleh e.a. - 2021 - Highly Flexible Polyaniline-Based Implantable Elec.pdf}
}

@article{aytonFirstinHumanTrialNovel2014,
  title = {First-in-{{Human Trial}} of a {{Novel Suprachoroidal Retinal Prosthesis}}},
  author = {Ayton, Lauren N. and Blamey, Peter J. and Guymer, Robyn H. and Luu, Chi D. and Nayagam, David A. X. and Sinclair, Nicholas C. and Shivdasani, Mohit N. and Yeoh, Jonathan and McCombe, Mark F. and Briggs, Robert J. and Opie, Nicholas L. and Villalobos, Joel and Dimitrov, Peter N. and Varsamidis, Mary and Petoe, Matthew A. and McCarthy, Chris D. and Walker, Janine G. and Barnes, Nick and Burkitt, Anthony N. and Williams, Chris E. and Shepherd, Robert K. and Allen, Penelope J. and Consortium, for the Bionic Vision Australia Research},
  date = {2014-12-18},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {9},
  number = {12},
  pages = {e115239},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0115239},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115239},
  urldate = {2024-05-21},
  abstract = {Retinal visual prostheses (“bionic eyes”) have the potential to restore vision to blind or profoundly vision-impaired patients. The medical bionic technology used to design, manufacture and implant such prostheses is still in its relative infancy, with various technologies and surgical approaches being evaluated. We hypothesised that a suprachoroidal implant location (between the sclera and choroid of the eye) would provide significant surgical and safety benefits for patients, allowing them to maintain preoperative residual vision as well as gaining prosthetic vision input from the device. This report details the first-in-human Phase 1 trial to investigate the use of retinal implants in the suprachoroidal space in three human subjects with end-stage retinitis pigmentosa. The success of the suprachoroidal surgical approach and its associated safety benefits, coupled with twelve-month post-operative efficacy data, holds promise for the field of vision restoration. Trial Registration Clinicaltrials.gov NCT01603576},
  langid = {english},
  keywords = {Functional electrical stimulation,Hemorrhage,Medical devices and equipment,Medical implants,Prosthetics,Retina,Surgical and invasive medical procedures,Vision},
  file = {C:\Users\marc_\Zotero\storage\AL8T7N8W\Ayton e.a. - 2014 - First-in-Human Trial of a Novel Suprachoroidal Ret.pdf}
}

@article{aytonUpdateRetinalProstheses2020,
  title = {An Update on Retinal Prostheses},
  author = {Ayton, Lauren N. and Barnes, Nick and Dagnelie, Gislin and Fujikado, Takashi and Goetz, Georges and Hornig, Ralf and Jones, Bryan W. and Muqit, Mahiul M.K. and Rathbun, Daniel L. and Stingl, Katarina and Weiland, James D. and Petoe, Matthew A.},
  date = {2020-06},
  journaltitle = {Clinical Neurophysiology},
  shortjournal = {Clinical Neurophysiology},
  volume = {131},
  number = {6},
  pages = {1383--1398},
  issn = {13882457},
  doi = {10.1016/j.clinph.2019.11.029},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1388245719313264},
  urldate = {2024-06-03},
  abstract = {Retinal prostheses are designed to restore a basic sense of sight to people with profound vision loss. They require a relatively intact posterior visual pathway (optic nerve, lateral geniculate nucleus and visual cortex). Retinal implants are options for people with severe stages of retinal degenerative disease such as retinitis pigmentosa and age-related macular degeneration.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\CY9RXVBQ\Ayton e.a. - 2020 - An update on retinal prostheses.pdf}
}

@article{bellapiantaRetinalOrganoidsRetinal2022,
  title = {Retinal {{Organoids}} and {{Retinal Prostheses}}: {{An Overview}}},
  shorttitle = {Retinal {{Organoids}} and {{Retinal Prostheses}}},
  author = {Bellapianta, Alessandro and Cetkovic, Ana and Bolz, Matthias and Salti, Ahmad},
  date = {2022-01},
  journaltitle = {International Journal of Molecular Sciences},
  volume = {23},
  number = {6},
  pages = {2922},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1422-0067},
  doi = {10.3390/ijms23062922},
  url = {https://www.mdpi.com/1422-0067/23/6/2922},
  urldate = {2024-06-03},
  abstract = {Despite the progress of modern medicine in the last decades, millions of people diagnosed with retinal dystrophies (RDs), such as retinitis pigmentosa, or age-related diseases, such as age-related macular degeneration, are suffering from severe visual impairment or even legal blindness. On the one hand, the reprogramming of somatic cells into induced pluripotent stem cells (iPSCs) and the progress of three-dimensional (3D) retinal organoids (ROs) technology provide a great opportunity to study, understand, and even treat retinal diseases. On the other hand, research advances in the field of electronic retinal prosthesis using inorganic photovoltaic polymers and the emergence of organic semiconductors represent an encouraging therapeutical strategy to restore vision to patients at the late onset of the disease. This review will provide an overview of the latest advancement in both fields. We first describe the retina and the photoreceptors, briefly mention the most used RD animal models, then focus on the latest RO differentiation protocols, carry out an overview of the current technology on inorganic and organic retinal prostheses to restore vision, and finally summarize the potential utility and applications of ROs.},
  issue = {6},
  langid = {english},
  keywords = {3D models,blindness,iPSCs,organic semiconductors,photovoltaic polymers,restore vision,retinal dystrophy,retinal organoids,retinal prosthesis},
  file = {C:\Users\marc_\Zotero\storage\EDIWNHI2\Bellapianta e.a. - 2022 - Retinal Organoids and Retinal Prostheses An Overv.pdf}
}

@article{beyelerLearningSeeAgain2017,
  title = {Learning to See Again: Biological Constraints on Cortical Plasticity and the Implications for Sight Restoration Technologies},
  shorttitle = {Learning to See Again},
  author = {Beyeler, Michael and Rokem, Ariel and Boynton, Geoffrey M. and Fine, Ione},
  date = {2017-08},
  journaltitle = {Journal of Neural Engineering},
  shortjournal = {J. Neural Eng.},
  volume = {14},
  number = {5},
  pages = {051003},
  publisher = {IOP Publishing},
  issn = {1741-2552},
  doi = {10.1088/1741-2552/aa795e},
  url = {https://dx.doi.org/10.1088/1741-2552/aa795e},
  urldate = {2024-05-31},
  abstract = {The ‘bionic eye’—so long a dream of the future—is finally becoming a reality with retinal prostheses available to patients in both the US and Europe. However, clinical experience with these implants has made it apparent that the visual information provided by these devices differs substantially from normal sight. Consequently, the ability of patients to learn to make use of this abnormal retinal input plays a critical role in whether or not some functional vision is successfully regained. The goal of the present review is to summarize the vast basic science literature on developmental and adult cortical plasticity with an emphasis on how this literature might relate to the field of prosthetic vision. We begin with describing the distortion and information loss likely to be experienced by visual prosthesis users. We then define cortical plasticity and perceptual learning, and describe what is known, and what is unknown, about visual plasticity across the hierarchy of brain regions involved in visual processing, and across different stages of life. We close by discussing what is known about brain plasticity in sight restoration patients and discuss biological mechanisms that might eventually be harnessed to improve visual learning in these patients.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\FFEI4X6A\Beyeler e.a. - 2017 - Learning to see again biological constraints on c.pdf}
}

@article{blochAdvancesRetinalProsthesis2019,
  title = {Advances in Retinal Prosthesis Systems},
  author = {Bloch, Edward and Luo, Yvonne and family=Cruz, given=Lyndon, prefix=da, useprefix=false},
  date = {2019-01-17},
  journaltitle = {Therapeutic Advances in Ophthalmology},
  publisher = {SAGE PublicationsSage UK: London, England},
  doi = {10.1177/2515841418817501},
  url = {https://journals.sagepub.com/doi/full/10.1177/2515841418817501},
  urldate = {2024-06-03},
  abstract = {Retinal prosthesis systems have undergone significant advances in the past quarter century, resulting in the development of several different novel surgical and...},
  langid = {english},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\U6JGNTTQ\\Bloch e.a. - 2019 - Advances in retinal prosthesis systems.pdf;C\:\\Users\\marc_\\Zotero\\storage\\2CHYCGWH\\2515841418817501.html}
}

@article{bourneTrendsPrevalenceBlindness2021,
  title = {Trends in Prevalence of Blindness and Distance and near Vision Impairment over 30 Years: An Analysis for the {{Global Burden}} of {{Disease Study}}},
  shorttitle = {Trends in Prevalence of Blindness and Distance and near Vision Impairment over 30 Years},
  author = {Bourne, Rupert and Steinmetz, Jaimie D. and Flaxman, Seth and Briant, Paul Svitil and Taylor, Hugh R. and Resnikoff, Serge and Casson, Robert James and Abdoli, Amir and Abu-Gharbieh, Eman and Afshin, Ashkan and Ahmadieh, Hamid and Akalu, Yonas and Alamneh, Alehegn Aderaw and Alemayehu, Wondu and Alfaar, Ahmed Samir and Alipour, Vahid and Anbesu, Etsay Woldu and Androudi, Sofia and Arabloo, Jalal and Arditi, Aries and Asaad, Malke and Bagli, Eleni and Baig, Atif Amin and Bärnighausen, Till Winfried and Parodi, Maurizio Battaglia and Bhagavathula, Akshaya Srikanth and Bhardwaj, Nikha and Bhardwaj, Pankaj and Bhattacharyya, Krittika and Bijani, Ali and Bikbov, Mukharram and Bottone, Michele and Braithwaite, Tasanee and Bron, Alain M. and Butt, Zahid A. and Cheng, Ching-Yu and Chu, Dinh-Toi and Cicinelli, Maria Vittoria and Coelho, João M. and Dagnew, Baye and Dai, Xiaochen and Dana, Reza and Dandona, Lalit and Dandona, Rakhi and Monte, Monte A. Del and Deva, Jenny P. and Diaz, Daniel and Djalalinia, Shirin and Dreer, Laura E. and Ehrlich, Joshua R. and Ellwein, Leon B. and Emamian, Mohammad Hassan and Fernandes, Arthur G. and Fischer, Florian and Friedman, David S. and Furtado, João M. and Gaidhane, Abhay Motiramji and Gaidhane, Shilpa and Gazzard, Gus and Gebremichael, Berhe and George, Ronnie and Ghashghaee, Ahmad and Golechha, Mahaveer and Hamidi, Samer and Hammond, Billy Randall and Hartnett, Mary Elizabeth R. and Hartono, Risky Kusuma and Hay, Simon I. and Heidari, Golnaz and Ho, Hung Chak and Hoang, Chi Linh and Househ, Mowafa and Ibitoye, Segun Emmanuel and Ilic, Irena M. and Ilic, Milena D. and Ingram, April D. and Irvani, Seyed Sina Naghibi and Jha, Ravi Prakash and Kahloun, Rim and Kandel, Himal and Kasa, Ayele Semachew and Kempen, John H. and Keramati, Maryam and Khairallah, Moncef and Khan, Ejaz Ahmad and Khanna, Rohit C. and Khatib, Mahalaqua Nazli and Kim, Judy E. and Kim, Yun Jin and Kisa, Sezer and Kisa, Adnan and Koyanagi, Ai and Kurmi, Om P. and Lansingh, Van Charles and Leasher, Janet L. and Leveziel, Nicolas and Limburg, Hans and Majdan, Marek and Manafi, Navid and Mansouri, Kaweh and McAlinden, Colm and Mohammadi, Seyed Farzad and Mohammadian-Hafshejani, Abdollah and Mohammadpourhodki, Reza and Mokdad, Ali H. and Moosavi, Delaram and Morse, Alan R. and Naderi, Mehdi and Naidoo, Kovin S. and Nangia, Vinay and Nguyen, Cuong Tat and Nguyen, Huong Lan Thi and Ogundimu, Kolawole and Olagunju, Andrew T. and Ostroff, Samuel M. and Panda-Jonas, Songhomitra and Pesudovs, Konrad and Peto, Tunde and Syed, Zahiruddin Quazi and Rahman, Mohammad Hifz Ur and Ramulu, Pradeep Y. and Rawaf, Salman and Rawaf, David Laith and Reinig, Nickolas and Robin, Alan L. and Rossetti, Luca and Safi, Sare and Sahebkar, Amirhossein and Samy, Abdallah M. and Saxena, Deepak and Serle, Janet B. and Shaikh, Masood Ali and Shen, Tueng T. and Shibuya, Kenji and Shin, Jae Il and Silva, Juan Carlos and Silvester, Alexander and Singh, Jasvinder A. and Singhal, Deepika and Sitorus, Rita S. and Skiadaresi, Eirini and Skirbekk, Vegard and Soheili, Amin and Sousa, Raúl A. R. C. and Spurlock, Emma Elizabeth and Stambolian, Dwight and Taddele, Biruk Wogayehu and Tadesse, Eyayou Girma and Tahhan, Nina and Tareque, Md Ismail and Topouzis, Fotis and Tran, Bach Xuan and Travillian, Ravensara S. and Tsilimbaris, Miltiadis K. and Varma, Rohit and Virgili, Gianni and Wang, Ya Xing and Wang, Ningli and West, Sheila K. and Wong, Tien Y. and Zaidi, Zoubida and Zewdie, Kaleab Alemayehu and Jonas, Jost B. and Vos, Theo},
  date = {2021-02-01},
  journaltitle = {The Lancet Global Health},
  shortjournal = {The Lancet Global Health},
  volume = {9},
  number = {2},
  eprint = {33275950},
  eprinttype = {pmid},
  pages = {e130-e143},
  publisher = {Elsevier},
  issn = {2214-109X},
  doi = {10.1016/S2214-109X(20)30425-3},
  url = {https://www.thelancet.com/journals/langlo/article/PIIS2214-109X(20)30425-3/fulltext},
  urldate = {2024-05-29},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\AQF8CS6R\Bourne e.a. - 2021 - Trends in prevalence of blindness and distance and.pdf}
}

@article{caravaca-rodriguezImplicationsNeuralPlasticity2022,
  title = {Implications of {{Neural Plasticity}} in {{Retinal Prosthesis}}},
  author = {Caravaca-Rodriguez, Daniel and Gaytan, Susana P. and Suaning, Gregg J. and Barriga-Rivera, Alejandro},
  date = {2022-10-17},
  journaltitle = {Investigative Ophthalmology \& Visual Science},
  shortjournal = {Investigative Ophthalmology \& Visual Science},
  volume = {63},
  number = {11},
  pages = {11},
  issn = {1552-5783},
  doi = {10.1167/iovs.63.11.11},
  url = {https://doi.org/10.1167/iovs.63.11.11},
  urldate = {2024-05-17},
  abstract = {Retinal degenerative diseases such as retinitis pigmentosa cause a progressive loss of photoreceptors that eventually prevents the affected person from perceiving visual sensations. The absence of a visual input produces a neural rewiring cascade that propagates along the visual system. This remodeling occurs first within the retina. Then, subsequent neuroplastic changes take place at higher visual centers in the brain, produced by either the abnormal neural encoding of the visual inputs delivered by the diseased retina or as the result of an adaptation to visual deprivation. While retinal implants can activate the surviving retinal neurons by delivering electric current, the unselective activation patterns of the different neural populations that exist in the retinal layers differ substantially from those in physiologic vision. Therefore, artificially induced neural patterns are being delivered to a brain that has already undergone important neural reconnections. Whether or not the modulation of this neural rewiring can improve the performance for retinal prostheses remains a critical question whose answer may be the enabler of improved functional artificial vision and more personalized neurorehabilitation strategies.},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\PBJPNFCS\\Caravaca-Rodriguez e.a. - 2022 - Implications of Neural Plasticity in Retinal Prost.pdf;C\:\\Users\\marc_\\Zotero\\storage\\EV8L8NK9\\article.html}
}

@article{chatterjeeBiphasicQuasistaticBrain2023,
  title = {Biphasic Quasistatic Brain Communication for Energy-Efficient Wireless Neural Implants},
  author = {Chatterjee, Baibhab and Nath, Mayukh and Kumar K, Gaurav and Xiao, Shulan and Jayant, Krishna and Sen, Shreyas},
  date = {2023-09},
  journaltitle = {Nature Electronics},
  shortjournal = {Nat Electron},
  volume = {6},
  number = {9},
  pages = {703--716},
  publisher = {Nature Publishing Group},
  issn = {2520-1131},
  doi = {10.1038/s41928-023-01000-3},
  url = {https://www.nature.com/articles/s41928-023-01000-3},
  urldate = {2024-05-17},
  abstract = {Wearable devices typically use electromagnetic fields for wireless information exchange. For implanted devices, electromagnetic signals suffer from a high amount of absorption in tissue, and alternative modes of transmission (ultrasound, optical and magneto-electric) cause large transduction losses due to energy conversion. To mitigate this challenge, we report biphasic quasistatic brain communication for wireless neural implants. The approach is based on electro-quasistatic signalling that avoids transduction losses and leads to an end-to-end channel loss of only around 60\,dB at a distance of 55\,mm. It utilizes dipole-coupling-based signal transfer through the brain tissue via differential excitation in the transmitter (implant) and differential signal pickup at the receiver (external hub). It also employs a series capacitor before the signal electrode to block d.c. current flow through the tissue and maintain ion balance. Since the electrical signal transfer through the brain is electro-quasistatic up to the several tens of megahertz, it provides a scalable (up to 10\,Mbps), low-loss and energy-efficient uplink from the implant to an external wearable. The transmit power consumption is only 0.52\,μW at 1\,Mbps (with 1\% duty cycling)—within the range of possible energy harvesting in the downlink from a wearable hub to an implant.},
  langid = {english},
  keywords = {Biomedical engineering,Electrical and electronic engineering},
  file = {C:\Users\marc_\Zotero\storage\QX525FAR\Chatterjee e.a. - 2023 - Biphasic quasistatic brain communication for energ.pdf}
}

@article{chenShapePerceptionHighchannelcount2020,
  title = {Shape Perception via a High-Channel-Count Neuroprosthesis in Monkey Visual Cortex},
  author = {Chen, Xing and Wang, Feng and Fernandez, Eduardo and Roelfsema, Pieter R.},
  date = {2020-12-04},
  journaltitle = {Science},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.abd7435},
  url = {https://www.science.org/doi/10.1126/science.abd7435},
  urldate = {2024-05-27},
  abstract = {Electrical stimulation of the visual cortex with a neuroprosthetic device allows artificial vision with shape and motion perception.},
  langid = {english},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\N9DMMR6V\\Chen e.a. - 2020 - Shape perception via a high-channel-count neuropro.pdf;C\:\\Users\\marc_\\Zotero\\storage\\M3SHNKWU\\science.html}
}

@article{choEnergyEfficientIntegratedCircuit2021,
  title = {Energy-{{Efficient Integrated Circuit Solutions Toward Miniaturized Closed-Loop Neural Interface Systems}}},
  author = {Cho, Jaeouk and Seong, Geunchang and Chang, Yonghee and Kim, Chul},
  date = {2021-05-31},
  journaltitle = {Frontiers in Neuroscience},
  shortjournal = {Front. Neurosci.},
  volume = {15},
  publisher = {Frontiers},
  issn = {1662-453X},
  doi = {10.3389/fnins.2021.667447},
  url = {https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2021.667447/full},
  urldate = {2024-05-17},
  abstract = {{$<$}p{$>$}Miniaturized implantable devices play a crucial role in neural interfaces by monitoring and modulating neural activities on the peripheral and central nervous systems. Research efforts toward a compact wireless closed-loop system stimulating the nerve automatically according to the user's condition have been maintained. These systems have several advantages over open-loop stimulation systems such as reduction in both power consumption and side effects of continuous stimulation. Furthermore, a compact and wireless device consuming low energy alleviates foreign body reactions and risk of frequent surgical operations. Unfortunately, however, the miniaturized closed-loop neural interface system induces several hardware design challenges such as neural activity recording with severe stimulation artifact, real-time stimulation artifact removal, and energy-efficient wireless power delivery. Here, we will review recent approaches toward the miniaturized closed-loop neural interface system with integrated circuit (IC) techniques.{$<$}/p{$>$}},
  langid = {english},
  keywords = {ADC-direct front-end,closed-loop system,Electroceuticals,Miniaturization,neural interface,Stimulation artifact removal,Wireless power transfer},
  file = {C:\Users\marc_\Zotero\storage\EKB5E5ZS\Cho e.a. - 2021 - Energy-Efficient Integrated Circuit Solutions Towa.pdf}
}

@article{coviAdaptiveExtremeEdge2021,
  title = {Adaptive {{Extreme Edge Computing}} for {{Wearable Devices}}},
  author = {Covi, Erika and Donati, Elisa and Liang, Xiangpeng and Kappel, David and Heidari, Hadi and Payvand, Melika and Wang, Wei},
  date = {2021-05-11},
  journaltitle = {Frontiers in Neuroscience},
  shortjournal = {Front. Neurosci.},
  volume = {15},
  publisher = {Frontiers},
  issn = {1662-453X},
  doi = {10.3389/fnins.2021.611300},
  url = {https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2021.611300/full},
  urldate = {2024-05-21},
  abstract = {{$<$}p{$>$}Wearable devices are a fast-growing technology with impact on personal healthcare for both society and economy. Due to the widespread of sensors in pervasive and distributed networks, power consumption, processing speed, and system adaptation are vital in future smart wearable devices. The visioning and forecasting of how to bring computation to the edge in smart sensors have already begun, with an aspiration to provide adaptive extreme edge computing. Here, we provide a holistic view of hardware and theoretical solutions toward smart wearable devices that can provide guidance to research in this pervasive computing era. We propose various solutions for biologically plausible models for continual learning in neuromorphic computing technologies for wearable sensors. To envision this concept, we provide a systematic outline in which prospective low power and low latency scenarios of wearable sensors in neuromorphic platforms are expected. We successively describe vital potential landscapes of neuromorphic processors exploiting complementary metal-oxide semiconductors (CMOS) and emerging memory technologies (e.g., memristive devices). Furthermore, we evaluate the requirements for edge computing within wearable devices in terms of footprint, power consumption, latency, and data size. We additionally investigate the challenges beyond neuromorphic computing hardware, algorithms and devices that could impede enhancement of adaptive edge computing in smart wearable devices.{$<$}/p{$>$}},
  langid = {english},
  keywords = {Edge computing,Learning algorithm,Memristive Devices,neuromorphic computing,Wearable Device},
  file = {C:\Users\marc_\Zotero\storage\K6KZ3S9A\Covi e.a. - 2021 - Adaptive Extreme Edge Computing for Wearable Devic.pdf}
}

@article{deruytervansteveninckEndtoendOptimizationProsthetic2022,
  title = {End-to-End Optimization of Prosthetic Vision},
  author = {family=Ruyter van Steveninck, given=Jaap, prefix=de, useprefix=true and Güçlü, Umut and family=Wezel, given=Richard, prefix=van, useprefix=true and family=Gerven, given=Marcel, prefix=van, useprefix=true},
  date = {2022-02-28},
  journaltitle = {Journal of Vision},
  shortjournal = {Journal of Vision},
  volume = {22},
  number = {2},
  pages = {20},
  issn = {1534-7362},
  doi = {10.1167/jov.22.2.20},
  url = {https://doi.org/10.1167/jov.22.2.20},
  urldate = {2024-05-10},
  abstract = {Neural prosthetics may provide a promising solution to restore visual perception in some forms of blindness. The restored prosthetic percept is rudimentary compared to normal vision and can be optimized with a variety of image preprocessing techniques to maximize relevant information transfer. Extracting the most useful features from a visual scene is a nontrivial task and optimal preprocessing choices strongly depend on the context. Despite rapid advancements in deep learning, research currently faces a difficult challenge in finding a general and automated preprocessing strategy that can be tailored to specific tasks or user requirements. In this paper, we present a novel deep learning approach that explicitly addresses this issue by optimizing the entire process of phosphene generation in an end-to-end fashion. The proposed model is based on a deep auto-encoder architecture and includes a highly adjustable simulation module of prosthetic vision. In computational validation experiments, we show that such an approach is able to automatically find a task-specific stimulation protocol. The results of these proof-of-principle experiments illustrate the potential of end-to-end optimization for prosthetic vision. The presented approach is highly modular and our approach could be extended to automated dynamic optimization of prosthetic vision for everyday tasks, given any specific constraints, accommodating individual requirements of the end-user.},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\D2H6LCK2\\de Ruyter van Steveninck e.a. - 2022 - End-to-end optimization of prosthetic vision.pdf;C\:\\Users\\marc_\\Zotero\\storage\\859NWS4K\\article.html}
}

@article{deruytervansteveninckRealworldIndoorMobility2022,
  title = {Real-World Indoor Mobility with Simulated Prosthetic Vision: {{The}} Benefits and Feasibility of Contour-Based Scene Simplification at Different Phosphene Resolutions},
  shorttitle = {Real-World Indoor Mobility with Simulated Prosthetic Vision},
  author = {family=Ruyter van Steveninck, given=Jaap, prefix=de, useprefix=true and family=Gestel, given=Tom, prefix=van, useprefix=true and Koenders, Paula and family=Ham, given=Guus, prefix=van der, useprefix=true and Vereecken, Floris and Güçlü, Umut and family=Gerven, given=Marcel, prefix=van, useprefix=true and Güçlütürk, Yağmur and family=Wezel, given=Richard, prefix=van, useprefix=true},
  date = {2022-02-01},
  journaltitle = {Journal of Vision},
  shortjournal = {Journal of Vision},
  volume = {22},
  number = {2},
  pages = {1},
  issn = {1534-7362},
  doi = {10.1167/jov.22.2.1},
  url = {https://doi.org/10.1167/jov.22.2.1},
  urldate = {2024-05-11},
  abstract = {Neuroprosthetic implants are a promising technology for restoring some form of vision in people with visual impairments via electrical neurostimulation in the visual pathway. Although an artificially generated prosthetic percept is relatively limited compared with normal vision, it may provide some elementary perception of the surroundings, re-enabling daily living functionality. For mobility in particular, various studies have investigated the benefits of visual neuroprosthetics in a simulated prosthetic vision paradigm with varying outcomes. The previous literature suggests that scene simplification via image processing, and particularly contour extraction, may potentially improve the mobility performance in a virtual environment. In the current simulation study with sighted participants, we explore both the theoretically attainable benefits of strict scene simplification in an indoor environment by controlling the environmental complexity, as well as the practically achieved improvement with a deep learning-based surface boundary detection implementation compared with traditional edge detection. A simulated electrode resolution of 26 × 26 was found to provide sufficient information for mobility in a simple environment. Our results suggest that, for a lower number of implanted electrodes, the removal of background textures and within-surface gradients may be beneficial in theory. However, the deep learning-based implementation for surface boundary detection did not improve mobility performance in the current study. Furthermore, our findings indicate that, for a greater number of electrodes, the removal of within-surface gradients and background textures may deteriorate, rather than improve, mobility. Therefore, finding a balanced amount of scene simplification requires a careful tradeoff between informativity and interpretability that may depend on the number of implanted electrodes.},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\FZYDCCTU\\de Ruyter van Steveninck e.a. - 2022 - Real-world indoor mobility with simulated prosthet.pdf;C\:\\Users\\marc_\\Zotero\\storage\\J7IKJKKU\\article.html}
}

@article{dobellePhosphenesProducedElectrical1974,
  title = {Phosphenes Produced by Electrical Stimulation of Human Occipital Cortex, and Their Application to the Development of a Prosthesis for the Blind},
  author = {Dobelle, W. H. and Mladejovsky, M. G.},
  date = {1974},
  journaltitle = {The Journal of Physiology},
  volume = {243},
  number = {2},
  pages = {553--576},
  issn = {1469-7793},
  doi = {10.1113/jphysiol.1974.sp010766},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1974.sp010766},
  urldate = {2024-05-21},
  abstract = {1. To explore the feasibility of a visual prosthesis for the blind, human visual cortex has been stimulated during a series of surgical procedures on conscious volunteers undergoing other occipital lobe surgery. 2. Area no. 17 seems the most effective locus for such stimulation, at least in sighted or recently hemianopic patients. 3. Changes in electrode size and configuration, or in stimulus parameters, have little effect on subjective sensation. 4. Thresholds do vary depending on parameters, but not electrode size, and these effects have been studied. 5. Painful effects are associated with stimulation of the dura, but not of the calcarine artery and associated vessels. 6. Stimulation of a single electrode usually produces one phosphene, whose size ranges from tiny punctate sensations like ‘a star in the sky’ up to a large coin at arm's length. Very large elongated phosphenes, like those seen by Brindley's second patient, have not been reported despite the number of patients, electrodes, and combinations of stimulus parameters tested. These large phosphenes may be an effect of prolonged blindness. 7. Stimulation substantially above threshold may produce a second conjugate phosphene, inverted about the horizontal meridian. 8. Stimulation of a single electrode may also produce multiple phosphenes with no differential threshold. 9. Chromatic effects and/or phosphene flicker may, or may not occur. This can vary from point to point on the same patient. 10. Phosphenes fade after 10–15 sec of continuous stimulation. 11. All phosphenes move proportionately with voluntary eye movements, within the accuracy of our mapping techniques. 12. Brightness modulation can easily be achieved by changing pulse amplitude. 13. The position of phosphenes in the visual field corresponds only roughly with expectations based on classical maps showing the projection of the visual field onto the cortex. 14. Patients can usually discriminate phosphenes produced by 1 mm2 electrodes on 3 mm centres, although this seems to be close to the limit of resolution. 15. Patterns of up to four phosphenes produced by four electrodes have been recognized. However, a variety of complex interactions have been reported. 16. Multiple phosphenes are co-planar, although patients are unable to estimate their distance. 17. Phosphenes appear immediately when stimulation is begun, and disappear immediately upon cessation of stimulation. 18. Future work must concentrate on blind volunteers to explore possible differences in subjective sensation produced after prolonged blindness, and to explore more complex pattern presentation which requires substantial periods of time with any given patient.},
  langid = {english},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\FTPX5BZN\\Dobelle en Mladejovsky - 1974 - Phosphenes produced by electrical stimulation of h.pdf;C\:\\Users\\marc_\\Zotero\\storage\\KXR6HUAH\\Dobelle en Mladejovsky - 1974 - Phosphenes produced by electrical stimulation of h.pdf;C\:\\Users\\marc_\\Zotero\\storage\\9WKXUCLB\\jphysiol.1974.html}
}

@article{elnabawyPVGANGenerativeAdversarial2022,
  title = {{{PVGAN}}: A Generative Adversarial Network for Object Simplification in Prosthetic Vision},
  shorttitle = {{{PVGAN}}},
  author = {Elnabawy, Reham H. and Abdennadher, Slim and Hellwich, Olaf and Eldawlatly, Seif},
  date = {2022-09},
  journaltitle = {Journal of Neural Engineering},
  shortjournal = {J. Neural Eng.},
  volume = {19},
  number = {5},
  pages = {056007},
  publisher = {IOP Publishing},
  issn = {1741-2552},
  doi = {10.1088/1741-2552/ac8acf},
  url = {https://dx.doi.org/10.1088/1741-2552/ac8acf},
  urldate = {2024-05-22},
  abstract = {Objective. By means of electrical stimulation of the visual system, visual prostheses provide promising solution for blind patients through partial restoration of their vision. Despite the great success achieved so far in this field, the limited resolution of the perceived vision using these devices hinders the ability of visual prostheses users to correctly recognize viewed objects. Accordingly, we propose a deep learning approach based on generative adversarial networks (GANs), termed prosthetic vision GAN (PVGAN), to enhance object recognition for the implanted patients by representing objects in the field of view based on a corresponding simplified clip art version. Approach. To assess the performance, an axon map model was used to simulate prosthetic vision in experiments involving normally-sighted participants. In these experiments, four types of image representation were examined. The first and second types comprised presenting phosphene simulation of real images containing the actual high-resolution object, and presenting phosphene simulation of the real image followed by the clip art image, respectively. The other two types were utilized to evaluate the performance in the case of electrode dropout, where the third type comprised presenting phosphene simulation of only clip art images without electrode dropout, while the fourth type involved clip art images with electrode dropout. Main results. The performance was measured through three evaluation metrics which are the accuracy of the participants in recognizing the objects, the time taken by the participants to correctly recognize the object, and the confidence level of the participants in the recognition process. Results demonstrate that representing the objects using clip art images generated by the PVGAN model results in a significant enhancement in the speed and confidence of the subjects in recognizing the objects. Significance. These results demonstrate the utility of using GANs in enhancing the quality of images perceived using prosthetic vision.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\RV2QFECC\Elnabawy e.a. - 2022 - PVGAN a generative adversarial network for object.pdf}
}

@article{fahimiGenerativeAdversarialNetworksBased2021,
  title = {Generative {{Adversarial Networks-Based Data Augmentation}} for {{Brain}}–{{Computer Interface}}},
  author = {Fahimi, Fatemeh and Dosen, Strahinja and Ang, Kai Keng and Mrachacz-Kersting, Natalie and Guan, Cuntai},
  date = {2021-09},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  shortjournal = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {32},
  number = {9},
  pages = {4039--4051},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2020.3016666},
  url = {https://ieeexplore.ieee.org/document/9177281/},
  urldate = {2024-05-22},
  abstract = {The performance of a classifier in a brain–computer interface (BCI) system is highly dependent on the quality and quantity of training data. Typically, the training data are collected in a laboratory where the users perform tasks in a controlled environment. However, users’ attention may be diverted in reallife BCI applications and this may decrease the performance of the classifier. To improve the robustness of the classifier, additional data can be acquired in such conditions, but it is not practical to record electroencephalogram (EEG) data over several long calibration sessions. A potentially time- and cost-efficient solution is artificial data generation. Hence, in this study, we proposed a framework based on the deep convolutional generative adversarial networks (DCGANs) for generating artificial EEG to augment the training set in order to improve the performance of a BCI classifier. To make a comparative investigation, we designed a motor task experiment with diverted and focused attention conditions. We used an end-to-end deep convolutional neural network for classification between movement intention and rest using the data from 14 subjects. The results from the leaveone subject-out (LOO) classification yielded baseline accuracies of 73.04\% for diverted attention and 80.09\% for focused attention without data augmentation. Using the proposed DCGANs-based framework for augmentation, the results yielded a significant improvement of 7.32\% for diverted attention ( p {$<$} 0.01) and 5.45\% for focused attention ( p {$<$} 0.01). In addition, we implemented the method on the data set IVa from BCI competition III to distinguish different motor imagery tasks. The proposed method increased the accuracy by 3.57\% ( p {$<$} 0.02). This study shows that using GANs for EEG augmentation can significantly improve BCI performance, especially in real-life applications, whereby users’ attention may be diverted.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\9IQ2RYNI\Fahimi e.a. - 2021 - Generative Adversarial Networks-Based Data Augment.pdf}
}

@article{farnumNewVisionVisual2020,
  title = {New {{Vision}} for {{Visual Prostheses}}},
  author = {Farnum, Alexander and Pelled, Galit},
  date = {2020-02-18},
  journaltitle = {Frontiers in Neuroscience},
  shortjournal = {Front. Neurosci.},
  volume = {14},
  publisher = {Frontiers},
  issn = {1662-453X},
  doi = {10.3389/fnins.2020.00036},
  url = {https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2020.00036/full},
  urldate = {2024-05-14},
  abstract = {{$<$}p{$>$}Developments of new strategies to restore vision and improving on current strategies by harnessing new advancements in material and electrical sciences, and biological and genetic-based technologies are of upmost health priorities around the world. Federal and private entities are spending billions of dollars on visual prosthetics technologies. This review describes the most current and state-of-the-art bioengineering technologies to restore vision. This includes a thorough description of traditional electrode-based visual prosthetics that have improved substantially since early prototypes. Recent advances in molecular and synthetic biology have transformed vision-assisted technologies; For example, optogenetic technologies that introduce light-responsive proteins offer excellent resolution but cortical applications are restricted by fiber implantation and tissue damage. Other stimulation modalities, such as magnetic fields, have been explored to achieve non-invasive neuromodulation. Miniature magnetic coils are currently being developed to activate select groups of neurons. Magnetically-responsive nanoparticles or exogenous proteins can significantly enhance the coupling between external electromagnetic devices and any neurons affiliated with these modifications. The need to minimize cytotoxic effects for nanoparticle-based therapies will likely restrict the number of usable materials. Nevertheless, advances in identifying and utilizing proteins that respond to magnetic fields may lead to non-invasive, cell-specific stimulation and may overcome many of the limitations that currently exist with other methods. Finally, sensory substitution systems also serve as viable visual prostheses by converting visual input to auditory and somatosensory stimuli. This review also discusses major challenges in the field and offers bioengineering strategies to overcome those.{$<$}/p{$>$}},
  langid = {english},
  keywords = {bioengeneering,Cortical implant,magnetic stimulation,Neuromodulation,Vision,visual prostheses},
  file = {C:\Users\marc_\Zotero\storage\Z45KV58R\Farnum en Pelled - 2020 - New Vision for Visual Prostheses.pdf}
}

@article{fauvelHumanintheloopOptimizationVisual2022,
  title = {Human-in-the-Loop Optimization of Visual Prosthetic Stimulation},
  author = {Fauvel, Tristan and Chalk, Matthew},
  date = {2022-06},
  journaltitle = {Journal of Neural Engineering},
  shortjournal = {J. Neural Eng.},
  volume = {19},
  number = {3},
  pages = {036038},
  publisher = {IOP Publishing},
  issn = {1741-2552},
  doi = {10.1088/1741-2552/ac7615},
  url = {https://dx.doi.org/10.1088/1741-2552/ac7615},
  urldate = {2024-05-22},
  abstract = {Objective. Retinal prostheses are a promising strategy to restore sight to patients with retinal degenerative diseases. These devices compensate for the loss of photoreceptors by electrically stimulating neurons in the retina. Currently, the visual function that can be recovered with such devices is very limited. This is due, in part, to current spread, unintended axonal activation, and the limited resolution of existing devices. Here we show, using a recent model of prosthetic vision, that optimizing how visual stimuli are encoded by the device can help overcome some of these limitations, leading to dramatic improvements in visual perception. Approach. We propose a strategy to do this in practice, using patients’ feedback in a visual task. The main challenge of our approach comes from the fact that, typically, one only has access to a limited number of noisy responses from patients. We propose two ways to deal with this: first, we use a model of prosthetic vision to constrain and simplify the optimization. We show that, if one knew the parameters of this model for a given patient, it would be possible to greatly improve their perceptual performance. Second we propose a preferential Bayesian optimization to efficiently learn these model parameters for each patient, using minimal trials. Main results. To test our approach, we presented healthy subjects with visual stimuli generated by a recent model of prosthetic vision, to replicate the perceptual experience of patients fitted with an implant. Our optimization procedure led to significant and robust improvements in perceived image quality, that transferred to increased performance in other tasks. Significance. Importantly, our strategy is agnostic to the type of prosthesis and thus could readily be implemented in existing implants.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\BX5ZSGG5\Fauvel en Chalk - 2022 - Human-in-the-loop optimization of visual prostheti.pdf}
}

@article{fengDesignOnlineBrainComputer2020,
  title = {Design of an {{Online Brain-Computer Interface System Based}} on {{Field Programmable Gate Array}}},
  author = {Feng, Zhengquan and Zeng, Lin and Wu, Haijing and Tian, Fengchun and He, Qinghua},
  date = {2020-10-01},
  journaltitle = {Journal of Physics: Conference Series},
  shortjournal = {J. Phys.: Conf. Ser.},
  volume = {1624},
  number = {4},
  pages = {042061},
  issn = {1742-6588, 1742-6596},
  doi = {10.1088/1742-6596/1624/4/042061},
  url = {https://iopscience.iop.org/article/10.1088/1742-6596/1624/4/042061},
  urldate = {2024-05-22},
  abstract = {In the article, an online brain-computer interface (BCI) demo system based on Field Programmable Gate Array (FPGA) was designed. A colour visual stimulator based on a Video Graphics Array (VGA) monitor controlled by FPGA is designed to produce transient visual stimulations. An electroencephalography (EEG) acquisition module including active electrodes and driven-right-leg circuit is used to acquire the visual evoked potential (VEP) signal; Finite impulse response (FIR) filtering combined with an averaging method allows for extraction of the weak VEP signals. The template matching method is used in target identification. The FPGA is successfully used in the BCI system to complete multiple tasks such as the VGA controller, analog to digital (AD) converter controller, VEP signal processor and electronic device controller. Experiments show that the subjects’ transient VEP can successfully activate the electronic devices by the online BCI system which has relatively high identification accuracy. All these results show that the real time BCI demo system based on FPGA is feasible and effective.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\DVXIP6GG\Feng e.a. - 2020 - Design of an Online Brain-Computer Interface Syste.pdf}
}

@article{fernandezVisualPerceptsEvoked2021,
  title = {Visual Percepts Evoked with an Intracortical 96-Channel Microelectrode Array Inserted in Human Occipital Cortex},
  author = {Fernández, Eduardo and Alfaro, Arantxa and Soto-Sánchez, Cristina and Gonzalez-Lopez, Pablo and Lozano, Antonio M. and Peña, Sebastian and Grima, Maria Dolores and Rodil, Alfonso and Gómez, Bernardeta and Chen, Xing and Roelfsema, Pieter R. and Rolston, John D. and Davis, Tyler S. and Normann, Richard A.},
  date = {2021-12-01},
  journaltitle = {The Journal of Clinical Investigation},
  shortjournal = {J Clin Invest},
  volume = {131},
  number = {23},
  eprint = {0},
  eprinttype = {pmid},
  publisher = {American Society for Clinical Investigation},
  issn = {0021-9738},
  doi = {10.1172/JCI151331},
  url = {https://www.jci.org/articles/view/151331},
  urldate = {2024-05-17},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\KV33FKPT\Fernández e.a. - 2021 - Visual percepts evoked with an intracortical 96-ch.pdf}
}

@article{fylstraHumanprosthesisCooperationCombining2022,
  title = {Human-Prosthesis Cooperation: Combining Adaptive Prosthesis Control with Visual Feedback Guided Gait},
  shorttitle = {Human-Prosthesis Cooperation},
  author = {Fylstra, Bretta L. and Lee, I-Chieh and Li, Minhan and Lewek, Michael D. and Huang, He},
  date = {2022-12-14},
  journaltitle = {Journal of NeuroEngineering and Rehabilitation},
  shortjournal = {J NeuroEngineering Rehabil},
  volume = {19},
  number = {1},
  pages = {140},
  issn = {1743-0003},
  doi = {10.1186/s12984-022-01118-z},
  url = {https://doi.org/10.1186/s12984-022-01118-z},
  urldate = {2024-05-22},
  abstract = {Personalizing prosthesis control is often structured as human-in-the-loop optimization. However, gait performance is influenced by both human control and intelligent prosthesis control. Hence, we need to consider both human and prosthesis control, and their cooperation, to achieve desired gait patterns. In this study, we developed a novel paradigm that engages human gait control via user-fed visual feedback (FB) of stance time to cooperate with automatic prosthesis control tuning. Three initial questions were studied: (1) does user control of gait timing (via visual FB) help the prosthesis tuning algorithm to converge faster? (2) in turn, does the prosthesis control influence the user’s ability to reach and maintain the target stance time defined by the feedback? and (3) does the prosthesis control parameters tuned with extended stance time on prosthesis side allow the user to maintain this potentially beneficial behavior even after feedback is removed (short- and long-term retention)?},
  langid = {english},
  keywords = {Gait,Human-in-the-loop optimization,Powered prosthesis tuning,Transfemoral amputee,Visual feedback},
  file = {C:\Users\marc_\Zotero\storage\CL6R3P7W\Fylstra e.a. - 2022 - Human-prosthesis cooperation combining adaptive p.pdf}
}

@article{gallettiCorticalConnectionsArea2001,
  title = {The Cortical Connections of Area {{V6}}: An Occipito-Parietal Network Processing Visual Information},
  shorttitle = {The Cortical Connections of Area {{V6}}},
  author = {Galletti, Claudio and Gamberini, Michela and Kutz, Dieter F. and Fattori, Patrizia and Luppino, Giuseppe and Matelli, Massimo},
  date = {2001},
  journaltitle = {European Journal of Neuroscience},
  volume = {13},
  number = {8},
  pages = {1572--1588},
  issn = {1460-9568},
  doi = {10.1046/j.0953-816x.2001.01538.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1046/j.0953-816x.2001.01538.x},
  urldate = {2024-05-17},
  abstract = {The aim of this work was to study the cortical connections of area V6 by injecting neuronal tracers into different retinotopic representations of this area. To this purpose, we first functionally recognized V6 by recording from neurons of the parieto-occipital cortex in awake macaque monkeys. Penetrations with recording syringes were performed in the behaving animals in order to inject tracers exactly at the recording sites. The tracers were injected into the central or peripheral field representation of V6 in different hemispheres. Irrespective of whether injections were made in the centre or periphery, area V6 showed reciprocal connections with areas V1, V2, V3, V3A, V4T, the middle temporal area /V5 (MT/V5), the medial superior temporal area (MST), the medial intraparietal area (MIP), the ventral intraparietal area (VIP), the ventral part of the lateral intraparietal area and the ventral part of area V6A (V6AV). No labelled cells or terminals were found in the inferior temporal, mesial and frontal cortices. The connections of V6 with V1, and with all the retinotopically organized prestriate areas, were organized retinotopically. The connection of V6 with MIP suggests a visuotopic organization for this latter. Labelling in V6A and VIP after either central or peripheral V6 injections was very similar in location and extent, as expected on the basis of the nonretinotopic organization of these areas. We suggest that V6 plays a pivotal role in the dorsal visual stream, by distributing the visual information coming from the occipital lobe to the sensorimotor areas of the parietal cortex. Given the functional characteristics of the cells of this network, we suggest that it could perform the fast form and motion analyses needed for the visual guiding of arm movements as well as their coordination with the eyes and the head.},
  langid = {english},
  keywords = {awake macaque monkey,dorsal visual stream,extrastriate visual cortex,visual topography,visuomotor integration},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\78N6WD9D\\Galletti e.a. - 2001 - The cortical connections of area V6 an occipito-p.pdf;C\:\\Users\\marc_\\Zotero\\storage\\3IFGW75J\\j.0953-816x.2001.01538.html}
}

@article{goodfellowGenerativeAdversarialNetworks2020,
  title = {Generative Adversarial Networks},
  author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  date = {2020-10-22},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {63},
  number = {11},
  pages = {139--144},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3422622},
  url = {https://dl.acm.org/doi/10.1145/3422622},
  urldate = {2024-05-22},
  abstract = {Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but GANs are among the most successful generative models (especially in terms of their ability to generate realistic highresolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\NTQQIB85\Goodfellow e.a. - 2020 - Generative adversarial networks.pdf}
}

@article{goOrganicNeuroelectronicsNeural2022,
  title = {Organic {{Neuroelectronics}}: {{From Neural Interfaces}} to {{Neuroprosthetics}}},
  shorttitle = {Organic {{Neuroelectronics}}},
  author = {Go, Gyeong-Tak and Lee, Yeongjun and Seo, Dae-Gyo and Lee, Tae-Woo},
  date = {2022},
  journaltitle = {Advanced Materials},
  volume = {34},
  number = {45},
  pages = {2201864},
  issn = {1521-4095},
  doi = {10.1002/adma.202201864},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/adma.202201864},
  urldate = {2024-05-13},
  abstract = {Requirements and recent advances in research on organic neuroelectronics are outlined herein. Neuroelectronics such as neural interfaces and neuroprosthetics provide a promising approach to diagnose and treat neurological diseases. However, the current neural interfaces are rigid and not biocompatible, so they induce an immune response and deterioration of neural signal transmission. Organic materials are promising candidates for neural interfaces, due to their mechanical softness, excellent electrochemical properties, and biocompatibility. Also, organic nervetronics, which mimics functional properties of the biological nerve system, is being developed to overcome the limitations of the complex and energy-consuming conventional neuroprosthetics that limit long-term implantation and daily-life usage. Examples of organic materials for neural interfaces and neural signal recordings are reviewed, recent advances of organic nervetronics that use organic artificial synapses are highlighted, and then further requirements for neuroprosthetics are discussed. Finally, the future challenges that must be overcome to achieve ideal organic neuroelectronics for next-generation neuroprosthetics are discussed.},
  langid = {english},
  keywords = {artificial nerves,artificial neurons,artificial synapses,bioelectronics,nervetronics,neuromorphic electronics},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\R9EQPIDV\\Go e.a. - 2022 - Organic Neuroelectronics From Neural Interfaces t.pdf;C\:\\Users\\marc_\\Zotero\\storage\\KRGJIAV4\\adma.html}
}

@article{graniPersonalizedClosedloopStimulation2022,
  title = {Toward a Personalized Closed-Loop Stimulation of the Visual Cortex: {{Advances}} and Challenges},
  shorttitle = {Toward a Personalized Closed-Loop Stimulation of the Visual Cortex},
  author = {Grani, Fabrizio and Soto-Sánchez, Cristina and Fimia, Antonio and Fernández, Eduardo},
  date = {2022-12-13},
  journaltitle = {Frontiers in Cellular Neuroscience},
  shortjournal = {Front. Cell. Neurosci.},
  volume = {16},
  publisher = {Frontiers},
  issn = {1662-5102},
  doi = {10.3389/fncel.2022.1034270},
  url = {https://www.frontiersin.org/articles/10.3389/fncel.2022.1034270},
  urldate = {2024-05-14},
  abstract = {Current cortical visual prosthesis approaches are primarily unidirectional and do not consider the feed-back circuits that exist in just about every part of the nervous system. Herein, we provide a brief overview of some recent developments for better controlling brain stimulation and present preliminary human data indicating that closed-loop strategies could considerably enhance the effectiveness, safety, and long-term stability of visual cortex stimulation. We propose that the development of improved closed-loop strategies may help to enhance our capacity to communicate with the brain.},
  langid = {english},
  keywords = {Brain Stimulation,closed-loop stimulation,Local Field Potentials,Neural Interfaces,visual prostheses},
  file = {C:\Users\marc_\Zotero\storage\68PXNWAC\Grani e.a. - 2022 - Toward a personalized closed-loop stimulation of t.pdf}
}

@online{granleyAdaptingBrainLikeNeural2022,
  title = {Adapting {{Brain-Like Neural Networks}} for {{Modeling Cortical Visual Prostheses}}},
  author = {Granley, Jacob and Riedel, Alexander and Beyeler, Michael},
  date = {2022-09-27},
  eprint = {2209.13561},
  eprinttype = {arxiv},
  eprintclass = {cs, q-bio},
  url = {http://arxiv.org/abs/2209.13561},
  urldate = {2024-05-22},
  abstract = {Cortical prostheses are devices implanted in the visual cortex that attempt to restore lost vision by electrically stimulating neurons. Currently, the vision provided by these devices is limited, and accurately predicting the visual percepts resulting from stimulation is an open challenge. We propose to address this challenge by utilizing ‘brain-like’ convolutional neural networks (CNNs), which have emerged as promising models of the visual system. To investigate the feasibility of adapting brain-like CNNs for modeling visual prostheses, we developed a proof-of-concept model to predict the perceptions resulting from electrical stimulation. We show that a neurologically-inspired decoding of CNN activations produces qualitatively accurate phosphenes, comparable to phosphenes reported by real patients. Overall, this is an essential first step towards building brain-like models of electrical stimulation, which may not just improve the quality of vision provided by cortical prostheses but could also further our understanding of the neural code of vision.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  file = {C:\Users\marc_\Zotero\storage\I3UX74V9\Granley e.a. - 2022 - Adapting Brain-Like Neural Networks for Modeling C.pdf}
}

@article{guoImplantableLiquidMetalbased2017,
  title = {Implantable Liquid Metal-Based Flexible Neural Microelectrode Array and Its Application in Recovering Animal Locomotion Functions},
  author = {Guo, Rui and Liu, Jing},
  date = {2017-09},
  journaltitle = {Journal of Micromechanics and Microengineering},
  shortjournal = {J. Micromech. Microeng.},
  volume = {27},
  number = {10},
  pages = {104002},
  publisher = {IOP Publishing},
  issn = {0960-1317},
  doi = {10.1088/1361-6439/aa891c},
  url = {https://dx.doi.org/10.1088/1361-6439/aa891c},
  urldate = {2024-05-17},
  abstract = {With significant advantages in rapidly restoring the nerve function, electrical stimulation of nervous tissue is a crucial treatment of peripheral nerve injuries leading to common movement disorder. However, the currently available stimulating electrodes generally based on rigid conductive materials would cause a potential mechanical mismatch with soft neural tissues which thus reduces long-term effects of electrical stimulation. Here, we proposed and fabricated a flexible neural microelectrode array system based on the liquid metal GaIn alloy (75.5\% Ga and 24.5\% In by weight) and via printing approach. Such an alloy with a unique low melting point (10.35 °C) owns excellent electrical conductivity and high compliance, which are beneficial to serve as implantable flexible neural electrodes. The flexible neural microelectrode array embeds four liquid metal electrodes and stretchable interconnects in a PDMS membrane (500 µm in thickness) that possess a lower elastic modulus (1.055 MPa), which is similar to neural tissues with elastic moduli in the 0.1–1.5 MPa range. The electrical experiments indicate that the liquid metal interconnects could sustain over 7000 mechanical stretch cycles with resistance approximately staying at 4 Ω. Over the conceptual experiments on animal sciatic nerve electrical stimulation, the dead bullfrog implanted with flexible neural microelectrode array could even rhythmically contract and move its lower limbs under the electrical stimulations from the implant. This demonstrates a highly efficient way for quickly recovering biological nerve functions. Further, the good biocompatibility of the liquid metal material was justified via a series of biological experiments. This liquid metal modality for neural stimulation is expected to play important roles as biologic electrodes to overcome the fundamental mismatch in mechanics between biological tissues and electronic devices in the coming time.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\IDD9AI4S\Guo en Liu - 2017 - Implantable liquid metal-based flexible neural mic.pdf}
}

@article{huangEnhancingImageResolution2023,
  title = {Enhancing Image Resolution of Confocal Fluorescence Microscopy with Deep Learning},
  author = {Huang, Boyi and Li, Jia and Yao, Bowen and Yang, Zhigang and Lam, Edmund Y. and Zhang, Jia and Yan, Wei and Qu, Junle},
  date = {2023-01-05},
  journaltitle = {PhotoniX},
  shortjournal = {PhotoniX},
  volume = {4},
  number = {1},
  pages = {2},
  issn = {2662-1991},
  doi = {10.1186/s43074-022-00077-x},
  url = {https://doi.org/10.1186/s43074-022-00077-x},
  urldate = {2024-05-17},
  abstract = {Super-resolution optical imaging is crucial to the study of cellular processes. Current super-resolution fluorescence microscopy is restricted by the need of special fluorophores or sophisticated optical systems, or long acquisition and computational times. In this work, we present a deep-learning-based super-resolution technique of confocal microscopy. We devise a two-channel attention network (TCAN), which takes advantage of both spatial representations and frequency contents to learn a more precise mapping from low-resolution images to high-resolution ones. This scheme is robust against changes in the pixel size and the imaging setup, enabling the optimal model to generalize to different fluorescence microscopy modalities unseen in the training set. Our algorithm is validated on diverse biological structures and dual-color confocal images of actin-microtubules, improving the resolution from \textasciitilde\,230\,nm to \textasciitilde\,110\,nm. Last but not least, we demonstrate live-cell super-resolution imaging by revealing the detailed structures and dynamic instability of microtubules.},
  langid = {english},
  keywords = {Deep learning,Generative adversarial network,Image resolution enhancement,Super-resolution fluorescence microscopy},
  file = {C:\Users\marc_\Zotero\storage\GVJRF5C9\Huang e.a. - 2023 - Enhancing image resolution of confocal fluorescenc.pdf}
}

@article{janssenBeneficialEffectsConventional2020,
  title = {The {{Beneficial Effects}} of {{Conventional Visual Cues Are Retained When Augmented Reality Glasses Are Worn}}},
  author = {Janssen, Sabine and family=Ruyter van Steveninck, given=Jaap, prefix=de, useprefix=true and Salim, Hizirwan S. and Bloem, Bastiaan R. and Heida, Tjitske and family=Wezel, given=Richard J. A., prefix=van, useprefix=true},
  date = {2020-04-07},
  journaltitle = {Parkinson’s Disease},
  volume = {2020},
  pages = {e4104712},
  publisher = {Hindawi},
  issn = {2090-8083},
  doi = {10.1155/2020/4104712},
  url = {https://www.hindawi.com/journals/pd/2020/4104712/},
  urldate = {2024-05-10},
  abstract = {Wearing smart glasses may be distracting and thus annihilate the beneficial effects of cues on freezing of gait in Parkinson’s disease. Furthermore, augmented reality cues might be effective in reducing FOG specifically in cueing-responsive patients. We present a single-patient study in which a patient with Parkinson’s disease traversed a doorway under different cueing conditions. Wearing augmented reality (AR) glasses did not deteriorate FOG nor affect the beneficial effects of cues. The AR visual cues did not improve FOG. This single-patient study implies that the current design of AR glasses does not stand in the way of the development of augmented reality visual cues. However, the effectivity of augmented reality visual cues remains to be proven.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\NW5ICCFA\Janssen e.a. - 2020 - The Beneficial Effects of Conventional Visual Cues.pdf}
}

@article{kangNIRIISemiconductingPolymers2023,
  title = {{{NIR-II}} Semiconducting Polymers for in Vivo High-Resolution Imaging and Theranostics},
  author = {Kang, Xiaoying and Yin, Shuai and Song, Jianwen and Zhang, Yuan and Qi, Ji},
  date = {2023},
  journaltitle = {Sensors \& Diagnostics},
  volume = {2},
  number = {3},
  pages = {492--506},
  publisher = {Royal Society of Chemistry},
  doi = {10.1039/D2SD00234E},
  url = {https://pubs.rsc.org/en/content/articlelanding/2023/sd/d2sd00234e},
  urldate = {2024-05-17},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\I4SP788F\Kang e.a. - 2023 - NIR-II semiconducting polymers for in vivo high-re.pdf}
}

@article{kriegeskorteDeepNeuralNetworks2015,
  title = {Deep {{Neural Networks}}: {{A New Framework}} for {{Modeling Biological Vision}} and {{Brain Information Processing}}},
  shorttitle = {Deep {{Neural Networks}}},
  author = {Kriegeskorte, Nikolaus},
  date = {2015-11-24},
  journaltitle = {Annual Review of Vision Science},
  volume = {1},
  pages = {417--446},
  publisher = {Annual Reviews},
  issn = {2374-4642, 2374-4650},
  doi = {10.1146/annurev-vision-082114-035447},
  url = {https://www.annualreviews.org/content/journals/10.1146/annurev-vision-082114-035447},
  urldate = {2024-05-17},
  abstract = {Recent advances in neural network modeling have enabled major strides in computer vision and other artificial intelligence applications. Human-level visual recognition abilities are coming within reach of artificial systems. Artificial neural networks are inspired by the brain, and their computations could be implemented in biological neurons. Convolutional feedforward networks, which now dominate computer vision, take further inspiration from the architecture of the primate visual hierarchy. However, the current models are designed with engineering goals, not to model brain computations. Nevertheless, initial studies comparing internal representations between these models and primate brains find surprisingly similar representational spaces. With human-level performance no longer out of reach, we are entering an exciting new era, in which we will be able to build biologically faithful feedforward and recurrent computational models of how biological brains perform high-level feats of intelligence, including vision.},
  issue = {Volume 1, 2015},
  langid = {english},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\KJDNEJYW\\Kriegeskorte - 2015 - Deep Neural Networks A New Framework for Modeling.pdf;C\:\\Users\\marc_\\Zotero\\storage\\3G8Y7M5V\\annurev-vision-082114-035447.html}
}

@article{kucukogluOptimizationNeuroprostheticVision2022,
  title = {Optimization of {{Neuroprosthetic Vision}} via {{End-to-End Deep Reinforcement Learning}}},
  author = {Küçükoğlu, Burcu and Rueckauer, Bodo and Ahmad, Nasir and family=Steveninck, given=Jaap de Ruyter, prefix=van, useprefix=true and Güçlü, Umut and family=Gerven, given=Marcel, prefix=van, useprefix=true},
  date = {2022-11},
  journaltitle = {International Journal of Neural Systems},
  shortjournal = {Int. J. Neur. Syst.},
  volume = {32},
  number = {11},
  pages = {2250052},
  publisher = {World Scientific Publishing Co.},
  issn = {0129-0657},
  doi = {10.1142/S0129065722500526},
  url = {https://www.worldscientific.com/doi/abs/10.1142/S0129065722500526},
  urldate = {2024-05-10},
  abstract = {Visual neuroprostheses are a promising approach to restore basic sight in visually impaired people. A major challenge is to condense the sensory information contained in a complex environment into meaningful stimulation patterns at low spatial and temporal resolution. Previous approaches considered task-agnostic feature extractors such as edge detectors or semantic segmentation, which are likely suboptimal for specific tasks in complex dynamic environments. As an alternative approach, we propose to optimize stimulation patterns by end-to-end training of a feature extractor using deep reinforcement learning agents in virtual environments. We present a task-oriented evaluation framework to compare different stimulus generation mechanisms, such as static edge-based and adaptive end-to-end approaches like the one introduced here. Our experiments in Atari games show that stimulation patterns obtained via task-dependent end-to-end optimized reinforcement learning result in equivalent or improved performance compared to fixed feature extractors on high difficulty levels. These findings signify the relevance of adaptive reinforcement learning for neuroprosthetic vision in complex environments.},
  keywords = {deep reinforcement learning,end-to-end optimization,phosphene vision,Visual neuroprosthesis},
  file = {C:\Users\marc_\Zotero\storage\IS5M3JMX\Küçükoğlu e.a. - 2022 - Optimization of Neuroprosthetic Vision via End-to-.pdf}
}

@article{landelleInvestigatingHumanSpinal2021,
  title = {Investigating the Human Spinal Sensorimotor Pathways through Functional Magnetic Resonance Imaging},
  author = {Landelle, Caroline and Lungu, Ovidiu and Vahdat, Shahabeddin and Kavounoudias, Anne and Marchand-Pauvert, Véronique and De Leener, Benjamin and Doyon, Julien},
  date = {2021-12},
  journaltitle = {NeuroImage},
  shortjournal = {NeuroImage},
  volume = {245},
  pages = {118684},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2021.118684},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811921009575},
  urldate = {2024-05-17},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\TW65WUZW\Landelle e.a. - 2021 - Investigating the human spinal sensorimotor pathwa.pdf}
}

@article{leviEditorialClosedLoopSystems2018,
  title = {Editorial: {{Closed-Loop Systems}} for {{Next-Generation Neuroprostheses}}},
  shorttitle = {Editorial},
  author = {Levi, Timothée and Bonifazi, Paolo and Massobrio, Paolo and Chiappalone, Michela},
  date = {2018-02-12},
  journaltitle = {Frontiers in Neuroscience},
  shortjournal = {Front. Neurosci.},
  volume = {12},
  publisher = {Frontiers},
  issn = {1662-453X},
  doi = {10.3389/fnins.2018.00026},
  url = {https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2018.00026/full},
  urldate = {2024-05-17},
  langid = {english},
  keywords = {Closed-loop experiments,Neuromodulation,neuroprostheses,SNN,stimulation},
  file = {C:\Users\marc_\Zotero\storage\8NKWQU9D\Levi e.a. - 2018 - Editorial Closed-Loop Systems for Next-Generation.pdf}
}

@article{liaoBridgingGapsResidual2016,
  title = {Bridging the {{Gaps Between Residual Learning}}, {{Recurrent Neural Networks}} and {{Visual Cortex}}},
  author = {Liao, Qianli and Poggio, Tomaso},
  date = {2016},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\NEGIZAFP\Liao en Poggio - Bridging the Gaps Between Residual Learning, Recur.pdf}
}

@article{liuMultidimensionalGraphNeural2024,
  title = {Multidimensional {{Graph Neural Networks}} for {{Wireless Communications}}},
  author = {Liu, Shengjie and Guo, Jia and Yang, Chenyang},
  date = {2024-04},
  journaltitle = {IEEE Transactions on Wireless Communications},
  shortjournal = {IEEE Trans. Wireless Commun.},
  volume = {23},
  number = {4},
  eprint = {2212.11531},
  eprinttype = {arxiv},
  eprintclass = {eess},
  pages = {3057--3073},
  issn = {1536-1276, 1558-2248},
  doi = {10.1109/TWC.2023.3305124},
  url = {http://arxiv.org/abs/2212.11531},
  urldate = {2024-05-17},
  abstract = {Graph neural networks (GNNs) can improve the efficiency of learning wireless policies by leveraging their permutation properties and topology prior. While mismatched permutation property to a policy may degrade the learning performance and overlooked permutations incurs low sample efficiency, there is still lacking a systematical approach for modeling graph and designing structure of GNNs to harness all permutation properties. Moreover, the information of input feature may lose during updating hidden representations with GNNs, which leads to poor learning performance. In this paper, we propose a unified framework to learn permutable wireless policies with multidimensional GNNs, which update the hidden representations of hyper-edges to avoid the information loss. We provide a method to construct graph for a policy, over which a GNN with proper parameter sharing can exploit all possible permutations of the policy. We also investigate the permutability of wireless channels that affects the sample efficiency, and show how to trade off the training, inference, and design complexities of GNNs. To showcase how to design the GNNs within the framework, we consider precoding optimization in different systems. Simulation results validate the gain of the proposed GNNs over existing counterparts from exploiting the permutation prior and avoiding the information loss.},
  langid = {english},
  keywords = {Electrical Engineering and Systems Science - Signal Processing},
  file = {C:\Users\marc_\Zotero\storage\RGEEF5PK\2212.pdf}
}

@article{liuSoftElasticHydrogelbased2019,
  title = {Soft and Elastic Hydrogel-Based Microelectronics for Localized Low-Voltage Neuromodulation},
  author = {Liu, Yuxin and Liu, Jia and Chen, Shucheng and Lei, Ting and Kim, Yeongin and Niu, Simiao and Wang, Huiliang and Wang, Xiao and Foudeh, Amir M. and Tok, Jeffrey B.-H. and Bao, Zhenan},
  date = {2019-01},
  journaltitle = {Nature Biomedical Engineering},
  shortjournal = {Nat Biomed Eng},
  volume = {3},
  number = {1},
  pages = {58--68},
  publisher = {Nature Publishing Group},
  issn = {2157-846X},
  doi = {10.1038/s41551-018-0335-6},
  url = {https://www.nature.com/articles/s41551-018-0335-6},
  urldate = {2024-05-17},
  abstract = {Narrowing the mechanical mismatch between tissue and implantable microelectronics is essential for reducing immune responses and for accommodating body movement. However, the design of implantable soft electronics (on the order of 10\,kPa in modulus) remains a challenge because of the limited availability of suitable electronic materials. Here, we report electrically conductive hydrogel-based elastic microelectronics with Young’s modulus values in the kilopascal range. The system consists of a highly conductive soft hydrogel as a conductor and an elastic fluorinated photoresist as the passivation insulation layer. Owing to the high volumetric capacitance and the passivation layer of the hydrogel, electrode arrays of the thin-film hydrogel ‘elastronics’, 20\,μm in feature size, show a significantly reduced interfacial impedance with tissue, a current-injection density that is \textasciitilde 30 times higher than that of platinum electrodes, and stable electrical performance under strain. We demonstrate the use of the soft elastronic arrays for localized low-voltage electrical stimulation of the sciatic nerve in live mice.},
  langid = {english},
  keywords = {Biomaterials,Biomedical engineering,Electrical and electronic engineering,Materials for devices,Peripheral nervous system}
}

@article{luGraphenebasedNeurotechnologiesAdvanced2018,
  title = {Graphene-Based Neurotechnologies for Advanced Neural Interfaces},
  author = {Lu, Yichen and Liu, Xin and Kuzum, Duygu},
  date = {2018-06-01},
  journaltitle = {Current Opinion in Biomedical Engineering},
  shortjournal = {Current Opinion in Biomedical Engineering},
  series = {Tissue {{Engineering}} and {{Regenerative Medicine}} / {{Biomaterials}}},
  volume = {6},
  pages = {138--147},
  issn = {2468-4511},
  doi = {10.1016/j.cobme.2018.06.001},
  url = {https://www.sciencedirect.com/science/article/pii/S2468451118300096},
  urldate = {2024-05-17},
  abstract = {Understanding how neuron populations transform activities of individual neurons into complex behaviors is one of the biggest challenges of neuroscience research. However, current neural monitoring and controlling technologies provide insufficient spatiotemporal resolution to unravel neural circuit functions. To~this end, multifunctional neurotechnologies combining electrical, optical and chemical sensing and stimulation modalities~have been proposed to overcome resolution limits. Research in multifunctional probes has fueled the demand for new materials to build minimally invasive chronic interfaces to~the brain. Graphene has recently emerged as a neural interface material offering several outstanding properties, such~as optical transparency, flexibility, high conductivity, functionalization and biocompatibility. The unique combination of these properties in a single material system makes graphene an attractive choice for multi-modal probing of neural~activity. In this review, we discuss recent advances in~graphene-based neurotechnologies, highlight different approaches~and consider emerging directions inspired by unique characteristics of graphene.},
  keywords = {Biocompatibility,Chemical sensing,Electrophysiology,Graphene,Multimodal neural interface},
  file = {C:\Users\marc_\Zotero\storage\V5Q5J2H5\S2468451118300096.html}
}

@article{luoReviewResearchProgress2022,
  title = {A {{Review}}: {{Research Progress}} of {{Neural Probes}} for {{Brain Research}} and {{Brain}}–{{Computer Interface}}},
  shorttitle = {A {{Review}}},
  author = {Luo, Jiahui and Xue, Ning and Chen, Jiamin},
  date = {2022-12},
  journaltitle = {Biosensors},
  volume = {12},
  number = {12},
  pages = {1167},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-6374},
  doi = {10.3390/bios12121167},
  url = {https://www.mdpi.com/2079-6374/12/12/1167},
  urldate = {2024-05-17},
  abstract = {Neural probes, as an invasive physiological tool at the mesoscopic scale, can decipher the code of brain connections and communications from the cellular or even molecular level, and realize information fusion between the human body and external machines. In addition to traditional electrodes, two new types of neural probes have been developed in recent years: optoprobes based on optogenetics and magnetrodes that record neural magnetic signals. In this review, we give a comprehensive overview of these three kinds of neural probes. We firstly discuss the development of microelectrodes and strategies for their flexibility, which is mainly represented by the selection of flexible substrates and new electrode materials. Subsequently, the concept of optogenetics is introduced, followed by the review of several novel structures of optoprobes, which are divided into multifunctional optoprobes integrated with microfluidic channels, artifact-free optoprobes, three-dimensional drivable optoprobes, and flexible optoprobes. At last, we introduce the fundamental perspectives of magnetoresistive (MR) sensors and then review the research progress of magnetrodes based on it.},
  issue = {12},
  langid = {english},
  keywords = {brain–computer interface,electrodes flexibility,magnetic recordings,micromechanical technology,neural probes,optogenetics},
  file = {C:\Users\marc_\Zotero\storage\UQMAFUUS\Luo e.a. - 2022 - A Review Research Progress of Neural Probes for B.pdf}
}

@article{maheswaranathanInterpretingRetinalNeural2023,
  title = {Interpreting the Retinal Neural Code for Natural Scenes: {{From}} Computations to Neurons},
  shorttitle = {Interpreting the Retinal Neural Code for Natural Scenes},
  author = {Maheswaranathan, Niru and McIntosh, Lane T. and Tanaka, Hidenori and Grant, Satchel and Kastner, David B. and Melander, Joshua B. and Nayebi, Aran and Brezovec, Luke E. and Wang, Julia H. and Ganguli, Surya and Baccus, Stephen A.},
  date = {2023-09},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {111},
  number = {17},
  pages = {2742-2755.e4},
  issn = {08966273},
  doi = {10.1016/j.neuron.2023.06.007},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627323004671},
  urldate = {2024-05-22},
  abstract = {Understanding the circuit mechanisms of the visual code for natural scenes is a central goal of sensory neuroscience. We show that a three-layer network model predicts retinal natural scene responses with an accuracy nearing experimental limits. The model’s internal structure is interpretable, as interneurons recorded separately and not modeled directly are highly correlated with model interneurons. Models fitted only to natural scenes reproduce a diverse set of phenomena related to motion encoding, adaptation, and predictive coding, establishing their ethological relevance to natural visual computation. A new approach decomposes the computations of model ganglion cells into the contributions of model interneurons, allowing automatic generation of new hypotheses for how interneurons with different spatiotemporal responses are combined to generate retinal computations, including predictive phenomena currently lacking an explanation. Our results demonstrate a unified and general approach to study the circuit mechanisms of ethological retinal computations under natural visual scenes.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\XSC7F7TF\Maheswaranathan e.a. - 2023 - Interpreting the retinal neural code for natural s.pdf}
}

@article{marblestoneIntegrationDeepLearning2016,
  title = {Toward an {{Integration}} of {{Deep Learning}} and {{Neuroscience}}},
  author = {Marblestone, Adam H. and Wayne, Greg and Kording, Konrad P.},
  date = {2016-09-14},
  journaltitle = {Frontiers in Computational Neuroscience},
  shortjournal = {Front. Comput. Neurosci.},
  volume = {10},
  publisher = {Frontiers},
  issn = {1662-5188},
  doi = {10.3389/fncom.2016.00094},
  url = {https://www.frontiersin.org/articles/10.3389/fncom.2016.00094},
  urldate = {2024-05-17},
  abstract = {Neuroscience has focused on the detailed implementation of computation, studying neural codes, dynamics and circuits. In machine learning, however, artificial neural networks tend to eschew precisely designed codes, dynamics or circuits in favor of brute force optimization of a cost function, often using simple and relatively uniform initial architectures. Two recent developments have emerged within machine learning that create an opportunity to connect these seemingly divergent perspectives. First, structured architectures are used, including dedicated systems for attention, recursion and various forms of short- and long-term memory storage. Second, cost functions and training procedures have become more complex and are varied across layers and over time. Here we think about the brain in terms of these ideas. We hypothesize that (1) the brain optimizes cost functions, (2) the cost functions are diverse and differ across brain locations and over development, and (3) optimization operates within a pre-structured architecture matched to the computational problems posed by behavior. In support of these hypotheses, we argue that a range of implementations of credit assignment through multiple layers of neurons are compatible with our current knowledge of neural circuitry, and that the brain's specialized systems can be interpreted as enabling efficient optimization for specific problem classes. Such a heterogeneously optimized system, enabled by a series of interacting cost functions, serves to make learning data-efficient and precisely targeted to the needs of the organism. We suggest directions by which neuroscience could seek to refine and test these hypotheses.},
  langid = {english},
  keywords = {Cognitive Architecture,Cost functions,Developmental Bootstrapping,memory systems,neural networks,reinforcement learning,unsupervised learning},
  file = {C:\Users\marc_\Zotero\storage\KH7WXFUW\Marblestone e.a. - 2016 - Toward an Integration of Deep Learning and Neurosc.pdf}
}

@article{mathiesonPhotovoltaicRetinalProsthesis2012,
  title = {Photovoltaic Retinal Prosthesis with High Pixel Density},
  author = {Mathieson, Keith and Loudin, James and Goetz, Georges and Huie, Philip and Wang, Lele and Kamins, Theodore I. and Galambos, Ludwig and Smith, Richard and Harris, James S. and Sher, Alexander and Palanker, Daniel},
  date = {2012-06},
  journaltitle = {Nature Photonics},
  shortjournal = {Nature Photon},
  volume = {6},
  number = {6},
  pages = {391--397},
  publisher = {Nature Publishing Group},
  issn = {1749-4893},
  doi = {10.1038/nphoton.2012.104},
  url = {https://www.nature.com/articles/nphoton.2012.104},
  urldate = {2024-05-21},
  abstract = {Retinal degenerative diseases lead to blindness due to loss of the ‘image capturing’ photoreceptors, while neurons in the ‘image-processing’ inner retinal layers are relatively well preserved. Electronic retinal prostheses seek to restore sight by electrically stimulating the surviving neurons. Most implants are powered through inductive coils, requiring complex surgical methods to implant the coil-decoder-cable-array systems that deliver energy to stimulating electrodes via intraocular cables. We present a photovoltaic subretinal prosthesis, in which silicon photodiodes in each pixel receive power and data directly through pulsed near-infrared illumination and electrically stimulate neurons. Stimulation is produced in normal and degenerate rat retinas, with pulse durations of 0.5–4~ms, and threshold peak irradiances of 0.2–10~mW~mm−2, two orders of magnitude below the ocular safety limit. Neural responses were elicited by illuminating a single 70~µm bipolar pixel, demonstrating the possibility of a fully integrated photovoltaic retinal prosthesis with high pixel density.},
  langid = {english},
  keywords = {Biophotonics,Retina,Solar energy and photovoltaic technology},
  file = {C:\Users\marc_\Zotero\storage\ILJG6CVQ\Mathieson e.a. - 2012 - Photovoltaic retinal prosthesis with high pixel de.pdf}
}

@article{meikleNeurophysiologicalConsiderationsVisual2022,
  title = {Neurophysiological Considerations for Visual Implants},
  author = {Meikle, Sabrina J. and Wong, Yan T.},
  date = {2022-05-01},
  journaltitle = {Brain Structure and Function},
  shortjournal = {Brain Struct Funct},
  volume = {227},
  number = {4},
  pages = {1523--1543},
  issn = {1863-2661},
  doi = {10.1007/s00429-021-02417-2},
  url = {https://doi.org/10.1007/s00429-021-02417-2},
  urldate = {2024-06-04},
  abstract = {Neural implants have the potential to restore visual capabilities in blind individuals by electrically stimulating the neurons of the visual system. This stimulation can produce visual percepts known as phosphenes. The ideal location of electrical stimulation for achieving vision restoration is widely debated and dependent on the physiological properties of the targeted tissue. Here, the neurophysiology of several potential target structures within the visual system will be explored regarding their benefits and downfalls in producing phosphenes. These regions will include the lateral geniculate nucleus, primary visual cortex, visual area 2, visual area 3, visual area 4 and the middle temporal area. Based on the existing engineering limitations of neural prostheses, we anticipate that electrical stimulation of any singular brain region will be incapable of achieving high-resolution naturalistic perception including color, texture, shape and motion. As improvements in visual acuity facilitate improvements in quality of life, emulating naturalistic vision should be one of the ultimate goals of visual prostheses. To achieve this goal, we propose that multiple brain areas will need to be targeted in unison enabling different aspects of vision to be recreated.},
  langid = {english},
  keywords = {Cortical implant,Electrical stimulation,Neurophysiology,Phosphene,Visual cortex,Visual prosthesis},
  file = {C:\Users\marc_\Zotero\storage\VGMZAC78\Meikle en Wong - 2022 - Neurophysiological considerations for visual impla.pdf}
}

@article{merabetNeuralReorganizationFollowing2010,
  title = {Neural Reorganization Following Sensory Loss: The Opportunity of Change},
  shorttitle = {Neural Reorganization Following Sensory Loss},
  author = {Merabet, Lotfi B. and Pascual-Leone, Alvaro},
  date = {2010-01},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {11},
  number = {1},
  pages = {44--52},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn2758},
  url = {https://www.nature.com/articles/nrn2758},
  urldate = {2024-05-17},
  abstract = {There is growing evidence that sensory deprivation is associated with crossmodal neuroplastic changes in the brain. After visual or auditory deprivation, brain areas that are normally associated with the lost sense are recruited by spared sensory modalities. These changes underlie adaptive and compensatory behaviours in blind and deaf individuals. Although there are differences between these populations owing to the nature of the deprived sensory modality, there seem to be common principles regarding how the brain copes with sensory loss and the factors that influence neuroplastic changes. Here, we discuss crossmodal neuroplasticity with regards to behavioural adaptation after sensory deprivation and highlight the possibility of maladaptive consequences within the context of rehabilitation.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\5YK3HWE9\Merabet en Pascual-Leone - 2010 - Neural reorganization following sensory loss the .pdf}
}

@article{merabetWhatBlindnessCan2005,
  title = {What Blindness Can Tell Us about Seeing Again: Merging Neuroplasticity and Neuroprostheses},
  shorttitle = {What Blindness Can Tell Us about Seeing Again},
  author = {Merabet, Lotfi B. and Rizzo, Joseph F. and Amedi, Amir and Somers, David C. and Pascual-Leone, Alvaro},
  date = {2005-01},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {6},
  number = {1},
  pages = {71--77},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn1586},
  url = {https://www.nature.com/articles/nrn1586},
  urldate = {2024-05-17},
  abstract = {Significant progress has been made in the development of visual neuroprostheses to restore vision in blind individuals. Appropriate delivery of electrical stimulation to intact visual structures can evoke patterned sensations of light in those who have been blind for many years. However, success in developing functional visual prostheses requires an understanding of how to communicate effectively with the visually deprived brain in order to merge what is perceived visually with what is generated electrically.},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\marc_\Zotero\storage\B5I84TCW\Merabet e.a. - 2005 - What blindness can tell us about seeing again mer.pdf}
}

@article{nayebiRecurrentConnectionsPrimate2022,
  title = {Recurrent {{Connections}} in the {{Primate Ventral Visual Stream Mediate}} a {{Tradeoff Between Task Performance}} and {{Network Size During Core Object Recognition}}},
  author = {Nayebi, Aran and Sagastuy-Brena, Javier and Bear, Daniel M and Kar, Kohitij and Kubilius, Jonas and Ganguli, Surya and Sussillo, David and DiCarlo, James J and Yamins, Daniel L K},
  date = {2022},
  abstract = {The computational role of the abundant feedback connections in the ventral visual stream (VVS) is unclear, enabling humans and non-human primates to effortlessly recognize objects across a multitude of viewing conditions. Prior studies have augmented feedforward convolutional neural networks (CNNs) with recurrent connections to study their role in visual processing; however, often these recurrent networks are optimized directly on neural data or the comparative metrics used are undefined for standard feedforward networks that lack these connections. In this work, we develop task-optimized convolutional recurrent (ConvRNN) network models that more correctly mimic the timing and gross neuroanatomy of the ventral pathway. Properly chosen intermediate-depth ConvRNN circuit architectures, which incorporate mechanisms of feedforward bypassing and recurrent gating, can achieve high performance on a core recognition task, comparable to that of much deeper feedforward networks. We then develop methods that allow us to compare both CNNs and ConvRNNs to fine-grained measurements of primate categorization behavior and neural response trajectories across thousands of stimuli. We find that high performing ConvRNNs provide a better match to this data than feedforward networks of any depth, predicting the precise timings at which each stimulus is behaviorally decoded from neural activation patterns. Moreover, these ConvRNN circuits consistently produce quantitatively accurate predictions of neural dynamics from V4 and IT across the entire stimulus presentation. In fact, we find that the highest performing ConvRNNs, which best match neural and behavioral data, also achieve a strong Pareto-tradeoff between task performance and overall network size. Taken together, our results suggest the functional purpose of recurrence in the ventral pathway is to fit a high performing network in cortex, attaining computational power through temporal rather than spatial complexity.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\KD9HDDSE\Nayebi e.a. - Recurrent Connections in the Primate Ventral Visua.pdf}
}

@article{niketeghadBrainMachineInterfaces2019,
  title = {Brain {{Machine Interfaces}} for {{Vision Restoration}}: {{The Current State}} of {{Cortical Visual Prosthetics}}},
  shorttitle = {Brain {{Machine Interfaces}} for {{Vision Restoration}}},
  author = {Niketeghad, Soroush and Pouratian, Nader},
  date = {2019-01},
  journaltitle = {Neurotherapeutics},
  shortjournal = {Neurotherapeutics},
  volume = {16},
  number = {1},
  pages = {134--143},
  issn = {18787479},
  doi = {10.1007/s13311-018-0660-1},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1878747923010036},
  urldate = {2024-05-21},
  abstract = {Loss of vision alters the day to day life of blind individuals and may impose a significant burden on their family and the economy. Cortical visual prosthetics have been shown to have the potential of restoring a useful degree of vision via stimulation of primary visual cortex. Due to current advances in electrode design and wireless power and data transmission, development of these prosthetics has gained momentum in the past few years and multiple sites around the world are currently developing and testing their designs. In this review, we briefly outline the visual prosthetic approaches and describe the history of cortical visual prosthetics. Next, we focus on the state of the art of cortical visual prosthesis by briefly explaining the design of current devices that are either under development or in the clinical testing phase. Lastly, we shed light on the challenges of each design and provide some potential solutions.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\YAH4YEPK\Niketeghad en Pouratian - 2019 - Brain Machine Interfaces for Vision Restoration T.pdf}
}

@article{normannNeuralInterfaceCortical1999,
  title = {A Neural Interface for a Cortical Vision Prosthesis},
  author = {Normann, Richard A and Maynard, Edwin M and Rousche, Patrick J and Warren, David J},
  date = {1999-07},
  journaltitle = {Vision Research},
  shortjournal = {Vision Research},
  volume = {39},
  number = {15},
  pages = {2577--2587},
  issn = {00426989},
  doi = {10.1016/S0042-6989(99)00040-1},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0042698999000401},
  urldate = {2024-05-11},
  abstract = {The development of a cortically based vision prosthesis has been hampered by a lack of basic experiments on phosphene psychophysics. This basic research has been hampered by the lack of a means to safely stimulate large numbers of cortical neurons. Recently, a number of laboratories have developed arrays of silicon microelectrodes that could enable such basic studies on phosphene psychophysics. This paper describes one such array, the Utah electrode array, and summarizes neurosurgical, physiological and histological experiments that suggest that such an array could be implanted safely in visual cortex. We also summarize a series of chronic behavioral experiments that show that modest levels of electrical currents passed into cortex via this array can evoke sensory percepts. Pending the successful outcome of biocompatibility studies using such arrays, high count arrays of penetrating microelectrodes similar to this design could provide a useful tool for studies of the psychophysics of phosphene perception in human volunteers. Such studies could provide a proof-of-concept for cortically based artificial vision. © 1999 Published by Elsevier Science Ltd. All rights reserved.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\JI6M3GRJ\Normann e.a. - 1999 - A neural interface for a cortical vision prosthesi.pdf}
}

@article{nurmikkoChallengesLargeScaleCortical2020,
  title = {Challenges for {{Large-Scale Cortical Interfaces}}},
  author = {Nurmikko, Arto},
  date = {2020-10},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {108},
  number = {2},
  pages = {259--269},
  issn = {08966273},
  doi = {10.1016/j.neuron.2020.10.015},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627320308114},
  urldate = {2024-05-21},
  abstract = {This Perspective examines the status of large-scale cortical interfaces through the lens of potential applications to active implants for brain-machine interfaces. Examples of research and development in a still embryonic field are discussed from a neuroengineer’s perspective, touching on the design of scalable electrophysiological sensors with the ambition to access thousands of cortical points at near-cellular-level resolution. Important issues include microscale geometry of neural probes, design of implantable ultra-low-power electronics, implementation of high-data-rate wireless telemetry, and compatible device packaging—all requiring advanced solutions along a translational path for chronic human use.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\T28CN879\Nurmikko - 2020 - Challenges for Large-Scale Cortical Interfaces.pdf}
}

@article{petrosyanDecodingInterpretingCortical2021a,
  title = {Decoding and Interpreting Cortical Signals with a Compact Convolutional Neural Network},
  author = {Petrosyan, Artur and Sinkin, Mikhail and Lebedev, Mikhail and Ossadtchi, Alexei},
  date = {2021-03},
  journaltitle = {Journal of Neural Engineering},
  shortjournal = {J. Neural Eng.},
  volume = {18},
  number = {2},
  pages = {026019},
  publisher = {IOP Publishing},
  issn = {1741-2552},
  doi = {10.1088/1741-2552/abe20e},
  url = {https://dx.doi.org/10.1088/1741-2552/abe20e},
  urldate = {2024-05-22},
  abstract = {Objective. Brain–computer interfaces (BCIs) decode information from neural activity and send it to external devices. The use of Deep Learning approaches for decoding allows for automatic feature engineering within the specific decoding task. Physiologically plausible interpretation of the network parameters ensures the robustness of the learned decision rules and opens the exciting opportunity for automatic knowledge discovery. Approach. We describe a compact convolutional network-based architecture for adaptive decoding of electrocorticographic (ECoG) data into finger kinematics. We also propose a novel theoretically justified approach to interpreting the spatial and temporal weights in the architectures that combine adaptation in both space and time. The obtained spatial and frequency patterns characterizing the neuronal populations pivotal to the specific decoding task can then be interpreted by fitting appropriate spatial and dynamical models. Main results. We first tested our solution using realistic Monte-Carlo simulations. Then, when applied to the ECoG data from Berlin BCI competition IV dataset, our architecture performed comparably to the competition winners without requiring explicit feature engineering. Using the proposed approach to the network weights interpretation we could unravel the spatial and the spectral patterns of the neuronal processes underlying the successful decoding of finger kinematics from an ECoG dataset. Finally we have also applied the entire pipeline to the analysis of a 32-channel EEG motor-imagery dataset and observed physiologically plausible patterns specific to the task. Significance. We described a compact and interpretable CNN architecture derived from the basic principles and encompassing the knowledge in the field of neural electrophysiology. For the first time in the context of such multibranch architectures with factorized spatial and temporal processing we presented theoretically justified weights interpretation rules. We verified our recipes using simulations and real data and demonstrated that the proposed solution offers a good decoder and a tool for investigating motor control neural mechanisms.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\4QM37PUR\Petrosyan e.a. - 2021 - Decoding and interpreting cortical signals with a .pdf}
}

@article{pio-lopezVisualCorticalProsthesis2021b,
  title = {Visual Cortical Prosthesis: An Electrical Perspective},
  shorttitle = {Visual Cortical Prosthesis},
  author = {Pio-Lopez, Léo and Poulkouras, Romanos and Depannemaecker, Damien},
  date = {2021-07-04},
  journaltitle = {Journal of Medical Engineering \& Technology},
  volume = {45},
  number = {5},
  eprint = {33843427},
  eprinttype = {pmid},
  pages = {394--407},
  publisher = {Taylor \& Francis},
  issn = {0309-1902},
  doi = {10.1080/03091902.2021.1907468},
  url = {https://doi.org/10.1080/03091902.2021.1907468},
  urldate = {2024-05-21},
  abstract = {The electrical stimulation of the visual cortices has the potential to restore vision to blind individuals. Until now, the results of visual cortical prosthetics have been limited as no prosthesis has restored a full working vision but the field has shown a renewed interest these last years, thanks to wireless and technological advances. However, several scientific and technical challenges are still open to achieve the therapeutic benefit expected by these new devices. One of the main challenges is the electrical stimulation of the brain itself. In this review, we analyse the results in electrode-based visual cortical prosthetics from the electrical point of view. We first describe what is known about the electrode–tissue interface and safety of electrical stimulation. Then we focus on the psychophysics of prosthetic vision and the state-of-the-art on the interplay between the electrical stimulation of the visual cortex and the phosphene perception. Lastly, we discuss the challenges and perspectives of visual cortex electrical stimulation and electrode array design to develop the new generation implantable cortical visual prostheses.},
  keywords = {brain–machine interface,electrical stimulation,phosphene,prosthetic vision,Visual cortical prosthesis},
  file = {C:\Users\marc_\Zotero\storage\IJ6T5JAL\Pio-Lopez e.a. - 2021 - Visual cortical prosthesis an electrical perspect.pdf}
}

@article{rivnayHighperformanceTransistorsBioelectronics2015,
  title = {High-Performance Transistors for Bioelectronics through Tuning of Channel Thickness},
  author = {Rivnay, Jonathan and Leleux, Pierre and Ferro, Marc and Sessolo, Michele and Williamson, Adam and Koutsouras, Dimitrios A. and Khodagholy, Dion and Ramuz, Marc and Strakosas, Xenofon and Owens, Roisin M. and Benar, Christian and Badier, Jean-Michel and Bernard, Christophe and Malliaras, George G.},
  date = {2015-05},
  journaltitle = {Science Advances},
  shortjournal = {Sci. Adv.},
  volume = {1},
  number = {4},
  pages = {e1400251},
  issn = {2375-2548},
  doi = {10.1126/sciadv.1400251},
  url = {https://www.science.org/doi/10.1126/sciadv.1400251},
  urldate = {2024-05-17},
  abstract = {Transistors with tunable transconductance allow high-quality recordings of human brain rhythms.           ,                             Despite recent interest in organic electrochemical transistors (OECTs), sparked by their straightforward fabrication and high performance, the fundamental mechanism behind their operation remains largely unexplored. OECTs use an electrolyte in direct contact with a polymer channel as part of their device structure. Hence, they offer facile integration with biological milieux and are currently used as amplifying transducers for bioelectronics. Ion exchange between electrolyte and channel is believed to take place in OECTs, although the extent of this process and its impact on device characteristics are still unknown. We show that the uptake of ions from an electrolyte into a film of poly(3,4-ethylenedioxythiophene) doped with polystyrene sulfonate (PEDOT:PSS) leads to a purely volumetric capacitance of 39 F/cm               3               . This results in a dependence of the transconductance on channel thickness, a new degree of freedom that we exploit to demonstrate high-quality recordings of human brain rhythms. Our results bring to the forefront a transistor class in which performance can be tuned independently of device footprint and provide guidelines for the design of materials that will lead to state-of-the-art transistor performance.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\BWSTVAGU\Rivnay e.a. - 2015 - High-performance transistors for bioelectronics th.pdf}
}

@article{romeniMachineLearningFramework2021,
  title = {A Machine Learning Framework to Optimize Optic Nerve Electrical Stimulation for Vision Restoration},
  author = {Romeni, Simone and Zoccolan, Davide and Micera, Silvestro},
  date = {2021-07},
  journaltitle = {Patterns},
  shortjournal = {Patterns},
  volume = {2},
  number = {7},
  pages = {100286},
  issn = {26663899},
  doi = {10.1016/j.patter.2021.100286},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2666389921001197},
  urldate = {2024-05-17},
  abstract = {Optic nerve electrical stimulation is a promising technique to restore vision in blind subjects. Machine learning methods can be used to select effective stimulation protocols, but they require a model of the stimulated system to generate enough training data. Here, we use a convolutional neural network (CNN) as a model of the ventral visual stream. A genetic algorithm drives the activation of the units in a layer of the CNN representing a cortical region toward a desired pattern, by refining the activation imposed at a layer representing the optic nerve. To simulate the pattern of activation elicited by the sites of an electrode array, a simple point-source model was introduced and its optimization process was investigated for static and dynamic scenes. Psychophysical data confirm that our stimulation evolution framework produces results compatible with natural vision. Machine learning approaches could become a very powerful tool to optimize and personalize neuroprosthetic systems.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\KI3WR45H\Romeni e.a. - 2021 - A machine learning framework to optimize optic ner.pdf}
}

@article{rosenfeldTissueResponseChronically2020,
  title = {Tissue Response to a Chronically Implantable Wireless Intracortical Visual Prosthesis ({{Gennaris}} Array)},
  author = {Rosenfeld, Jeffrey V. and Wong, Yan T. and Yan, Edwin and Szlawski, Julian and Mohan, Anand and Clark, Jonathan CM and Rosa, Marcello and Lowery, Arthur},
  date = {2020-07},
  journaltitle = {Journal of Neural Engineering},
  shortjournal = {J. Neural Eng.},
  volume = {17},
  number = {4},
  pages = {046001},
  publisher = {IOP Publishing},
  issn = {1741-2552},
  doi = {10.1088/1741-2552/ab9e1c},
  url = {https://dx.doi.org/10.1088/1741-2552/ab9e1c},
  urldate = {2024-05-17},
  abstract = {Objective. Cortical vision prostheses aim to restore visual percepts to those who have lost sight by delivering electrical stimulation to the visual cortex. These devices need to be implanted intracranially using subdural or intracortical microelectrodes, and should preferably dispense with the need of transcranial wiring. The risks of cortical tissue injury from mechanical trauma, material biocompatibility, heat generation, electrical stimulation and long-term immune responses need to be evaluated. In this paper, we investigate the biological response to a wireless cortical vision prosthesis (Gennaris array), by characterizing the histological changes that occur following chronic electrical stimulation. Approach. Ten arrays (7 active, 3 passive) were implanted in three sheep using a pneumatic insertor. Each device consisted of a wireless receiver and Application Specific Integrated Circuit encased in a ceramic box, and could deliver electrical stimulation through one of 43 electrodes. Main results. Stimulation was delivered through seven of these devices for up to 3 months and each device was treated as independent for further analysis. Cumulatively, over 2700 h of stimulation were achieved without any observable adverse health effects. Histology showed that the devices and implantation procedure were well tolerated by the brain with a similar tissue response to the more common Utah arrays. However, voltage transients across the stimulating electrodes were not measured so exact charge injection could not be verified. Significance. This work represents one of the first long-term tests of a fully implantable cortical vision prosthesis. The results indicate that long-term stimulation through wireless arrays can be achieved without induction of widespread tissue damage.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\C7HGQ6LD\Rosenfeld e.a. - 2020 - Tissue response to a chronically implantable wirel.pdf}
}

@inproceedings{rueckauerExperiencingProstheticVision2022,
  title = {Experiencing {{Prosthetic Vision}} with {{Event-Based Sensors}}},
  booktitle = {Proceedings of the {{International Conference}} on {{Neuromorphic Systems}} 2022},
  author = {Rueckauer, Bodo and Van Gerven, Marcel},
  date = {2022-07-27},
  pages = {1--7},
  publisher = {ACM},
  location = {Knoxville TN USA},
  doi = {10.1145/3546790.3546813},
  url = {https://dl.acm.org/doi/10.1145/3546790.3546813},
  urldate = {2024-05-22},
  abstract = {Advances in materials science enable steadily increasing electrode counts for visual implants. On the algorithmic side, the fundamental problem remains how to encode a dense video feed using a lowdimensional set of stereotypical stimulation patterns. Bio-inspired retinal models have been proposed to improve the perceived light dots (phosphenes) resulting from electric stimulation. Here we present a system to evaluate prosthetic vision driven by a Dynamic Vision Sensor (DVS); a silicon retina modelling ON / OFF ganglion cells. This frame-free sensor signals pixel-wise changes in light intensity and is characterized by a high dynamic range and microsecond temporal resolution. We demonstrate how these retina-derived characteristics are beneficial in the presence of difficult lighting, motion blur, and for removal of cluttered redundant background. The system is tested in scenarios pertinent to prosthetic vision, such as recognition of letters, human gestures, pedestrians and cyclists, and compared against a setup with a conventional camera using edge-based stimulus generation. An AI agent trained to perform gesture recognition achieves 90\% accuracy via simulated prosthetic vision driven by the DVS.},
  eventtitle = {{{ICONS}}: {{International Conference}} on {{Neuromorphic Systems}}},
  isbn = {978-1-4503-9789-6},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\TBKTB7U5\Rueckauer en Van Gerven - 2022 - Experiencing Prosthetic Vision with Event-Based Se.pdf}
}

@article{ryuHumanCorticalProstheses2009,
  title = {Human Cortical Prostheses: Lost in Translation?},
  shorttitle = {Human Cortical Prostheses},
  author = {Ryu, Stephen I. and Shenoy, KRIShna V.},
  date = {2009-07},
  journaltitle = {Neurosurgical focus},
  shortjournal = {Neurosurg Focus},
  volume = {27},
  number = {1},
  eprint = {19569893},
  eprinttype = {pmid},
  pages = {E5},
  issn = {1092-0684},
  doi = {10.3171/2009.4.FOCUS0987},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3614414/},
  urldate = {2024-05-11},
  abstract = {Direct brain control of a prosthetic system is the subject of much popular and scientific news. Neural technology and science have advanced to the point that proof-of-concept systems exist for cortically-controlled prostheses in rats, monkeys, and even humans. However, realizing the dream of making such technology available to everyone is still far off. Fortunately today there is great public and scientific interest in making this happen, but it will only occur when the functional benefits of such systems outweigh the risks. In this article, the authors briefly summarize the state of the art and then highlight many issues that will directly limit clinical translation, including system durability, system performance, and patient risk. Despite the challenges, scientists and clinicians are in the desirable position of having both public and fiscal support to begin addressing these issues directly. The ultimate challenge now is to determine definitively whether these prosthetic systems will become clinical reality or forever unrealized.},
  pmcid = {PMC3614414},
  file = {C:\Users\marc_\Zotero\storage\F475J49T\Ryu en Shenoy - 2009 - Human cortical prostheses lost in translation.pdf}
}

@article{ryuSpatiallyConfinedResponses2020,
  title = {Spatially Confined Responses of Mouse Visual Cortex to Intracortical Magnetic Stimulation from Micro-Coils},
  author = {Ryu, Sang Baek and Paulk, Angelique C. and Yang, Jimmy C. and Ganji, Mehran and Dayeh, Shadi A. and Cash, Sydney S. and Fried, Shelley I. and Lee, Seung Woo},
  date = {2020-10},
  journaltitle = {Journal of Neural Engineering},
  shortjournal = {J. Neural Eng.},
  volume = {17},
  number = {5},
  pages = {056036},
  publisher = {IOP Publishing},
  issn = {1741-2552},
  doi = {10.1088/1741-2552/abbd22},
  url = {https://dx.doi.org/10.1088/1741-2552/abbd22},
  urldate = {2024-05-17},
  abstract = {Objective. Electrical stimulation via microelectrodes implanted in cortex has been suggested as a potential treatment for a wide range of neurological disorders. Despite some success however, the effectiveness of conventional electrodes remains limited, in part due to an inability to create specific patterns of neural activity around each electrode and in part due to challenges with maintaining a stable interface. The use of implantable micro-coils to magnetically stimulate the cortex has the potential to overcome these limitations because the asymmetric fields from coils can be harnessed to selectively activate some neurons, e.g. vertically-oriented pyramidal neurons while avoiding others, e.g. horizontally-oriented passing axons. In vitro experiments have shown that activation is indeed confined with micro-coils but their effectiveness in the intact brain of living animals has not been evaluated. Approach. To assess the efficacy of stimulation, a 128-channel custom recording microelectrode array was positioned on the surface of the visual cortex (ECoG) in anesthetized mice and responses to magnetic and electric stimulation were compared. Stimulation was delivered from electrodes or micro-coils implanted through a hole in the center of the recording array at a rate of 200 pulses per second for 100 ms. Main results. Both electric and magnetic stimulation reliably elicited cortical responses, although activation from electric stimulation was spatially expansive, often extending more than 1 mm from the stimulation site, while activation from magnetic stimulation was typically confined to a ∼300 µm diameter region around the stimulation site. Results were consistent for stimulation of both cortical layer 2/3 and layer 5 as well as across a range of stimulus strengths. Significance. The improved focality with magnetic stimulation suggests that the effectiveness of cortical stimulation can be improved. Improved focality may be particularly attractive for cortical prostheses that require high spatial resolution, e.g. devices that target sensory cortex, as it may lead to improved acuity.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\55VC46SG\Ryu e.a. - 2020 - Spatially confined responses of mouse visual corte.pdf}
}

@article{saxeIfDeepLearning2021,
  title = {If Deep Learning Is the Answer, What Is the Question?},
  author = {Saxe, Andrew and Nelli, Stephanie and Summerfield, Christopher},
  date = {2021-01},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {22},
  number = {1},
  pages = {55--67},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/s41583-020-00395-8},
  url = {https://www.nature.com/articles/s41583-020-00395-8},
  urldate = {2024-05-17},
  abstract = {Neuroscience research is undergoing a minor revolution. Recent advances in machine learning and artificial intelligence research have opened up new ways of thinking about neural computation. Many researchers are excited by the possibility that deep neural networks may offer theories of perception, cognition and action for biological brains. This approach has the potential to radically reshape our approach to understanding neural systems, because the computations performed by deep networks are learned from experience, and not endowed by the researcher. If so, how can neuroscientists use deep networks to model and understand biological brains? What is the outlook for neuroscientists who seek to characterize computations or neural codes, or who wish to understand perception, attention, memory and executive functions? In this Perspective, our goal is to offer a road map for systems neuroscience research in the age of deep learning. We discuss the conceptual and methodological challenges of comparing behaviour, learning dynamics and neural representations in artificial and biological systems, and we highlight new research questions that have emerged for neuroscience as a direct consequence of recent advances in machine learning.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\EETNLZ36\Saxe e.a. - 2021 - If deep learning is the answer, what is the questi.pdf}
}

@article{springerOnDeviceDeepLearning2021,
  title = {On-{{Device Deep Learning Inference}} for {{System-on-Chip}} ({{SoC}}) {{Architectures}}},
  author = {Springer, Tom and Eiroa-Lledo, Elia and Stevens, Elizabeth and Linstead, Erik},
  date = {2021-01},
  journaltitle = {Electronics},
  volume = {10},
  number = {6},
  pages = {689},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics10060689},
  url = {https://www.mdpi.com/2079-9292/10/6/689},
  urldate = {2024-05-22},
  abstract = {As machine learning becomes ubiquitous, the need to deploy models on real-time, embedded systems will become increasingly critical. This is especially true for deep learning solutions, whose large models pose interesting challenges for target architectures at the “edge” that are resource-constrained. The realization of machine learning, and deep learning, is being driven by the availability of specialized hardware, such as system-on-chip solutions, which provide some alleviation of constraints. Equally important, however, are the operating systems that run on this hardware, and specifically the ability to leverage commercial real-time operating systems which, unlike general purpose operating systems such as Linux, can provide the low-latency, deterministic execution required for embedded, and potentially safety-critical, applications at the edge. Despite this, studies considering the integration of real-time operating systems, specialized hardware, and machine learning/deep learning algorithms remain limited. In particular, better mechanisms for real-time scheduling in the context of machine learning applications will prove to be critical as these technologies move to the edge. In order to address some of these challenges, we present a resource management framework designed to provide a dynamic on-device approach to the allocation and scheduling of limited resources in a real-time processing environment. These types of mechanisms are necessary to support the deterministic behavior required by the control components contained in the edge nodes. To validate the effectiveness of our approach, we applied rigorous schedulability analysis to a large set of randomly generated simulated task sets and then verified the most time critical applications, such as the control tasks which maintained low-latency deterministic behavior even during off-nominal conditions. The practicality of our scheduling framework was demonstrated by integrating it into a commercial real-time operating system (VxWorks) then running a typical deep learning image processing application to perform simple object detection. The results indicate that our proposed resource management framework can be leveraged to facilitate integration of machine learning algorithms with real-time operating systems and embedded platforms, including widely-used, industry-standard real-time operating systems.},
  issue = {6},
  langid = {english},
  keywords = {deep learning,feedback control,heterogeneous multiprocessor scheduling,Internet-of-Things,real-time operating systems,system-on-chip},
  file = {C:\Users\marc_\Zotero\storage\Q8WNUSPG\Springer e.a. - 2021 - On-Device Deep Learning Inference for System-on-Ch.pdf}
}

@inproceedings{srivastavaEstimatingPhospheneMaps2007,
  title = {Estimating {{Phosphene Maps}} for {{Psychophysical Experiments}} Used in {{Testing}} a {{Cortical Visual Prosthesis Device}}},
  booktitle = {2007 3rd {{International IEEE}}/{{EMBS Conference}} on {{Neural Engineering}}},
  author = {Srivastava, N.R. and Troyk, P. R. and Towle, V. L. and Curry, D. and Schmidt, E. and Kufta, C. and Dagnelie, G.},
  date = {2007-05},
  pages = {130--133},
  issn = {1948-3554},
  doi = {10.1109/CNE.2007.369629},
  url = {https://ieeexplore.ieee.org/document/4227234},
  urldate = {2024-05-29},
  abstract = {Visual prosthesis devices are being developed to restore vision for those with blindness. Researchers working in the field of visual prosthesis are taking different approaches to develop a practical device. Some are targeting the retina for stimulation, whereas at least one group is targeting the optical nerve, and our laboratory is developing a system for the visual cortex. To estimate the kind of response they might expect from a typical user, researchers are conducting psychophysical experiments on normally-sighted persons. The device being developed in our laboratory is a first generation visual prosthesis system, designed to test the limits of artificial visual pattern recognition. Targeting the visual cortex area with our first generation device has limitations including limitations in lateral cortical surface area for electrode implantation, surgical difficulties and the lack of understanding as to how to use an artificial interface for communication with the visual cortex. Here, we discuss the uncertainties related to visotopic mapping of the lateral surface of the occipital lobe in humans.},
  eventtitle = {2007 3rd {{International IEEE}}/{{EMBS Conference}} on {{Neural Engineering}}},
  keywords = {Blindness,Electrodes,Intracortical,Laboratories,Pattern recognition,phosphene map,Psychology,psychophysical experiments,Retina,Stimulated emission,System testing,Test pattern generators,visual cortex,visual prosthesis,Visual prosthesis},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\JDIIBXUF\\Srivastava e.a. - 2007 - Estimating Phosphene Maps for Psychophysical Exper.pdf;C\:\\Users\\marc_\\Zotero\\storage\\AEYDVER9\\4227234.html}
}

@article{stevensGlobalPrevalenceVision2013,
  title = {Global {{Prevalence}} of {{Vision Impairment}} and {{Blindness}}},
  author = {Stevens, Gretchen A and White, Richard A and Flaxman, Seth R and Price, Holly and Jonas, Jost B and Keeffe, Jill and Leasher, Janet and Naidoo, Kovin and Pesudovs, Konrad and Resnikoff, Serge and Taylor, Hugh and Bourne, Rupert R A},
  date = {2013},
  volume = {120},
  number = {12},
  abstract = {Purpose: Vision impairment is a leading and largely preventable cause of disability worldwide. However, no study of global and regional trends in the prevalence of vision impairment has been carried out. We estimated the prevalence of vision impairment and its changes worldwide for the past 20 years. Design: Systematic review. Participants: A systematic review of published and unpublished population-based data on vision impairment and blindness from 1980 through 2012. Methods: Hierarchical models were fitted fitted to estimate the prevalence of moderate and severe vision impairment (MSVI; defined as presenting visual acuity {$<$}6/18 but !3/60) and the prevalence of blindness (presenting visual acuity {$<$}3/60) by age, country, and year. Main Outcome Measures: Trends in the prevalence of MSVI and blindness for the period 1990 through 2010. Results: Globally, 32.4 million people (95\% confidence interval [CI], 29.4e36.5 million people; 60\% women) were blind in 2010, and 191 million people (95\% CI, 174e230 million people; 57\% women) had MSVI. The agestandardized prevalence of blindness in older adults (!50 years) was more than 4\% in Western Sub-Saharan Africa (6.0\%; 95\% CI, 4.6\%e7.1\%), Eastern Sub-Saharan Africa (5.7\%; 95\% CI, 4.4\%e6.9\%), South Asia (4.4\%; 95\% CI, 3.5\%e5.1\%), and North Africa and the Middle East (4.6\%; 95\% CI, 3.5\%e5.8\%), in contrast to high-income regions with blindness prevalences of 0.4\% or less. The MSVI prevalence in older adults was highest in South Asia (23.6\%; 95\% CI, 19.4\%e29.4\%), Oceania (18.9\%; 95\% CI, 11.8\%e23.7\%), and Eastern and Western Sub-Saharan Africa and North Africa and the Middle East (95\% CI, 15.9\%e16.8\%). The MSVI prevalence was less than 5\% in all 4 high-income regions. The global age-standardized prevalence of blindness and MSVI for older adults decreased from 3.0\% (95\% CI, 2.7\%e3.4\%) worldwide in 1990 to 1.9\% (95\% CI, 1.7\%e2.2\%) in 2010 and from 14.3\% (95\% CI, 12.1\%e16.2\%) worldwide to 10.4\% (95\% CI, 9.5\%e12.3\%), respectively. When controlling for age, women’s prevalence of blindness was greater than men’s in all world regions. Because the global population has increased and aged between 1990 and 2010, the number of blind has increased by 0.6 million people (95\% CI, À5.2 to 5.3 million people). The number with MSVI may have increased by 19 million people (95\% CI, À8 to 72 million people) from 172 million people (95\% CI, 142e198 million people) in 1990. Conclusions: The age-standardized prevalence of blindness and MSVI has decreased in the past 20 years. However, because of population growth and the relative increase in older adults, the blind population has been stable and the population with MSVI may have increased.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\EJPMQCKC\Stevens e.a. - 2013 - Global Prevalence of Vision Impairment and Blindne.pdf}
}

@online{subramanianGraphConvolutionalNetworks2020,
  title = {Graph {{Convolutional Networks Reveal Neural Connections Encoding Prosthetic Sensation}}},
  author = {Subramanian, Vivek and Khani, Joshua},
  date = {2020-08-22},
  eprint = {2009.03272},
  eprinttype = {arxiv},
  eprintclass = {cs, q-bio, stat},
  url = {http://arxiv.org/abs/2009.03272},
  urldate = {2024-05-22},
  abstract = {Extracting stimulus features from neuronal ensembles is of great interest to the development of neuroprosthetics that project sensory information directly to the brain via electrical stimulation. Machine learning strategies that optimize stimulation parameters as the subject learns to interpret the artificial input could improve device efficacy, increase prosthetic performance, ensure stability of evoked sensations, and improve power consumption by eliminating extraneous input. Recent advances extending deep learning techniques to non-Euclidean graph data provide a novel approach to interpreting neuronal spiking activity. For this study, we apply graph convolutional networks (GCNs) to infer the underlying functional relationship between neurons that are involved in the processing of artificial sensory information. Data was collected from a freely behaving rat using a four infrared (IR) sensor, ICMS-based neuroprosthesis to localize IR light sources. We use GCNs to predict the stimulation frequency across four stimulating channels in the prosthesis, which encode relative distance and directional information to an IR-emitting reward port. Our GCN model is able to achieve a peak performance of 73.5\% on a modified ordinal regression performance metric in a multiclass classification problem consisting of 7 classes, where chance is 14.3\%. Additionally, the inferred adjacency matrix provides a adequate representation of the underlying neural circuitry encoding the artificial sensation.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Neurons and Cognition,Quantitative Biology - Quantitative Methods,Statistics - Machine Learning},
  file = {C:\Users\marc_\Zotero\storage\39JQYPAP\Subramanian en Khani - 2020 - Graph Convolutional Networks Reveal Neural Connect.pdf}
}

@article{towleDevelopmentColorVisual2021,
  title = {Toward the Development of a Color Visual Prosthesis},
  author = {Towle, Vernon L. and Pham, Tuan and McCaffrey, Michael and Allen, Danielle and Troyk, Philip R.},
  date = {2021-02},
  journaltitle = {Journal of Neural Engineering},
  shortjournal = {J. Neural Eng.},
  volume = {18},
  number = {2},
  pages = {023001},
  publisher = {IOP Publishing},
  issn = {1741-2552},
  doi = {10.1088/1741-2552/abd520},
  url = {https://dx.doi.org/10.1088/1741-2552/abd520},
  urldate = {2024-05-11},
  abstract = {Objective. All of the human prosthetic visual systems implanted so far have been achromatic. Schmidt et al (1996 Brain 119 507–22) reported that at low stimulation intensities their subject reported that phosphenes usually had a specific hue, but when the stimulus intensity was increased, they desaturated to white. We speculate here that previous B/W prosthetic systems were unnecessarily over-stimulating the visual cortex to obtain white phosphenes, which may be why unexpected alterations in phosphenes and seizures were not an uncommon occurrence. A color prosthesis would have the advantage of being elicited by lower levels of stimulation, reducing the probability of causing epileptogenic responses. Approach. A ‘hybrid’ mode of stimulation is suggested, involving a combination of B/W and color stimulation, which could provide color information without reducing spatial resolution. Main results. Colors in the real world are spread along intensity and chromatic gradients. Significance. Software implementation strategies are discussed, as are the advantages and challenges for possible color prosthetic systems.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\9FBXMQ3W\Towle e.a. - 2021 - Toward the development of a color visual prosthesi.pdf}
}

@article{tzekovGabelEdArtificial2020,
  title = {Gabel, {{V}}.{{P}}. (Ed): {{Artificial Vision}}: {{A Clinical Guide}}},
  shorttitle = {Gabel, {{V}}.{{P}}. (Ed)},
  author = {Tzekov, Radouil},
  date = {2020-03-01},
  journaltitle = {Graefe's Archive for Clinical and Experimental Ophthalmology},
  shortjournal = {Graefes Arch Clin Exp Ophthalmol},
  volume = {258},
  number = {3},
  pages = {699--700},
  issn = {1435-702X},
  doi = {10.1007/s00417-020-04606-x},
  url = {https://doi.org/10.1007/s00417-020-04606-x},
  urldate = {2024-05-31},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\BUINW73A\Tzekov - 2020 - Gabel, V.P. (ed) Artificial Vision A Clinical Gu.pdf}
}

@article{vandergrintenBiologicallyPlausiblePhosphene2024a,
  title = {Towards Biologically Plausible Phosphene Simulation for the Differentiable Optimization of Visual Cortical Prostheses},
  author = {family=Grinten, given=Maureen, prefix=van der, useprefix=true and family=Ruyter van Steveninck, given=Jaap, prefix=de, useprefix=true and Lozano, Antonio and Pijnacker, Laura and Rueckauer, Bodo and Roelfsema, Pieter and family=Gerven, given=Marcel, prefix=van, useprefix=true and family=Wezel, given=Richard, prefix=van, useprefix=true and Güçlü, Umut and Güçlütürk, Yağmur},
  editor = {Baker, Chris I and Barry, Michael P},
  date = {2024-02-22},
  journaltitle = {eLife},
  volume = {13},
  pages = {e85812},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.85812},
  url = {https://doi.org/10.7554/eLife.85812},
  urldate = {2024-05-14},
  abstract = {Blindness affects millions of people around the world. A promising solution to restoring a form of vision for some individuals are cortical visual prostheses, which bypass part of the impaired visual pathway by converting camera input to electrical stimulation of the visual system. The artificially induced visual percept (a pattern of localized light flashes, or ‘phosphenes’) has limited resolution, and a great portion of the field’s research is devoted to optimizing the efficacy, efficiency, and practical usefulness of the encoding of visual information. A commonly exploited method is non-invasive functional evaluation in sighted subjects or with computational models by using simulated prosthetic vision (SPV) pipelines. An important challenge in this approach is to balance enhanced perceptual realism, biologically plausibility, and real-time performance in the simulation of cortical prosthetic vision. We present a biologically plausible, PyTorch-based phosphene simulator that can run in real-time and uses differentiable operations to allow for gradient-based computational optimization of phosphene encoding models. The simulator integrates a wide range of clinical results with neurophysiological evidence in humans and non-human primates. The pipeline includes a model of the retinotopic organization and cortical magnification of the visual cortex. Moreover, the quantitative effects of stimulation parameters and temporal dynamics on phosphene characteristics are incorporated. Our results demonstrate the simulator’s suitability for both computational applications such as end-to-end deep learning-based prosthetic vision optimization as well as behavioral experiments. The modular and open-source software provides a flexible simulation framework for computational, clinical, and behavioral neuroscientists working on visual neuroprosthetics.},
  keywords = {bionic vision,blindness,cortical stimulation,deep learning,neural implants,neurotechnology,simulated prosthetic vision},
  file = {C:\Users\marc_\Zotero\storage\KCRLQFNK\van der Grinten e.a. - 2024 - Towards biologically plausible phosphene simulatio.pdf}
}

@article{wanArtificialSensoryNeuron2020,
  title = {An Artificial Sensory Neuron with Visual-Haptic Fusion},
  author = {Wan, Changjin and Cai, Pingqiang and Guo, Xintong and Wang, Ming and Matsuhisa, Naoji and Yang, Le and Lv, Zhisheng and Luo, Yifei and Loh, Xian Jun and Chen, Xiaodong},
  date = {2020-09-14},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {11},
  number = {1},
  pages = {4602},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-18375-y},
  url = {https://www.nature.com/articles/s41467-020-18375-y},
  urldate = {2024-05-17},
  abstract = {Human behaviors are extremely sophisticated, relying on the adaptive, plastic and event-driven network of sensory neurons. Such neuronal system analyzes multiple sensory cues efficiently to establish accurate depiction of the environment. Here, we develop a bimodal artificial sensory neuron to implement the sensory fusion processes. Such a bimodal artificial sensory neuron collects optic and pressure information from the photodetector and pressure sensors respectively, transmits the bimodal information through an ionic cable, and integrates them into post-synaptic currents by a synaptic transistor. The sensory neuron can be excited in multiple levels by synchronizing the two sensory cues, which enables the manipulating of skeletal myotubes and a robotic hand. Furthermore, enhanced recognition capability achieved on fused visual/haptic cues is confirmed by simulation of a multi-transparency pattern recognition task. Our biomimetic design has the potential to advance technologies in cyborg and neuromorphic systems by endowing them with supramodal perceptual capabilities.},
  langid = {english},
  keywords = {Electrical and electronic engineering,Nanosensors,Sensors and biosensors},
  file = {C:\Users\marc_\Zotero\storage\4G9GJ832\Wan e.a. - 2020 - An artificial sensory neuron with visual-haptic fu.pdf}
}

@article{wangApplicationComputerVision2021,
  title = {The Application of Computer Vision to Visual Prosthesis},
  author = {Wang, Jing and Zhu, Haiyi and Liu, Jianyun and Li, Heng and Han, Yanling and Zhou, Ruyan and Zhang, Yun},
  date = {2021},
  journaltitle = {Artificial Organs},
  volume = {45},
  number = {10},
  pages = {1141--1154},
  issn = {1525-1594},
  doi = {10.1111/aor.14022},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/aor.14022},
  urldate = {2024-05-21},
  abstract = {A visual prosthesis is an auxiliary device for patients with blinding diseases that cannot be treated with conventional surgery or drugs. It converts captured images into corresponding electrical stimulation patterns, according to which phosphenes are generated through the action of internal electrodes on the visual pathway to form visual perception. However, due to some restrictions such as the few implantable electrodes that the biological tissue can accommodate, the induced perception is far from ideal. Therefore, an important issue in visual prosthesis research is how to detect and present useful information in low-resolution prosthetic vision to improve the visual function of the wearer. In recent years, with the development and broad application of computer vision methods, researchers have investigated the possibility of their utilization in visual prostheses by simulating prosthetic visual percepts. Through the optimization of visual perception by image processing, the efficiency of visual prosthesis devices can be further improved to better meet the needs of prosthesis wearers. In this article, recent works on prosthetic vision centering on implementing computer vision methods are reviewed. Differences, strengths, and weaknesses of the mentioned methods are discussed. The development directions of optimizing prosthetic vision and improving methods of visual perception are analyzed.},
  langid = {english},
  keywords = {computer vision,image processing,machine learning,simulated prosthetic vision,visual prosthesis},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\M54RPIST\\Wang e.a. - 2021 - The application of computer vision to visual prost.pdf;C\:\\Users\\marc_\\Zotero\\storage\\XHBN9DZ2\\aor.html}
}

@article{wangArtificialIntelligenceTechniques2023,
  title = {Artificial Intelligence Techniques for Retinal Prostheses: A Comprehensive Review and Future Direction},
  shorttitle = {Artificial Intelligence Techniques for Retinal Prostheses},
  author = {Wang, Chuanqing and Fang, Chaoming and Zou, Yong and Yang, Jie and Sawan, Mohamad},
  date = {2023-02},
  journaltitle = {Journal of Neural Engineering},
  shortjournal = {J. Neural Eng.},
  volume = {20},
  number = {1},
  pages = {011003},
  publisher = {IOP Publishing},
  issn = {1741-2552},
  doi = {10.1088/1741-2552/acb295},
  url = {https://dx.doi.org/10.1088/1741-2552/acb295},
  urldate = {2024-05-11},
  abstract = {Objective. Retinal prostheses are promising devices to restore vision for patients with severe age-related macular degeneration or retinitis pigmentosa disease. The visual processing mechanism embodied in retinal prostheses play an important role in the restoration effect. Its performance depends on our understanding of the retina’s working mechanism and the evolvement of computer vision models. Recently, remarkable progress has been made in the field of processing algorithm for retinal prostheses where the new discovery of the retina’s working principle and state-of-the-arts computer vision models are combined together. Approach. We investigated the related research on artificial intelligence techniques for retinal prostheses. The processing algorithm in these studies could be attributed to three types: computer vision-related methods, biophysical models, and deep learning models. Main results. In this review, we first illustrate the structure and function of the normal and degenerated retina, then demonstrate the vision rehabilitation mechanism of three representative retinal prostheses. It is necessary to summarize the computational frameworks abstracted from the normal retina. In addition, the development and feature of three types of different processing algorithms are summarized. Finally, we analyze the bottleneck in existing algorithms and propose our prospect about the future directions to improve the restoration effect. Significance. This review systematically summarizes existing processing models for predicting the response of the retina to external stimuli. What’s more, the suggestions for future direction may inspire researchers in this field to design better algorithms for retinal prostheses.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\NNNDXHBZ\Wang e.a. - 2023 - Artificial intelligence techniques for retinal pro.pdf}
}

@article{wangDeepLearningEdge2020,
  title = {Deep {{Learning}} for {{Edge Computing Applications}}: {{A State-of-the-Art Survey}}},
  author = {Wang, Fangxin and Ma, Xiaoqiang and Liu, Jiangchuan},
  date = {2020},
  volume = {8},
  abstract = {With the booming development of Internet-of-Things (IoT) and communication technologies such as 5G, our future world is envisioned as an interconnected entity where billions of devices will provide uninterrupted service to our daily lives and the industry. Meanwhile, these devices will generate massive amounts of valuable data at the network edge, calling for not only instant data processing but also intelligent data analysis in order to fully unleash the potential of the edge big data. Both the traditional cloud computing and on-device computing cannot sufficiently address this problem due to the high latency and the limited computation capacity, respectively. Fortunately, the emerging edge computing sheds a light on the issue by pushing the data processing from the remote network core to the local network edge, remarkably reducing the latency and improving the efficiency. Besides, the recent breakthroughs in deep learning have greatly facilitated the data processing capacity, enabling a thrilling development of novel applications, such as video surveillance and autonomous driving. The convergence of edge computing and deep learning is believed to bring new possibilities to both interdisciplinary researches and industrial applications. In this article, we provide a comprehensive survey of the latest efforts on the deep-learning-enabled edge computing applications and particularly offer insights on how to leverage the deep learning advances to facilitate edge applications from four domains, i.e., smart multimedia, smart transportation, smart city, and smart industry. We also highlight the key research challenges and promising research directions therein. We believe this survey will inspire more researches and contributions in this promising field.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\PNLA2RTL\Wang e.a. - 2020 - Deep Learning for Edge Computing Applications A S.pdf}
}

@article{wangNeuroSEENeuromorphicEnergyEfficient2022,
  title = {{{NeuroSEE}}: {{A Neuromorphic Energy-Efficient Processing Framework}} for {{Visual Prostheses}}},
  shorttitle = {{{NeuroSEE}}},
  author = {Wang, Chuanqing and Yang, Jie and Sawan, Mohamad},
  date = {2022-08},
  journaltitle = {IEEE Journal of Biomedical and Health Informatics},
  volume = {26},
  number = {8},
  pages = {4132--4141},
  issn = {2168-2208},
  doi = {10.1109/JBHI.2022.3172306},
  url = {https://ieeexplore.ieee.org/abstract/document/9767670},
  urldate = {2024-05-22},
  abstract = {Visual prostheses with both comprehensive visual signal processing capability and energy efficiency are becoming increasingly demanded in the age of intelligent personal healthcare, particularly with the rise of wearable and implantable devices. To address this trend, we propose NeuroSEE, a neuromorphic energy-efficient processing framework that combines a spike representation encoding technique and a bio-inspired processing method. This framework first utilizes sparse spike trains to represent visual information, and then a bio-inspired spiking neural network (SNN) is adopted to process the spike trains. The SNN model makes use of an IF neuron with multiple spike-firing rates to decrease the energy consumption without compensating for prediction performance. The experimental results indicate that when predicting the response of the primary visual cortex, the framework achieves a state-of-the-art Pearson correlation coefficient performance. Spike-based recording and processing methods simplify the storage and transmission of redundant scene information and complex calculation processes. It could reduce power consumption by 15 times compared with the existing Convolutional neural network (CNN) processing framework. The proposed NeuroSEE framework predicts the response of the primary visual cortex in an energy efficient manner, making it a powerful tool for visual prostheses.},
  eventtitle = {{{IEEE Journal}} of {{Biomedical}} and {{Health Informatics}}},
  keywords = {Age-related macular degeneration,bio-inspired processing,Biological system modeling,Image edge detection,Image restoration,Predictive models,Retina,retinitis pigmentosa,spiking neural network,Visual prostheses,Visual prosthesis,Visualization,wearable devices},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\2D8B8ZHE\\Wang e.a. - 2022 - NeuroSEE A Neuromorphic Energy-Efficient Processi.pdf;C\:\\Users\\marc_\\Zotero\\storage\\EFVS8VGC\\9767670.html}
}

@article{wangNovelSimulationParadigm2023,
  title = {A Novel Simulation Paradigm Utilising {{MRI-derived}} Phosphene Maps for Cortical Prosthetic Vision},
  author = {Wang, Haozhe Zac and Wong, Yan Tat},
  date = {2023-08},
  journaltitle = {Journal of Neural Engineering},
  shortjournal = {J. Neural Eng.},
  volume = {20},
  number = {4},
  pages = {046027},
  publisher = {IOP Publishing},
  issn = {1741-2552},
  doi = {10.1088/1741-2552/aceca2},
  url = {https://dx.doi.org/10.1088/1741-2552/aceca2},
  urldate = {2024-05-11},
  abstract = {Objective. We developed a realistic simulation paradigm for cortical prosthetic vision and investigated whether we can improve visual performance using a novel clustering algorithm. Approach. Cortical visual prostheses have been developed to restore sight by stimulating the visual cortex. To investigate the visual experience, previous studies have used uniform phosphene maps, which may not accurately capture generated phosphene map distributions of implant recipients. The current simulation paradigm was based on the Human Connectome Project retinotopy dataset and the placement of implants on the cortices from magnetic resonance imaging scans. Five unique retinotopic maps were derived using this method. To improve performance on these retinotopic maps, we enabled head scanning and a density-based clustering algorithm was then used to relocate centroids of visual stimuli. The impact of these improvements on visual detection performance was tested. Using spatially evenly distributed maps as a control, we recruited ten subjects and evaluated their performance across five sessions on the Berkeley Rudimentary Visual Acuity test and the object recognition task. Main results. Performance on control maps is significantly better than on retinotopic maps in both tasks. Both head scanning and the clustering algorithm showed the potential of improving visual ability across multiple sessions in the object recognition task. Significance. The current paradigm is the first that simulates the experience of cortical prosthetic vision based on brain scans and implant placement, which captures the spatial distribution of phosphenes more realistically. Utilisation of evenly distributed maps may overestimate the performance that visual prosthetics can restore. This simulation paradigm could be used in clinical practice when making plans for where best to implant cortical visual prostheses.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\GD9VY3TI\Wang en Wong - 2023 - A novel simulation paradigm utilising MRI-derived .pdf}
}

@article{wangRecentProgressSecond2023,
  title = {Recent Progress of Second Near-Infrared ({{NIR-II}}) Fluorescence Microscopy in Bioimaging},
  author = {Wang, Tian and Chen, Yingying and Wang, Bo and Wu, Mingfu},
  date = {2023-02-21},
  journaltitle = {Frontiers in Physiology},
  shortjournal = {Front. Physiol.},
  volume = {14},
  pages = {1126805},
  issn = {1664-042X},
  doi = {10.3389/fphys.2023.1126805},
  url = {https://www.frontiersin.org/articles/10.3389/fphys.2023.1126805/full},
  urldate = {2024-05-17},
  abstract = {Visualizing biological tissues               in vivo               at a cellular or subcellular resolution to explore molecular signaling and cell behaviors is a crucial direction for research into biological processes.               In vivo               imaging can provide quantitative and dynamic visualization/mapping in biology and immunology. New microscopy techniques combined with near-infrared region fluorophores provide additional avenues for further progress               in vivo               bioimaging. Based on the development of chemical materials and physical optoelectronics, new NIR-II microscopy techniques are emerging, such as confocal and multiphoton microscopy, light-sheet fluorescence microscopy (LSFM), and wide-field microscopy. In this review, we introduce the characteristics of               in vivo               imaging using NIR-II fluorescence microscopy. We also cover the recent advances in NIR-II fluorescence microscopy techniques in bioimaging and the potential for overcoming current challenges.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\Z2TDSBUZ\Wang e.a. - 2023 - Recent progress of second near-infrared (NIR-II) f.pdf}
}

@article{warwickNeuroengineeringNeuroprosthetics2018,
  title = {Neuroengineering and Neuroprosthetics},
  author = {Warwick, Kevin},
  date = {2018-01-01},
  journaltitle = {Brain and Neuroscience Advances},
  volume = {2},
  pages = {2398212818817499},
  publisher = {SAGE Publications Ltd STM},
  issn = {2398-2128},
  doi = {10.1177/2398212818817499},
  url = {https://doi.org/10.1177/2398212818817499},
  urldate = {2024-05-13},
  abstract = {This article contains a directed overview of the field of neuroengineering and neuroprosthetics. The aim of the article is, however, not to go over introductory material covered elsewhere, but rather to look ahead at exciting areas for likely future development. The BrainGate implant is focussed on in terms of its use as an interface between the Internet and the human nervous system. Sensory prosthetics of different types and deep brain stimulation are considered. Different possibilities with deep brain stimulation are also discussed.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\ISGFU5N7\Warwick - 2018 - Neuroengineering and neuroprosthetics.pdf}
}

@article{weilandRetinalProsthesis2014,
  title = {Retinal {{Prosthesis}}},
  author = {Weiland, James D. and Humayun, Mark S.},
  date = {2014-05},
  journaltitle = {IEEE Transactions on Biomedical Engineering},
  volume = {61},
  number = {5},
  pages = {1412--1424},
  issn = {1558-2531},
  doi = {10.1109/TBME.2014.2314733},
  url = {https://ieeexplore.ieee.org/abstract/document/6782448?casa_token=ZUTicFUaXioAAAAA:IBxCmWvvE-CQbSXi-FSAn4FokSS-r52MbH4CZJEPBznsyAkjYauVxh9XV015JCpC7WKcbEbAYGzt},
  urldate = {2024-06-03},
  abstract = {Retinal prosthesis has been translated from the laboratory to the clinic over the past two decades. Currently, two devices have regulatory approval for the treatment of retinitis pigmentosa. These devices provide partial sight restoration and patients use this improved vision in their everyday lives. Improved mobility and object detection are some of the more notable findings from the clinical trials. However, significant vision restoration will require both better technology and improved understanding of the interaction between electrical stimulation and the retina. This paper reviews the recent clinical trials and highlights technology breakthroughs that will contribute to next generation of retinal prostheses.},
  eventtitle = {{{IEEE Transactions}} on {{Biomedical Engineering}}},
  keywords = {Arrays,Blindness,Electrodes,Implants,medical device,neural prosthesis,Packaging,Prosthetics,Retina,retinal prosthesis,Visualization},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\RUACHJ6M\\Weiland en Humayun - 2014 - Retinal Prosthesis.pdf;C\:\\Users\\marc_\\Zotero\\storage\\Y8FQGBER\\6782448.html}
}

@article{willseyRealtimeBrainmachineInterface2022,
  title = {Real-Time Brain-Machine Interface in Non-Human Primates Achieves High-Velocity Prosthetic Finger Movements Using a Shallow Feedforward Neural Network Decoder},
  author = {Willsey, Matthew S. and Nason-Tomaszewski, Samuel R. and Ensel, Scott R. and Temmar, Hisham and Mender, Matthew J. and Costello, Joseph T. and Patil, Parag G. and Chestek, Cynthia A.},
  date = {2022-11-12},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {6899},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-34452-w},
  url = {https://www.nature.com/articles/s41467-022-34452-w},
  urldate = {2024-05-11},
  abstract = {Despite the rapid progress and interest in brain-machine interfaces that restore motor function, the performance of prosthetic fingers and limbs has yet to mimic native function. The algorithm that converts brain signals to a control signal for the prosthetic device is one of the limitations in achieving rapid and realistic finger movements. To achieve more realistic finger movements, we developed a shallow feed-forward neural network to decode real-time two-degree-of-freedom finger movements in two adult male rhesus macaques. Using a two-step training method, a recalibrated feedback intention–trained (ReFIT) neural network is introduced to further improve performance. In 7 days of testing across two animals, neural network decoders, with higher-velocity and more natural appearing finger movements, achieved a 36\% increase in throughput over the ReFIT Kalman filter, which represents the current standard. The neural network decoders introduced herein demonstrate real-time decoding of continuous movements at a level superior to the current state-of-the-art and could provide a starting point to using neural networks for the development of more naturalistic brain-controlled prostheses.},
  langid = {english},
  keywords = {Brain–machine interface,Motor cortex},
  file = {C:\Users\marc_\Zotero\storage\S9REYDQ8\Willsey e.a. - 2022 - Real-time brain-machine interface in non-human pri.pdf}
}

@article{wuComprehensiveSurveyGraph2021,
  title = {A {{Comprehensive Survey}} on {{Graph Neural Networks}}},
  author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
  date = {2021-01},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  shortjournal = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {32},
  number = {1},
  pages = {4--24},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2020.2978386},
  url = {https://ieeexplore.ieee.org/document/9046288/},
  urldate = {2024-05-22},
  abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial–temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing field.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\HMQ6QT2W\Wu e.a. - 2021 - A Comprehensive Survey on Graph Neural Networks.pdf}
}

@article{wuRetinalProsthesesEngineering2023,
  title = {Retinal {{Prostheses}}: {{Engineering}} and {{Clinical Perspectives}} for {{Vision Restoration}}},
  shorttitle = {Retinal {{Prostheses}}},
  author = {Wu, Kevin Y. and Mina, Mina and Sahyoun, Jean-Yves and Kalevar, Ananda and Tran, Simon D.},
  date = {2023-01},
  journaltitle = {Sensors},
  volume = {23},
  number = {13},
  pages = {5782},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s23135782},
  url = {https://www.mdpi.com/1424-8220/23/13/5782},
  urldate = {2024-06-03},
  abstract = {A retinal prosthesis, also known as a bionic eye, is a device that can be implanted to partially restore vision in patients with retinal diseases that have resulted in the loss of photoreceptors (e.g., age-related macular degeneration and retinitis pigmentosa). Recently, there have been major breakthroughs in retinal prosthesis technology, with the creation of numerous types of implants, including epiretinal, subretinal, and suprachoroidal sensors. These devices can stimulate the remaining cells in the retina with electric signals to create a visual sensation. A literature review of the pre-clinical and clinical studies published between 2017 and 2023 is conducted. This narrative review delves into the retinal anatomy, physiology, pathology, and principles underlying electronic retinal prostheses. Engineering aspects are explored, including electrode–retina alignment, electrode size and material, charge density, resolution limits, spatial selectivity, and bidirectional closed-loop systems. This article also discusses clinical aspects, focusing on safety, adverse events, visual function, outcomes, and the importance of rehabilitation programs. Moreover, there is ongoing debate over whether implantable retinal devices still offer a promising approach for the treatment of retinal diseases, considering the recent emergence of cell-based and gene-based therapies as well as optogenetics. This review compares retinal prostheses with these alternative therapies, providing a balanced perspective on their advantages and limitations. The recent advancements in retinal prosthesis technology are also outlined, emphasizing progress in engineering and the outlook of retinal prostheses. While acknowledging the challenges and complexities of the technology, this article highlights the significant potential of retinal prostheses for vision restoration in individuals with retinal diseases and calls for continued research and development to refine and enhance their performance, ultimately improving patient outcomes and quality of life.},
  issue = {13},
  langid = {english},
  keywords = {flexible electronic devices,flexible sensors,human–machine interface,implantable electronic devices,ophthalmology,retinal disease,retinal prosthesis,vision restoration},
  file = {C:\Users\marc_\Zotero\storage\5AS4287U\Wu e.a. - 2023 - Retinal Prostheses Engineering and Clinical Persp.pdf}
}

@article{xiangFlexibleThreedimensionalElectrode2016,
  title = {A Flexible Three-Dimensional Electrode Mesh: {{An}} Enabling Technology for Wireless Brain–Computer Interface Prostheses},
  shorttitle = {A Flexible Three-Dimensional Electrode Mesh},
  author = {Xiang, Zhuolin and Liu, Jingquan and Lee, Chengkuo},
  date = {2016-05-23},
  journaltitle = {Microsystems \& Nanoengineering},
  shortjournal = {Microsyst Nanoeng},
  volume = {2},
  number = {1},
  pages = {1--8},
  publisher = {Nature Publishing Group},
  issn = {2055-7434},
  doi = {10.1038/micronano.2016.12},
  url = {https://www.nature.com/articles/micronano201612},
  urldate = {2024-05-17},
  abstract = {The neural interface is a key component in wireless brain–computer prostheses. In this study, we demonstrate that a unique three-dimensional (3D) microneedle electrode on a flexible mesh substrate, which can be fabricated without complicated micromachining techniques, is conformal to the tissues with minimal invasiveness. Furthermore, we demonstrate that it can be applied to different functional layers in the nervous system without length limitation. The microneedle electrode is fabricated using drawing lithography technology from biocompatible materials. In this approach, the profile of a 3D microneedle electrode array is determined by the design of a two-dimensional (2D) pattern on the mask, which can be used to access different functional layers in different locations of the brain. Due to the sufficient stiffness of the electrode and the excellent flexibility of the mesh substrate, the electrode can penetrate into the tissue with its bottom layer fully conformal to the curved brain surface. Then, the exposed contact at the end of the microneedle electrode can successfully acquire neural signals from the brain.},
  langid = {english},
  keywords = {Chemistry,Electrical and electronic engineering},
  file = {C:\Users\marc_\Zotero\storage\AA9LHT26\Xiang e.a. - 2016 - A flexible three-dimensional electrode mesh An en.pdf}
}

@article{xieUseOpticalCoherence2022,
  title = {The Use of Optical Coherence Tomography in Neurology: A Review},
  shorttitle = {The Use of Optical Coherence Tomography in Neurology},
  author = {Xie, Jim S and Donaldson, Laura and Margolin, Edward},
  date = {2022-12-01},
  journaltitle = {Brain},
  shortjournal = {Brain},
  volume = {145},
  number = {12},
  pages = {4160--4177},
  issn = {0006-8950},
  doi = {10.1093/brain/awac317},
  url = {https://doi.org/10.1093/brain/awac317},
  urldate = {2024-05-17},
  abstract = {Optical coherence tomography is a non-invasive, cost-efficient technique that provides high-resolution in vivo imaging of retinal tissue. The peripapillary retinal nerve fibre layer and macular ganglion cell complex are surrogate markers of neuroaxonal integrity in not only the eye, but also the CNS. Retinal atrophy may occur in tandem with CNS pathologies as a result of injury to ganglion cells, direct degeneration of the pregeniculate pathway, or retrograde trans-synaptic degeneration secondary to postgeniculate lesions. In this review, we outline the basic principles of optical coherence tomography and discuss its application to managing patients with demyelinating disorders, idiopathic intracranial hypertension, stroke, neurodegenerative conditions, and mitochondrial disorders. We demonstrate that measurements of peripapillary retinal nerve fibre layer and macular ganglion cell complex thickness are paramount in diagnosing and monitoring neurological disorders, including those with subclinical disease progression.},
  file = {C:\Users\marc_\Zotero\storage\IK4UM2E3\Xie e.a. - 2022 - The use of optical coherence tomography in neurolo.pdf}
}

@article{yangIntegratedMicroprismMicroelectrode2024,
  title = {Integrated {{Microprism}} and {{Microelectrode Array}} for {{Simultaneous Electrophysiology}} and {{Two-Photon Imaging}} across {{All Cortical Layers}}},
  author = {Yang, Qianru and Wu, Bingchen and Castagnola, Elisa and Pwint, May Yoon and Williams, Nathaniel P. and Vazquez, Alberto L. and Cui, Xinyan Tracy},
  date = {2024},
  journaltitle = {Advanced Healthcare Materials},
  volume = {n/a},
  number = {n/a},
  pages = {2302362},
  issn = {2192-2659},
  doi = {10.1002/adhm.202302362},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/adhm.202302362},
  urldate = {2024-05-17},
  abstract = {Cerebral neural electronics play a crucial role in neuroscience research with increasing translational applications such as brain–computer interfaces for sensory input and motor output restoration. While widely utilized for decades, the understanding of the cellular mechanisms underlying this technology remains limited. Although two-photon microscopy (TPM) has shown great promise in imaging superficial neural electrodes, its application to deep-penetrating electrodes is technically difficult. Here, a novel device integrating transparent microelectrode arrays with glass microprisms, enabling electrophysiology recording and stimulation alongside TPM imaging across all cortical layers in a vertical plane, is introduced. Tested in Thy1-GCaMP6 mice for over 4 months, the integrated device demonstrates the capability for multisite electrophysiological recording/stimulation and simultaneous TPM calcium imaging. As a proof of concept, the impact of microstimulation amplitude, frequency, and depth on neural activation patterns is investigated using the setup. With future improvements in material stability and single unit yield, this multimodal tool greatly expands integrated electrophysiology and optical imaging from the superficial brain to the entire cortical column, opening new avenues for neuroscience research and neurotechnology development.},
  langid = {english},
  keywords = {calcium imaging,electrophysiology,microprism,microstimulation,two-photon microscopy},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\5S6FCHX3\\Yang e.a. - Integrated Microprism and Microelectrode Array for.pdf;C\:\\Users\\marc_\\Zotero\\storage\\25JPRA3P\\adhm.html}
}

@article{zareElectroconductiveMultifunctionalPolypyrrole2021a,
  title = {Electroconductive Multi-Functional Polypyrrole Composites for Biomedical Applications},
  author = {Zare, Ehsan Nazarzadeh and Agarwal, Tarun and Zarepour, Atefeh and Pinelli, Filippo and Zarrabi, Ali and Rossi, Filippo and Ashrafizadeh, Milad and Maleki, Aziz and Shahbazi, Mohammad-Ali and Maiti, Tapas Kumar and Varma, Rajender S. and Tay, Franklin R and Hamblin, Michael R and Mattoli, Virgilio and Makvandi, Pooyan},
  date = {2021-09},
  journaltitle = {Applied Materials Today},
  shortjournal = {Applied Materials Today},
  volume = {24},
  pages = {101117},
  issn = {23529407},
  doi = {10.1016/j.apmt.2021.101117},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2352940721001827},
  urldate = {2024-05-17},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\6FPPE4MZ\Zare e.a. - 2021 - Electroconductive multi-functional polypyrrole com.pdf}
}

@article{zareGoldNanostructuresSynthesis2022,
  title = {Gold Nanostructures: Synthesis, Properties, and Neurological Applications},
  shorttitle = {Gold Nanostructures},
  author = {Zare, Iman and Tavakkoli~Yaraki, Mohammad and Speranza, Giorgio and Hassani~Najafabadi, Alireza and Shourangiz-Haghighi, Alireza and Bakhshian~Nik, Amirala and B.~Manshian, Bella and Saraiva, Cláudia and J.~Soenen, Stefaan and J.~Kogan, Marcelo and Woong~Lee, Jee and V.~Apollo, Nicholas and Bernardino, Liliana and Araya, Eyleen and Mayer, Dirk and Mao, Guangzhao and R.~Hamblin, Michael},
  date = {2022},
  journaltitle = {Chemical Society Reviews},
  volume = {51},
  number = {7},
  pages = {2601--2680},
  publisher = {Royal Society of Chemistry},
  doi = {10.1039/D1CS01111A},
  url = {https://pubs.rsc.org/en/content/articlelanding/2022/cs/d1cs01111a},
  urldate = {2024-05-17},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\67IPIAKG\Zare e.a. - 2022 - Gold nanostructures synthesis, properties, and ne.pdf}
}

@article{zhangAdvancesMachineLearningEnhanced2024,
  title = {Advances in {{Machine-Learning Enhanced Nanosensors}}: {{From Cloud Artificial Intelligence Toward Future Edge Computing}} at {{Chip Level}}},
  shorttitle = {Advances in {{Machine-Learning Enhanced Nanosensors}}},
  author = {Zhang, Zixuan and Liu, Xinmiao and Zhou, Hong and Xu, Siyu and Lee, Chengkuo},
  date = {2024},
  journaltitle = {Small Structures},
  volume = {5},
  number = {4},
  pages = {2300325},
  issn = {2688-4062},
  doi = {10.1002/sstr.202300325},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sstr.202300325},
  urldate = {2024-05-21},
  abstract = {Machine-learning-enhanced nanosensors are rapidly emerging as a promising solution in the field of sensor technology, as traditional sensors encounter limitations of data analysis in their development. Since the inception of machine-learning algorithms being applied to enhance nanosensors, they have gained significant attention due to their adaptive and predictive capabilities, which promise to dramatically improve efficiency in data collection and processing applications. Herein, a comprehensive overview of technological innovation is provided by reviewing the latest developments in cloud computing, edge computing, and the burgeoning realm of neuromorphic computing. Cloud computing has emerged as a powerhouse, harnessing formidable computational capabilities to process vast volumes of high-dimensional data. Then, the research directions for various applications of these cloud artificial intelligence (AI)-enhanced nanosensors are outlined. Moreover, the integration of AI and nanosensor technology into chip-level edge computing, although promising, still faces challenges such as energy-efficient hardware development, algorithm optimization, and scalability for mass production. Finally, a forward-looking perspective on the future of machine-learning-enhanced nanosensors is provided, delineating the challenges and opportunities for further research and innovation in this exciting field.},
  langid = {english},
  keywords = {cloud computing,edge computing,memristors,neuromorphic computing},
  file = {C\:\\Users\\marc_\\Zotero\\storage\\WSIJ738W\\Zhang e.a. - 2024 - Advances in Machine-Learning Enhanced Nanosensors.pdf;C\:\\Users\\marc_\\Zotero\\storage\\Z2PTA6ZK\\sstr.html}
}

@article{zhangClimbinginspiredTwiningElectrodes2019,
  title = {Climbing-Inspired Twining Electrodes Using Shape Memory for Peripheral Nerve Stimulation and Recording},
  author = {Zhang, Yingchao and Zheng, Ning and Cao, Yu and Wang, Fengle and Wang, Peng and Ma, Yinji and Lu, Bingwei and Hou, Guohui and Fang, Zizheng and Liang, Ziwei and Yue, Mengkun and Li, Yan and Chen, Ying and Fu, Ji and Wu, Jian and Xie, Tao and Feng, Xue},
  date = {2019-04-05},
  journaltitle = {Science Advances},
  shortjournal = {Sci. Adv.},
  volume = {5},
  number = {4},
  pages = {eaaw1066},
  issn = {2375-2548},
  doi = {10.1126/sciadv.aaw1066},
  url = {https://www.science.org/doi/10.1126/sciadv.aaw1066},
  urldate = {2024-05-17},
  abstract = {Proposed 3D neural electrode can self-climb onto peripheral nerve driven by body temperature and form flexible neural interface.           ,              Peripheral neuromodulation has been widely used throughout clinical practices and basic neuroscience research. However, the mechanical and geometrical mismatches at current electrode-nerve interfaces and complicated surgical implantation often induce irreversible neural damage, such as axonal degradation. Here, compatible with traditional 2D planar processing, we propose a 3D twining electrode by integrating stretchable mesh serpentine wires onto a flexible shape memory substrate, which has permanent shape reconfigurability (from 2D to 3D), distinct elastic modulus controllability (from \textasciitilde 100 MPa to \textasciitilde 300 kPa), and shape memory recoverability at body temperature. Similar to the climbing process of twining plants, the temporarily flattened 2D stiff twining electrode can naturally self-climb onto nerves driven by 37°C normal saline and form 3D flexible neural interfaces with minimal constraint on the deforming nerves. In vivo animal experiments, including right vagus nerve stimulation for reducing the heart rate and action potential recording of the sciatic nerve, demonstrate the potential clinical utility.},
  langid = {english},
  file = {C:\Users\marc_\Zotero\storage\T3VLGAH8\Zhang e.a. - 2019 - Climbing-inspired twining electrodes using shape m.pdf}
}
