\documentclass[twocolumn,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{abstract}
\usepackage{titlesec}
\usepackage[backend=biber,style=apa]{biblatex}% Changed style to apa
\usepackage[hidelinks]{hyperref}
\PassOptionsToPackage{hyphens}{url} % Pass hyphens option to url package via hyperref
\usepackage{fancyhdr} % For custom headers and footers
\usepackage{lastpage} % For page numbering in the footer
\usepackage{xcolor} % For text color
\usepackage{tabularx} % Tabularx package for better table formatting
\usepackage{longtable}% Long table package for tables that span multiple pages

% Set marginparwidth for todonotes
\setlength{\marginparwidth}{2cm} % Adjust the marginparwidth
\usepackage{todonotes} % TODOs
\usepackage{tcolorbox} % For colored boxes
\usepackage{caption} % For custom captions

% Fonts and typography
\usepackage{helvet} % Load the Helvetica font package
\renewcommand{\familydefault}{\sfdefault} % Set sans-serif as the default font family

% Page setup
\geometry{margin=1in}
\setstretch{1.2}
\titleformat{\section}{\bfseries\Large}{\thesection}{1em}{}
\titleformat{\subsection}{\bfseries\large}{\thesubsection}{1em}{}
\titleformat{\subsubsection}{\bfseries\normalsize}{\thesubsubsection}{1em}{}

% Add bibliography file
\addbibresource{references.bib}

% Customization to remove url date and format URLs and DOIs
\AtEveryBibitem{%
  \ifentrytype{online}{%
    \clearfield{urldate}%
    \clearfield{note}%
  }{}%
  \ifentrytype{article}{%
    \clearfield{urldate}%
  }{}%
}

\renewbibmacro*{doi+eprint+url}{%
  \printfield{doi}%
  \newunit\newblock%
  \iffieldundef{doi}{%
    \usebibmacro{eprint}%
    \newunit\newblock%
    \usebibmacro{url+urldate}}%
    {}%
}

% Customize the caption format
\captionsetup[figure]{
    labelfont=bf,           % Bold font for the label
    labelsep=space           % Use a space as the separator
}
\captionsetup[table]{
    labelfont=bf,           % Bold font for the label
    labelsep=space           % Use a space as the separator
}

% Change font size of bibliography entries
\renewcommand{\bibfont}{\fontsize{7pt}{9pt}\selectfont}% Set font size to 7pt, maybe too small. Change to 8pt if needed. Also adjust actual text size?

% Title
\title{State-of-the-Art in Visual Cortical Prostheses: Technological Advances \& AI Integration}
\author{
  Marc J. Posthuma\\
  Student Number: 4413105\\
  \texttt{marc.posthuma@ru.nl}\\
  \\
  Radboud University\\
  Supervisor: Prof.\ dr.\ R.J.A.\ van\ Wezel\\
  Department of Neurobiology, Donders Centre for Neuroscience
}
\date{\today}

% Adjust page geometry to balance header and footer
\geometry{
  a4paper,
  left=20mm,
  right=20mm,
  top=30mm,
  bottom=30mm,
  headheight=60.50554pt, % Set the head height
  headsep=10pt, % Space between header and text
  footskip=30pt % Space between text and footer
}

% Custom footrule commands
\newcommand{\blackfootrule}{%
  \color{black}\makebox[\headwidth]{\rule[0.5ex]{\headwidth}{0.3pt}}%
}

\newcommand{\grayfootrule}{%
  \color{gray}\makebox[\headwidth]{\rule[0.5ex]{\headwidth}{0.3pt}}%
}

% Define fancyhdr styles
\fancypagestyle{firstpage}{
  \fancyhf{}
  \fancyhead[L]{\includegraphics[width=5cm, keepaspectratio]{imgs/RU_logo_NL_cropped.png}}
  \fancyhead[R]{\fontsize{10}{12}\selectfont \textbf{Systematic Review in Neuroscience} \\ NWI-BM059}
  \fancyfoot[L]{\fontsize{8}{10}\selectfont \textcolor{gray}{Radboud University}}
  \fancyfoot[C]{\fontsize{8}{10}\selectfont \textcolor{gray}{\thepage\ of~\pageref{LastPage}}}
  \fancyfoot[R]{\fontsize{8}{10}\selectfont \textcolor{gray}{July 2024}}
  \renewcommand{\footrulewidth}{0.3pt}
  \renewcommand{\footrule}{\blackfootrule}
}

\fancypagestyle{rest}{
  \fancyhf{}
  \fancyhead[L]{\fontsize{8}{10}\selectfont \textcolor{gray}{Systematic Review}}
  \fancyhead[R]{\fontsize{8}{10}\selectfont \textcolor{gray}{State-of-the-Art in Visual Cortical Prostheses}}
  \fancyfoot[L]{\fontsize{8}{10}\selectfont \textcolor{gray}{Radboud University}}
  \fancyfoot[C]{\fontsize{8}{10}\selectfont \textcolor{gray}{\thepage\ of~\pageref{LastPage}}}
  \fancyfoot[R]{\fontsize{8}{10}\selectfont \textcolor{gray}{July 2024}}
  \renewcommand{\footrulewidth}{0.3pt}
  \renewcommand{\footrule}{\grayfootrule}
}

% Document
\begin{document}

% \pagestyle{plain}% Default plain page style for the list of TODOs
% \listoftodos% Remove this line before submission
% \clearpage%To make sure the todo list is on a separate page without fancyhdr

% \newpage% To make sure the todo list is on a separate page without fancyhdr

% Title and abstract
\twocolumn[
      \maketitle
      \thispagestyle{firstpage} % Apply first page style after title
      \begin{onecolabstract}
            \noindent Visual cortical prostheses represent a revolutionary
            technology within the field of neuro\-prosthetics, aimed at
            restoring vision for individuals with visual impairments through
            direct neural interfaces. This review systematically explores the
            current capabilities, limitations, and future prospects of visual
            cortical prostheses, with a focus on the integration of artificial
            intelligence (AI) to enhance functionality and effectiveness. Key
            topics include the optimization of phosphene patterns, real-time
            image processing, and comparisons with other types of visual
            prosthetic devices. The goal is to provide a comprehensive overview
            of the state-of-the-art in visual cortical prostheses and propose
            future research directions.
      \end{onecolabstract}
      \textbf{Keywords:} Visual cortical prostheses, neuroprosthetics, artificial intelligence, phosphene patterns, real-time image processing
      \vspace{1cm}
]

% Ensure first page style is applied until the first page is full
\thispagestyle{firstpage}
\section*{Introduction}\label{sec:intro}
\subsection*{Background}
Globally, blindness affects millions of people, with estimates rising from over
30 million in 2013 to 43.3 million in
2020~\parencite{stevensGlobalPrevalenceVision2013,
      bourneTrendsPrevalenceBlindness2021}. For certain types of blindness, visual
prosthetics present a promising avenue for restoring rudimentary vision through
electrical stimulation of the visual system. The concept of using bioelectrical
interfaces dates back to the 18th century, with pioneering experiments by LeRoy
in 1755 and Volta in 1800 demonstrating that electrical stimulation of the eye
can induce visual sensations~\parencite{voltaXVIIElectricityExcited1997}.

The field of neuroprosthetics has witnessed remarkable progress, particularly
with the advent of visual cortical prostheses. These advanced devices offer hope
for restoring vision in individuals with severe visual impairments by
interfacing directly with the brain's visual cortex
(Figure~\ref{fig:schematic}). Visual cortical prostheses work by converting
visual information from the external environment into neural signals that the
brain can process, effectively bypassing damaged visual pathways. The core
technology involves the generation of phosphenes---perceived spots of light
resulting from electrical stimulation of the visual
cortex~\parencite{vandergrintenBiologicallyPlausiblePhosphene2024}. However,
organizing these phosphenes into coherent and interpretable visual patterns
remains a significant challenge~\parencite{merabetWhatBlindnessCan2005}.

\pagestyle{rest} % Apply rest page style from here

% Schematic figure (Bio-render)
\begin{figure*}[ht!]
      \centering
      \includegraphics[width=0.7\textwidth]{imgs/visual_cortical_prothesis.png}
      \caption{| Functional schematic representation of a visual cortical
            prosthesis. The visual environment is recorded by a wearable camera
            and sent to a (wireless) mobile computer. Electrodes within a brain
            implant are then selectively activated to stimulate neurons in the
            primary visual cortex (V1). By leveraging the retinotopic
            organization of V1, a precise pattern of phosphenes is created,
            forming a coherent representation of the visual
            scene~\parencite{chenShapePerceptionHighchannelcount2020}. (Image:
            BioRender,
            \href{https://app.biorender.com/}{https://app.biorender.com/},
            accessed on 27 May 2024).}\label{fig:schematic}
\end{figure*}

AI has emerged as a pivotal element in enhancing these prosthetic systems. By
leveraging sophisticated algorithms, AI can optimize stimulation patterns to
create more naturalistic visual experiences for
users~\parencite{kriegeskorteDeepNeuralNetworks2015}. AI's role extends to real-time
image processing, allowing the prosthesis to adapt to varying visual
environments and tasks~\parencite{marblestoneIntegrationDeepLearning2016}. This
capability is crucial for developing prosthetic systems that closely mimic
natural vision, providing users with more effective and adaptable solutions. The
integration of AI not only improves the functionality of these devices but also
opens new avenues for innovation in how visual information is processed and
perceived~\parencite{gallettiCorticalConnectionsArea2001}.

This review aims to provide a comprehensive analysis of visual cortical
prostheses, focusing on the role of AI in advancing these prosthetics. It
investigates current technological advancements, particularly in electrode
design, signal processing, and integration. Furthermore, it explores the
optimization of phosphene patterns and real-time image processing facilitated by
AI, comparing visual cortical prostheses with other types of prosthetic devices,
and examining the functional differences between AI-enhanced prosthetic vision
and natural visual processing within the human brain. By examining current
capabilities, identifying limitations, and proposing future research directions,
this work seeks to contribute to the ongoing development of more effective and
user-friendly visual prosthetic systems. Combining technological innovation with
neuroscientific insights has the profound potential to enhance the quality of
life for individuals with visual impairments.

\subsection*{Key Articles}\label{sec:key_articles}
To ground this review, several key articles have been selected that highlight
the current state and advancements in visual cortical prostheses:
\begin{itemize}
      \item Van der Grinten et al. (2024) discuss the simulation of phosphene
            patterns for optimizing visual
            experiences~\parencite{vandergrintenBiologicallyPlausiblePhosphene2024}.
      \item Farnum \& Pelled (2020) review the advancements in microelectronic
            devices and the integration of AI for enhanced visual
            prostheses~\parencite{farnumNewVisionVisual2020}.
      \item Grani et al. (2022) explore closed-loop stimulation strategies for
            real-time adjustments in visual
            prostheses~\parencite{graniPersonalizedClosedloopStimulation2022}.
\end{itemize}

\section*{Technological Advances}\label{sec:tech_advances}
Recent years have seen significant progress in the development of visual
cortical prostheses, driven by advancements in both hardware and software
systems. These innovations are pivotal in enhancing the functionality,
efficiency, and user experience of these devices. For an overview of the
advances see table~\ref{fig:advances_vcp}.

\subsection*{Advancements in Biomaterials and Electrode Design}
One major area of advancement is in electrode design and fabrication.
Traditional electrodes have been limited by issues such as biocompatibility,
stability, and the ability to generate precise neural stimulation. Recent
studies have introduced novel materials and fabrication techniques that
significantly improve these aspects.


\subsubsection*{Conductive Polymers}
The development of flexible and biocompatible electrodes allows for better
integration with neural tissue, reducing the risk of damage and increasing the
longevity of the implants. These polymers are especially useful for flexible 3D
microneedle electrode arrays and are able to support mesh substrate layers that
can support the curvature of various brain
tissue~\parencite{xiangFlexibleThreedimensionalElectrode2016}. Conductive
polymers have been instrumental in advancing the design and functionality of
these electrodes.

One notable conductive polymer is PEDOT:PSS (poly (3,4-ethylenedioxythiophene)
polystyrene sulfonate), which has been widely used due to its excellent
electrical conductivity, flexibility, and biocompatibility. PEDOT:PSS coatings
on electrodes improve signal transduction and reduce impedance, which enhances
the quality of neural recordings and
stimulation~\parencite{rivnayHighperformanceTransistorsBioelectronics2015}.
Additionally, PEDOT exhibits remarkable stability in physiological environments,
ensuring long-term functionality of neural interfaces. Its ability to form thin,
conformal coatings on complex surfaces allows for seamless integration with
neural tissue, minimizing tissue damage and inflammatory
responses~\parencite{zhangRecentProgressPEDOTbased2022}.

Another significant advancement is the use of polyaniline (PANI), a conductive
polymer known for its tunable conductivity. PANI can be
chemically modified to optimize its electrical properties, making it suitable
for long-term neural interfacing applications. Its use in electrode design has
shown promising results in maintaining stable performance over extended periods
using a silicone matrix~\parencite{almuflehHighlyFlexiblePolyanilineBased2021}.
While PANI electrodes are cheaper to fabricate than PEDOT:PSS, their
biocompatibility and rigidity while implanted are still areas of investigation.
However, this polymer shows promise for future applications using graphene
composites~\parencite{liuBiocompatibleHighPerformanceWetAdhesive2021,fangBiocompatibleElectrodeExoelectrogens2024}.

Polypyrrole (PPy) is another conductive polymer that has been extensively
studied for neural applications. PPy-based electrodes offer a unique combination
of electrical conductivity and mechanical properties that facilitate close
contact with neural tissue. Additionally, PPy can be doped with various
bioactive molecules, such as neurotrophic factors (NGF/BDNF/GDNF) or Heparin to
promote tissue integration and reduce inflammatory
responses~\parencite{zareElectroconductiveMultifunctionalPolypyrrole2021a}.

\subsubsection*{Nanotechnology}
Advances in microfabrication have enabled the creation of high-density electrode
arrays that can stimulate the visual cortex with greater precision, offering the
potential for more detailed and coherent visual
experiences, whilst minimizing adverse effects such as inflammation which causes
glial scarring and encapsulation of electrodes~\parencite{ryuSpatiallyConfinedResponses2020}.

Nanotechnology has introduced several innovative approaches to enhance the
performance and integration of electrodes in visual cortical prostheses. One
such approach is the use of carbon nanotubes (CNTs), which possess exceptional
electrical conductivity and mechanical strength. CNTs can be incorporated into
3D scaffold electrode designs to improve signal transmission and reduce
impedance, thereby enhancing the quality of neural
stimulation~\parencite{alegretThreeDimensionalConductiveScaffolds2018}.
Additionally, these nanotubes can be interfaced with conductive polymers like
PPY to create conjugated polymers that combine the benefits of both to reduce
gliosis, improve adaptability and increase charge-transfer
efficiency~\parencite{sharCarbonNanotubeNanocomposite2023}.

Another promising implementation is the use of graphene, a fairly new
two-dimensional material known for its outstanding electrical and thermal
properties. Graphene-based electrodes, due to their thinness, are incredibly
flexible and highly conductive with a huge surface area. These characteristics
are crucial for long-term implantation and stable neural interfaces.
Furthermore, graphene has proven biocompatibility in multiple biological
scaffolding
applications~\parencite{liThreedimensionalGrapheneFoam2013,sahniBiocompatibilityPristineGraphene2013}.
Thus, graphene could be a unique material that bridges modern requirements of
electronics, biology and
optics~\parencite{luGraphenebasedNeurotechnologiesAdvanced2018}.

Lastly, gold nanostructures have been utilized to enhance electrode performance.
Gold nanostructures refer to nanoscale particles or architectures made of gold,
typically with dimensions ranging from 1 to 100 nanometers. These structures can
take various forms, such as spheres, rods, shells, cages, wires and stars. Gold
nanoparticles and nanowires can be used to modify the surface of electrodes,
increasing their surface area and improving their electrical properties. This
modification can lead to more efficient charge transfer and lower stimulation
thresholds~\parencite{zareGoldNanostructuresSynthesis2022}. The ability to
control the size, shape and surface chemistry can allow for a variety of
different physicochemical properties that are necessary for specific
applications. In combination with graphene, gold nanostructures can be utilized
to provide biosensor functionality in addition to neural stimulation, allowing
for the possibility of also recording neural
activity~\parencite{raufGoldNanostructuredLaserscribed2021}.

\subsubsection*{3D Printing}
3D printing technology has allowed for unparalleled precision and
customization capabilities, allowing for the creation of complex and highly
detailed electrode arrays that can be tailored to the unique anatomical features
of individual patients~\parencite{guoImplantableLiquidMetalbased2017}.

This technology enables the production of electrodes that conform to the
specific geometry of the cortical surface, improving contact and integration
with neural tissue, thereby enhancing the accuracy of neural stimulation and
minimizing potential damage to surrounding
tissues~\parencite{liuSoftElasticHydrogelbased2019}. Advances in 3D printing
materials, including biocompatible and conductive inks, have improved the
performance and longevity of printed electrodes, providing the necessary
electrical properties while maintaining compatibility with neural tissue.

Additionally, the ability to rapidly prototype and produce electrodes using 3D
printing reduces manufacturing time and cost, facilitating quicker iterations
and refinements in electrode design, which accelerates the development
process~\parencite{zhangClimbinginspiredTwiningElectrodes2019}.

The combination of conductive polymers, nanotechnology, and 3D printing allows
for the creation of more densely packed electrode arrays that do not incur as
many issues with the surrounding tissue, while also providing a more stable and
reliable hardware base for the complex demands of prosthetic vision devices and
the software that utilizes them.

\subsection*{Improved Signal Processing and Integration}
Advances in signal processing and integration enhance the performance and
functionality of software that orchestrate the formation of phosphene patterns
in higher resolutions. This is supported by high-resolution imaging techniques
and sophisticated signal processing algorithms that have significantly improved
the precision and reliability of implants while also evaluating their functionality.

\subsubsection*{High-Resolution Imaging}
High-resolution imaging techniques provide detailed maps of the brain's cortical
structures. These techniques allow for more precise placement and targeting of
electrodes, which is essential for effective neural stimulation and helps
prevent unnecessary damage to surrounding tissue. As the amount of electrodes
increases, the need for more precise placement becomes more important to ensure
that the electrodes are stimulating the correct regions of the visual cortex.

Functional Magnetic Resonance Imaging (fMRI) is one such high-resolution imaging
technique that provides high-resolution images of
brain activity by detecting changes associated with blood flow. This imaging
technique is valuable for mapping functional areas of the brain, ensuring that
electrodes are placed in regions that will yield the most beneficial outcomes
for the user~\parencite{landelleInvestigatingHumanSpinal2021}.

Two-photon microscopy allows for deep imaging of living brain tissue with high
spatial resolution. This technique is particularly useful for observing the
interactions between electrodes and neural tissue over time, providing insights
that can guide the design and optimization of electrode
arrays~\parencite{yangIntegratedMicroprismMicroelectrode2024}.

Furthermore, the development of near-infrared light compatible (NIR-II)
semiconducting polymers has enhanced in vivo high-resolution imaging
capabilities. These polymers offer excellent penetration depth and spatial
resolution using near-infrared window imaging, which are critical for accurate
diagnostics and possible therapeutic applications in neural
prosthetics~\parencite{wangRecentProgressSecond2023,kangNIRIISemiconductingPolymers2023}.

Deep learning techniques have also been employed to enhance the resolution of
confocal fluorescence microscopy. By using generative models, these techniques
improve the learning ability of imaging systems in the frequency domain,
resulting in significantly higher resolution images that are essential for
detailed neural mapping~\parencite{huangEnhancingImageResolution2023}. Some of
the types of deep learning models are elaborated in the next section on how AI
is integrated into visual prostheses.

These high-resolution imaging techniques are integral to the development of more
precise and effective visual cortical prostheses, facilitating better
integration and performance of these devices. In the future these techniques may
allow for real-time monitoring of neural activity through the use of
fluorescence with significant penetration depth into the brain. Thus, these
could allowing more downstream stimulation while tracking the effects of the
implant.

\subsubsection*{Wireless Communication}
Additionally, innovations in wireless technology have enabled the development of
untethered wearable prostheses. Wireless systems eliminate the need for external
wires, which not only improves the comfort and aesthetics of the prostheses but
also reduces the risk of infections and mechanical
failures~\parencite{bruntonOptimisingElectrodeSurface2013}. Advancements in
wireless power transfer and data communication have made it possible to deliver
sufficient power and high-fidelity signals to the implants, ensuring reliable
and efficient operation.

Modern wireless devices, such as the \textit{Gennaris} array described
by~\textcite{rosenfeldTissueResponseChronically2020}, incorporate all necessary
electronics within the implant. This system includes a wireless receiver and an
Application Specific Integrated Circuit (ASIC) encased in a ceramic capsule,
allowing for independent control and power for multiple arrays implanted into
the visual cortex. This design simplifies surgical procedures and reduces trauma
to major cortical blood vessels~\parencite{polikovResponseBrainTissue2005}.

Recent advancements include the development of biphasic quasistatic brain
communication (BP-QBC), a technique that significantly reduces power consumption
while maintaining high data transfer rates. This method leverages
electro-quasistatic signaling to create a low-power, broadband communication
channel between wireless neural implants and external devices, offering a
promising solution for energy-efficient and high-speed data transmission in
neural prosthetics~\parencite{chatterjeeBiphasicQuasistaticBrain2023}.

These advancements in wireless communication technology are crucial in order to
provide a more seamless and reliable neural interface.

\subsection*{Software and Algorithmic Enhancements}
On the software side, the integration of artificial intelligence (AI) has
revolutionized the way visual information is processed and interpreted by
prosthetic systems. AI algorithms, particularly those based on deep learning,
have been employed to optimize stimulation patterns and enhance image processing
capabilities. These algorithms can learn from vast amounts of data to improve
the accuracy and efficiency of visual signal conversion, making the visual
experiences more naturalistic and adaptable to different
environments~\parencite{romeniMachineLearningFramework2021}.

\subsubsection*{Real-Time Data Processing}
Real-time data processing is pivotal for the functionality of a complex
prosthesis that has to generate accurate representations of an environment,
especially while a user is moving. Translation of visual information from the
external environment into neural signals has to be seamless so that they can be
interpreted by the brain's visual cortex.

A key aspect of real-time data processing involves the integration of high-speed
computing systems capable of handling large volumes of visual data with minimal
latency~\parencite{nurmikkoChallengesLargeScaleCortical2020}. The processing
pipeline typically includes capturing visual information via cameras,
preprocessing the data to reduce noise and enhance relevant features, and
converting this data into neural stimulation patterns based on the resolution of
the phosphene pattern.

Edge computing plays a crucial role in this pipeline by performing data
processing closer to the data source. This reduces latency and enhances the
responsiveness of the prosthetic system, which is particularly important for
real-time applications such as navigation in dynamic
environments~\parencite{wangDeepLearningEdge2020}. By offloading computational
tasks from centralized servers to local devices, edge computing ensures that
visual data is processed swiftly, enabling immediate feedback to the user.

Another important component is the use of adaptive algorithms in the form of
deep learning models that can dynamically adjust to changes in the visual
environment. These algorithms leverage feedback from the user's interactions
with the prosthetic system to continuously improve accuracy and
effectiveness~\parencite{pio-lopezVisualCorticalProsthesis2021b}. For example,
real-time adjustments can be made to the stimulation patterns based on
environmental factors such as lighting conditions and the presence of moving
objects, ensuring that the visual output remains consistent and
coherent~\parencite{fylstraHumanprosthesisCooperationCombining2022}.

Additionally, advancements in sensor technology have significantly contributed
to real-time data processing capabilities. High-resolution cameras and depth
sensors provide detailed visual information, which is essential for generating
precise and informative neural signals. These sensors can capture a wide range
of visual cues, including color, depth, and motion, which are then processed to
create a comprehensive visual experience for the
user~\parencite{rueckauerExperiencingProstheticVision2022}.

Real-time data processing also benefits from the constantly improving development of specialized
hardware accelerators, such as Graphics Processing Units (GPUs) and Field
Programmable Gate Arrays
(FPGAs)~\parencite{springerOnDeviceDeepLearning2021,fengDesignOnlineBrainComputer2020}.
These devices are optimized for parallel processing tasks and can handle the
intensive computational demands of real-time visual data processing. By
utilizing these hardware accelerators, visual cortical prostheses can achieve
the necessary processing speeds to provide immediate and accurate visual
feedback.

In summary, real-time data processing in visual cortical prostheses involves a
combination of high-speed computing, edge computing, adaptive algorithms,
advanced sensors, and specialized hardware accelerators. These systems work
together to ensure that visual information is processed and transmitted to the
brain without noticeable delays, creating a natural and effective visual
experience for users. This seamless integration of hardware and software
components is crucial for the ongoing development and enhancement of visual
prosthetic systems.

% Add the summary box at the end of the Technological Advances section
\begin{figure*}[ht!]
      \begin{tcolorbox}[
                  title=Technological Advances in Visual Cortical Prostheses,
                  colframe=gray!30, % Border color
                  colback=gray!20, % Background color
                  coltitle=white, % Title color
                  colbacktitle=gray!50, % Title background color
                  fonttitle=\bfseries,
                  sharp corners=all,
                  width=\textwidth,
                  boxrule=1.5pt % Border width
            ]
            \fontsize{8pt}{10pt}\selectfont % Set the font size directly
            \begin{itemize}
                  \item \textbf{Advancements in Biomaterials and Electrode Design}
                        \begin{itemize}
                              \item \textbf{Conductive Polymers:} PEDOT:PSS, Polyaniline (PANI), Polypyrrole (PPy)
                              \item \textbf{Nanotechnology:} Carbon Nanotubes (CNTs), Graphene, Gold Nanostructures
                              \item \textbf{3D Printing:} Customizable and high-precision electrode arrays
                        \end{itemize}

                  \item \textbf{Improved Signal Processing and Integration}
                        \begin{itemize}
                              \item \textbf{High-Resolution Imaging:} Functional Magnetic Resonance Imaging (fMRI), Two-photon microscopy, NIR-II semiconducting polymers
                              \item \textbf{Wireless Communication:} Biphasic Quasistatic Brain Communication (BP-QBC)
                        \end{itemize}

                  \item \textbf{Software and Algorithmic Enhancements}
                        \begin{itemize}
                              \item \textbf{Real-Time Data Processing:} Edge computing, adaptive algorithms, advanced sensors, hardware accelerators (GPUs and FPGAs)
                        \end{itemize}

                  \item \textbf{Other Functional Improvements}
                        \begin{itemize}
                              \item \textbf{Closed-Loop Feedback Systems:} Dynamic adjustment of stimulation parameters
                              \item \textbf{Multi-Modal Sensory Integration:} Incorporation of auditory and tactile feedback
                        \end{itemize}
            \end{itemize}
      \end{tcolorbox}
      \caption{| Summary of key technological advancements in the development of
            visual cortical prostheses, highlighting improvements in biomaterials,
            signal processing, software, and functional
            integration.}\label{fig:advances_vcp}
\end{figure*}

\subsection*{Other Functional Improvements}
\subsubsection*{Closed-Loop Feedback Systems}
Another significant advancement is the implementation of closed-loop systems in
visual cortical prostheses. These systems continuously monitor neural feedback
to adjust stimulation parameters in real-time, thereby enhancing the precision
and effectiveness of visual restoration. Closed-loop systems mimic the natural
feedback mechanisms of the human visual system, providing a more responsive and
user-friendly experience. Recent research has demonstrated the efficacy of these
systems in improving the visual outcomes for users, as they can dynamically
adapt to changes in the environment and the user's neural
responses~\parencite{leviEditorialClosedLoopSystems2018}.

\subsubsection*{Multi-Modal Sensory Integration}
The integration of multi-modal sensory input is another promising development in
this field. By incorporating inputs from other senses, such as auditory or
tactile feedback, visual cortical prostheses can provide a more holistic sensory
experience. This multi-modal approach leverages the brain's ability to integrate
information from different sensory modalities, potentially enhancing the overall
perceptual experience and aiding in the interpretation of visual
scenes~\parencite{wanArtificialSensoryNeuron2020}.

\section*{AI Integration}\label{sec:ai_integration}
The integration of AI in visual prosthesis systems is focused on how deep
learning algorithms enhance visual data processing, optimize phosphene patterns,
and emulate normal brain processing. Figure~\ref{fig:simulator_framework}
provides an overview of a Visual Prosthesis Simulation Framework based on the
work by~\textcite{deruytervansteveninckEndtoendOptimizationProsthetic2022}. This
framework employs AI to simulate and predict how users perceive visual
information through a prosthetic device. By integrating deep learning
algorithms, the system can accurately replicate and enhance visual experiences.

The functional process of a visual cortical prosthesis in this framework is an
end-to-end process that includes three main components: an encoder, a phosphene
simulator, and a decoder. The encoder processes the input image to generate a
stimulation protocol, which determines the intensity of stimulation for each
electrode. The phosphene simulator translates this protocol into a simulated
phosphene vision (SPV) representation, incorporating factors like distortions in
phosphene positions and brightness variations. Finally, the decoder reconstructs
the input image from the SPV representation, ensuring accurate interpretation of
the encoded information.

Optimization is a critical aspect, involving automated and tailored adjustments
to achieve the best visual reconstruction. Task-specific optimization is
implemented by using different loss functions, guiding the network to preserve
relevant information. Constraints such as sparsity can be incorporated to
minimize adverse effects of electrical stimulation. The modular design allows
the system to adapt to practical, medical, or biophysical limitations. Some
designs, such as the one
by~\textcite{deruytervansteveninckEndtoendOptimizationProsthetic2022}, have been
made open-source to facilitate collaboration and further development.

% Diagram figure (inkscape)
\begin{figure*}[ht!]
      \centering
      \includegraphics[width=0.6\textwidth]{imgs/block_diagram_vis_prost.png}
      \caption{| Overview of a Visual Prosthesis Simulation Framework. The
            simulator is initialized with electrode locations on a visuotopic
            map of the visual cortex (V1), representing the spatial organization
            of the visual field. For each frame, it processes stimulation
            parameters such as amplitude, pulse width, and frequency for each
            electrode. Using these parameters and electrode locations, it
            estimates phosphene characteristics, which are rendered on a visual
            field map considering cortical magnification and activation
            thresholds. Individual phosphene renderings are summed to produce
            the simulated prosthetic percept. Temporal dynamics, including
            delayed onset and offset of perception, are modeled using a leaky
            integrator. The simulator's modular and open-source design,
            implemented in Python with PyTorch for example, allows for fast GPU
            computations and easy integration with external
            software~\parencite{deruytervansteveninckEndtoendOptimizationProsthetic2022}.
            It is validated through computational and behavioral experiments,
            incorporating neurophysiological and clinical findings to ensure
            biological plausibility.}\label{fig:simulator_framework}
\end{figure*}

\subsection*{Deep Learning Algorithms in Prosthetic Vision}
An innovative approach is the use of feed-forward neural networks to improve the
control of brain-machine interfaces. This simpler neural network architecture
enhances the speed and accuracy of prosthetic control by more closely mimicking
the natural communication pathways between the brain and the body. Such improves
the functionality of prosthetic devices and enhance their usability for
individuals with paralysis or limb
loss~\parencite{willseyRealtimeBrainmachineInterface2022}. However, these
``simpler'' networks are not suitable for more complex image generation tasks
and require on-the-fly learning capability. This is where more sophisticated so
called deep learning models come into play, a model that learns to perform
classification or regression tasks directly from (image) data.

So why are AI algorithms essential for the development of prosthetic vision?
These algorithmic models are in principle, designed as solutions to low sampling
resolution. The optimization of phosphene patterns are an area that benefits
significantly from preprocessing optimizations of image quality. An example of a
spiking neural network is the NeoCube architecture for obstacle-avoidance
by~\textcite{guoOptimizationVisualInformation2018}. This architecture is a prime
example of how an AI system can enhance the user experience by adding increased
stability and accuracy to the prosthetic system, without the addition of
additional hardware.

Deep learning models are different kinds of neural networks that are used to
predict and interpret visual inputs without providing environmental context.
This is known as saliency mapping, which is an important technique used in deep
learning to identify and visualize the regions of an input that most
significantly influence the model's predictions. Within the deep learning domain
there are however several types of neural networks that are used to enhance the
capabilities of models in different ways.

Various types of neural networks exist, including Convolutional Neural Networks
(CNNs) for image recognition, Recurrent Neural Networks (RNNs) for temporal data
processing, Generative Adversarial Networks (GANs) for generating realistic
visual patterns, and Graph Neural Networks (GNNs) for understanding complex
spatial relationships, that collectively enhance capabilities in image
translation, object recognition, and scene interpretation. These key deep
learning algorithms are crucial in predictive modeling, with each contributing
uniquely to improving the functionality and performance of visual cortical
prostheses. A comparison of these algorithms in prosthetic vision systems is
provided in Table~\ref{tab:dl_algorithms_prosthetic_vision}.

\subsubsection*{Predictive Modeling}
Predictive modeling plays a crucial role in prosthetic vision by leveraging
various deep learning algorithms to enhance visual perception for users. These
models are designed to predict and interpret visual inputs, creating a seamless
and coherent visual experience. By utilizing large datasets and advanced neural
network architectures, predictive modeling enables the prosthetic system to
anticipate and adapt to dynamic visual environments. Aforementioned key deep
learning algorithms are employed in predictive modeling, these include CNNs,
RNNs, GANs, and Multidimensional GNNs. While not all of these model types have
been explicitly used in visual prosthetics yet, they have significant potential
to enhance the capabilities of these systems.

\begin{table*}[ht!]
      \centering
      \fontsize{8pt}{10pt}\selectfont
      \caption{| Comparison of Different Deep Learning Algorithms in Prosthetic Vision Systems}\label{tab:dl_algorithms_prosthetic_vision}
      \begin{tabularx}{\textwidth}{|X|X|X|X|X|}
            \hline
            \textbf{Algorithm}                                                                                                                                                                           & \textbf{Input} & \textbf{Processing} & \textbf{Output} & \textbf{Benefits} \\ \hline

            \textbf{Convolutional Neural Networks (CNNs)}                                                                                                                                                &
            Receives raw sensory data from the external world, possibly through a camera or other sensors.                                                                                               &
            Extracts relevant features (edges, textures, shapes) and identifies objects in the scene.                                                                                                    &
            Generates a pattern of phosphenes that correspond to recognized objects, translating into a simplified image with phosphene ``dots'' representing different objects or regions of the scene. &
            Excels at recognizing objects and spatial relationships. Provides
            basic visual information like identifying objects, their locations,
            and general scene understanding.\
            \\ \hline

            \textbf{Recurrent Neural Networks (RNNs)}                                                                                                                                                    &
            Receives continuous streams of data from the CNN, representing the changing visual scene.                                                                                                    &
            Maintains temporal continuity and tracks moving objects.                                                                                                                                     &
            Modifies the phosphenes to reflect the movement of objects, allowing the user to perceive dynamic aspects of the world.                                                                      &
            Allows for smooth tracking of movement and prediction of future
            events. Crucial for perceiving the world as a dynamic environment
            rather than a static snapshot.\
            \\ \hline

            \textbf{Generative Adversarial Networks (GANs)}                                                                                                                                              &
            Trained on large datasets of real-world images.                                                                                                                                              &
            Learns to generate realistic and diverse phosphenes resembling actual visual patterns.                                                                                                       &
            Produces highly realistic phosphenes for displaying processed visual information.                                                                                                            &
            Enhances perception by creating natural and vivid visual
            experiences. Generates realistic phosphenes resembling natural light
            patterns, making prosthetic vision less ``artificial''.\
            \\ \hline

            \textbf{Multidimensional Graph Neural Networks (GNNs)}                                                                                                                                       &
            Receives spatial information from the CNN, representing relationships between objects in the scene.                                                                                          &
            Analyzes spatial relationships, understanding context of visual input.                                                                                                                       &
            Modifies phosphenes to represent objects and their spatial arrangement and potential interactions.                                                                                           &
            Enhances spatial awareness and navigation. Understands complex
            relationships between objects.\
            \\ \hline

            \multicolumn{5}{|p{\dimexpr\textwidth-2\tabcolsep}|}{
            \textbf{How These Algorithms Can Work Together:}\newline
            \textbf{CNN:} Acts as the core object recognition system, identifying objects and basic scene features.\newline
            \textbf{RNN:} Adds temporal information, allowing the user to perceive movement and changes in the scene.\newline
            \textbf{GAN:} Ensures that the output phosphenes are realistic and visually appealing.\newline
            \textbf{GNN:} Adds a deeper level of understanding by representing spatial relationships between objects.
            }                                                                                                                                                                                                                                                                         \\ \hline
      \end{tabularx}
\end{table*}

\subsubsection*{Convolutional Neural Networks (CNNs)}
CNNs are employed to process and classify visual inputs, enhancing the ability
of the prosthetic system to interpret complex visual scenes and improve object
recognition capabilities. CNNs are particularly effective at identifying spatial
hierarchies in images through layers of convolutions that capture features like
edges, textures, and shapes. By training on large datasets, CNNs learn to
recognize a wide range of objects and scenes, enabling the prosthetic system to
provide users with detailed and accurate visual
information~\parencite{petrosyanDecodingInterpretingCortical2021a}. This
improves the user's ability to navigate and interact with their environment by
providing clearer and more recognizable visual
cues~\parencite{maheswaranathanInterpretingRetinalNeural2023}. An example of
such a system was used in one of the key articles by
\textcite{deruytervansteveninckRealworldIndoorMobility2022}, where they used
SharpNet predictions to create a surface boundary mask. SharpNet is a CNN-based
model that allows for estimation of depth and surface normals, which is
essential for the formation of meaningful phosphene vision patterns.

\subsubsection*{Recurrent Neural Networks (RNNs)}
RNNs, including LSTM (Long Short-Term Memory) networks, are used to handle
sequential data, making it possible to maintain temporal continuity in visual
perception and improve the user's ability to track moving objects. Unlike CNNs,
which focus on spatial relationships, RNNs excel at processing temporal
sequences. They retain information over time, allowing them to predict future
frames based on past visual data. This capability is essential for maintaining a
continuous and stable visual experience, especially when tracking dynamic scenes
or moving objects, thereby enhancing the user's perception of motion and
improving their ability to react to changes in their
environment~\parencite{nayebiRecurrentConnectionsPrimate2022,
      liaoBridgingGapsResidual2016}. RRNs in the form of LSTMs have been explored for
the use of special conditions such as low-light environments, by enhancing the
visual inputs and provide greater image
clarity~\parencite{renLowLightImageEnhancement2019}. In addition, these same
specific networks show excellent performance in gesture recognition~\parencite{nguyen-trongGestureRecognitionUsing2021}, which is an
important aspect of human interaction which can be facilitated via a prosthetic.

\subsubsection*{Generative Adversarial Networks (GANs)}
GANs can be utilized to generate realistic phosphene patterns by training on
large datasets of visual scenes, improving the fidelity and natural appearance
of the visual output. A GAN consists of two neural networks, a generator and a
discriminator, which are trained together in a competitive process. The
generator creates synthetic images that the discriminator attempts to
distinguish from real images~\parencite{ledigPhotoRealisticSingleImage2017}.
Through this adversarial training, GANs learn to produce high-quality, realistic
images that can be used to simulate phosphenes—patterns of light perceived by
the visual
cortex~\parencite{goodfellowGenerativeAdversarialNetworks2020,elnabawyPVGANGenerativeAdversarial2022}.
This enhances the naturalness and coherence of the visual scenes presented to
the user, making the prosthetic vision more similar to natural sight.

\subsubsection*{Multidimensional Graph Neural Networks (GNNs)}
GNNs are leveraged to model and interpret complex relationships within
multidimensional data, enhancing the system's ability to understand and process
spatial and relational information. GNNs extend traditional neural networks by
operating on graph-structured data, which can represent the spatial
relationships between objects in a scene. This allows the prosthetic system to
better understand the context and interactions within the visual input. By
capturing these intricate relationships, GNNs improve the prosthetic's ability
to recognize patterns, structures, and spatial hierarchies, leading to more
accurate and context-aware visual perception. This is particularly useful in
complex environments where understanding the spatial arrangement of objects is
crucial for navigation and
interaction~\parencite{subramanianGraphConvolutionalNetworks2020,wuComprehensiveSurveyGraph2021}.

Moreover, multidimensional GNNs have been employed to optimize wireless
communication policies in neural prosthetics. These networks use graph-based
representations to manage complex data transmission scenarios, improving the
efficiency and reliability of wireless communication between implants and
external devices~\parencite{liuMultidimensionalGraphNeural2024}.

In the future, these algorithms will have to be combined to create a
comprehensive AI system that can process and interpret all the varied visual
stimuli that a user may encounter and adapt their relative parameters in real
time to recreate a faithful representation of the environment.

\section*{Comparison with Other Visual Prosthetic Systems}\label{sec:comparison}
Cortical prosthetics present a distinct and innovative method for restoring
vision, setting them apart from earlier retinal and optic nerve implants.
Devices such as the PRIMA and IRIS systems by Pixium-Vision, as well as the
FDA-approved Orion and ARGUS II by Second Sight Medical Products Inc, have
demonstrated their effectiveness. The PRIMA and IRIS systems focus on subretinal
and epiretinal placements, respectively, to stimulate remaining retinal cells,
making them suitable for specific retinal degenerative
conditions~\parencites{muqitProstheticVisualAcuity2023,hoLongTermResultsEpiretinal2015}.
A comparison of cortical, retinal, and optic nerve prostheses is provided in
Table~\ref{tab:prostheses_comparison}.

In contrast, the Intracortical Visual Prosthesis (ICVP) and the Utah Electrode Array exemplify advancements in cortical prostheses. The ICVP uses microelectrode arrays implanted in the visual cortex to provide visual information to blind individuals, offering fine-grained control over neural activation~\parencite{troykIntracorticalVisualProsthesis2005}. The Utah Electrode Array employs high-density microelectrodes to evoke visual perceptions by stimulating the visual cortex directly, allowing for the creation of more complex visual patterns~\parencite{normannClinicalApplicationsPenetrating2016}.

These cortical prostheses are uniquely advantageous due to their ability to bypass both retinal and optic nerve impairments and stimulate the visual cortex directly. This downstream positioning is particularly beneficial for individuals with severe visual impairment where other prostheses are ineffective. Additionally, cortical implants offer the longest therapeutic intervention window, leveraging compensatory plasticity mechanisms that recruit neurons from other cortical regions. This enables effective stimulation and rehabilitation long after the onset of injury or disease, significantly enhancing their rehabilitative potential~\parencite{tzekovGabelEdArtificial2020, beyelerLearningSeeAgain2017}.

\begin{table*}[ht!]
      \centering
      \fontsize{8pt}{10pt}\selectfont
      \caption{| Comparison of Cortical, Retinal, and Optic Nerve Prostheses}\label{tab:prostheses_comparison}
      \begin{tabularx}{\textwidth}{X X X X}
            \hline
            \textbf{Feature}                             & \textbf{Cortical Prostheses}                                                        & \textbf{Retinal Prostheses}                                                    & \textbf{Optic Nerve Prostheses}                                 \\ \hline
            \textbf{Target Area}                         & Visual cortex                                                                       & Retina                                                                         & Optic nerve                                                     \\ \hline
            \textbf{Surgical \newline Invasiveness}      & Highly invasive (brain surgery)                                                     & Moderately invasive (eye surgery)                                              & Moderately invasive (requires access to the optic nerve)        \\ \hline
            \textbf{Applicability}                       & Suitable for severe visual impairment with retinal or optic nerve damage            & Best for retinal degenerative diseases with some functional retinal cells      & Suitable for optic nerve damage with functional retinal cells   \\ \hline
            \textbf{Mechanism}                           & Direct stimulation of the visual cortex                                             & Stimulation of remaining functional retinal cells                              & Stimulation of the optic nerve fibers                           \\ \hline
            \textbf{Therapeutic \newline Window}         & Longest, can be effective long after onset of blindness                             & Requires some residual retinal function                                        & Depends on the extent of optic nerve damage                     \\ \hline
            \textbf{Technological \newline Complexity}   & High (phosphene organization and neural plasticity)                                 & Moderate (retinal cell stimulation)                                            & High (complexity in targeting optic nerve fibers)               \\ \hline
            \textbf{Advantages}                          & Broad applicability, effective for extensive damage, leverages cortical plasticity  & Less invasive, established success in specific diseases, direct visual pathway & Can target optic nerve damage directly, bypasses retinal issues \\ \hline
            \textbf{Disadvantages}                       & Highly invasive
            surgery, complex visual pattern organization &
            Limited to retinal functionality, less effective with severe damage
                                                         & Invasive, technical challenges in precise nerve stimulation                                                                                                                                                                            \\
            \hline
            \textbf{Example Devices}                     & Orion (Second Sight), ICVP (Illinois Institute of Technology), Utah Electrode Array & Argus II (Second Sight), Alpha IMS (Retina Implant AG), PRIMA (Pixium-Vision)  & Epi-Ret3, Experimental Optic Nerve Stimulation Systems          \\ \hline
      \end{tabularx}
\end{table*}

\subsection*{Comparison with Retinal Prostheses}
Retinal prostheses, such as the Argus II and the Alpha IMS, focus on stimulating the remaining functional cells within the retina to restore vision. These devices provide visual perception to individuals with retinal degenerative diseases, such as retinitis pigmentosa. The Argus II, for example, employs an epiretinal approach, placing electrodes on the surface of the retina to evoke visual sensations. The Alpha IMS, on the other hand, uses a subretinal approach, inserting the implant beneath the retina to directly stimulate photoreceptor cells~\parencite{stinglArtificialVisionWirelessly2013}.

While retinal prostheses have demonstrated significant success in patients with some remaining retinal function, their applicability is limited for those with extensive retinal damage or complete retinal degeneration. In contrast, cortical prostheses offer a broader applicability by bypassing the damaged retinal cells and directly stimulating the visual cortex. This capability allows cortical prostheses to be effective even in cases where retinal prostheses are not viable. Furthermore, the position of cortical implants downstream in the visual pathway leverages the brain's plasticity, potentially offering a longer therapeutic window and enabling rehabilitation well beyond the onset of retinal degeneration~\parencite{tzekovGabelEdArtificial2020}.

\subsection*{Comparison with Optic Nerve Prostheses}
Optic nerve prostheses, such as the Epi-Ret3 device and other experimental optic nerve stimulation (ONS) systems, aim to stimulate the optic nerve fibers directly. These devices are particularly beneficial for patients with optic nerve damage, allowing for the bypass of retinal issues. However, the technological complexity involved in precisely targeting optic nerve fibers and the invasive nature of the implantation procedure present significant challenges. The Epi-Ret3 device, for example, has shown potential in preliminary studies but requires highly precise stimulation to be effective~\parencite{trieuImplantsEpiretinalStimulation2009}.

In comparison, cortical prostheses, such as the Orion Visual Cortical Prosthesis
and the Intracortical Visual Prosthesis (ICVP), offer distinct advantages by
bypassing both the retina and optic nerve. This direct stimulation of the visual
cortex enables broader applicability for a wide range of visual impairments,
including those resulting from severe optic nerve damage. Additionally, cortical
implants benefit from the brain's compensatory plasticity mechanisms, allowing
for effective stimulation and visual rehabilitation long after the onset of
injury or disease. This extended therapeutic window, coupled with the ability to
leverage cortical plasticity, underscores the substantial rehabilitative
potential of cortical prostheses for individuals who are blind or visually
impaired~\parencite{beyelerLearningSeeAgain2017}.

\subsection*{Comparison with Natural Vision}
The PRIMA system, as demonstrated in the study
by~\textcite{palankerSimultaneousPerceptionProsthetic2022}, represents a
significant technological advancement in visual prosthetics, providing a means
to restore central vision in patients with geographic atrophy due to age-related
macular degeneration. Unlike natural vision, which relies on the complex and
highly efficient biological processes of the retina and visual cortex, the PRIMA
system uses a subretinal implant to convert images projected from video glasses
into electrical signals that stimulate the remaining inner retinal neurons. This
artificial method of vision restoration, while impressive, results in visual
acuity levels that are still substantially lower than those achieved through
natural vision. For example, the best prosthetic acuity achieved in the study
was 20/460, compared to the near-perfect acuity of 20/20 in natural vision.

Natural vision benefits from the intricate network of photoreceptors, bipolar
cells, and ganglion cells within the retina, which work in concert to process
visual information with high spatial and temporal resolution. The PRIMA system,
on the other hand, must rely on the brain's plasticity and the ability to adapt
to and interpret the new, less refined visual signals in the form of phosphenes
generated by the implant. While the study showed that patients could achieve
functional vision with the PRIMA system, including the ability to recognize
letters and basic shapes, this prosthetic vision is limited by the current
technology's pixel density and the spatial resolution it can provide.
Nonetheless, systems like PRIMA offer a crucial alternative for individuals who
have lost their natural vision.

\section*{Limitations and Challenges}\label{sec:limitations}
\subsection*{Quality of Prosthetic Vision}
Cortical prosthesis systems, while showing great promise for several types of
blind
individuals~\parencite{deruytervansteveninckRealworldIndoorMobility2022,deruytervansteveninckEndtoendOptimizationProsthetic2022,kucukogluOptimizationNeuroprostheticVision2022},
artificial vision is far from fully functional. The limits of artificial vision
are both due to technological and biological constraints.

\subsubsection*{Field of Vision}
For real-world applicable prosthetic, a wide field of view is essential.
Otherwise the user will have trouble to map and interact with the
environment~\parencite{sugawaraRelationshipPeripheralVisual2010}. Tasks include:
influencing the comprehension of layout space, assessment of walking distance,
performance in identify-and-reach tasks, spatial cognition, and attention.
Numerous studies have emphasized that restoring a large visual field is
essential for artificial vision to be beneficial in daily
life.~\parencite{subhiFunctionalVisualFields2017,sugawaraRelationshipPeripheralVisual2010}.
Current cortical devices have a limited field of view of around 16 degrees of
visual angle~\parencite{vandergrintenBiologicallyPlausiblePhosphene2024}.
Whereas the minimum requirement for sufficient visual information has been
established to be at least 30--35
degrees~\parencite{sommerhalderProspectsLimitationsSpatial2017}. Furthermore,
there it might underestimated that user have to go through rigorous perceptual
adaptation and behavioral training in order to make use of artificial vision.
Realistically, creating a larger field of view for the user is paired with
requiring more implant coverage of the visual cortex, which can lead to possible
neurophysiological side-effects due to riskier surgical incisions that have not
yet been proven to be safe. Additionally, the arrays used have limited space for
extra electrodes, which are already incredibly small and densely packed in Utah
arrays for instance.

\subsubsection*{Spatial Resolution}
In addition to a limited field of view, current devices require significant
improvement in spatial resolution. Practically, this means increasing the number
of distinguishable phosphenes. Although technology exists to create smaller,
higher-density electrodes for greater pixel density, challenges such as
electrode cross-talk and spatial selectivity in neural activation become more
important~\parencite{bordaAdvancesVisualProstheses2022}. Retinal and optic nerve
prostheses have employed solutions such as bipolar stimulation of two adjacent
electrodes, current steering to the desired location, and modulation of current
amplitude to achieve more focused
stimulation~\parencite{yanElectricallyEvokedResponses2016,delbekePositionSizeLuminosity2003}.

It remains difficult to target few neurons without affecting others, which may
lead to distorted or overlapping phosphenes. The challenge here is to find
stimulation parameters that optimally characterize the phosphenes on aspects
such as brightness, size, color and duration. This is a complex optimization
problem where developments in AI provide the most direct road to improvement in
SPV quality. Smarter algorithms that can employ tricks to reduce computational
complexity and increase the speed of the optimization process. An example of
this is contour extraction for object recognition which allows for scene
simplification~\parencite{deruytervansteveninckRealworldIndoorMobility2022}.
Allowing for sufficient visual information to be perceived at various phosphene
(pixel) resolutions without the need for higher density stimulation.

\subsubsection*{Temporal Resolution}
A characterized issue with SPV is phosphene fading, which affects retinal
prostheses such as ARGUS-II and can similarly affect cortical devices is a
phenomenon known as the Troxler effect; where a stationary visual stimulus in
the peripheral vision tends to fade and disappear over time if it remains
unchanged and the observer maintains a steady gaze. This effect occurs because
of neural adaptation in the visual system, where constant stimuli become less
noticeable as neurons reduce their firing rates in response to unchanging input.
This makes perception of flicker fusion of light at stimulation frequencies
higher than 30 Hz
near-impossible~\parencite{perezfornosTemporalPropertiesVisual2012}. This effect
can be reduced in sighted individuals with ocular micromovements such as
tremors, drifts or microsaccades~\parencite{hafedOculomotorBehaviorBlind2016}.
However, with SPV the projected image needs to move across the electrode array
to simulate the sensation of shifted vision and the physiological ocular
movements need to still be possible in the blind to reduce the Troxler
effect~\parencite{moleirinhoImpactSynchronousAsynchronous2021}.

\subsection*{Limitations in Current AI Technology}
Despite significant advancements in AI and advanced processing over the past
decade, several key issues remain unresolved. One primary challenge is the
increased complexity of models required to interpret more intricate visual
scenes. This complexity leads to higher system latency when reconstructing the
scene's spatial visual representation (SPV), posing a problem for real-time
adaptation and mobility. Solutions such as Principal Component Analysis may help
reduce data dimensionality and increase processing speed, but at a cost of
visual detail in the SPV~\parencite{mohammadiEnhancedArtificialVision2023}.

Additionally, more complex deep learning models necessitate larger annotated
datasets for training and benchmarking, which are not always available for
specific tasks. Even when sufficient data is accessible, models must be robust
enough to handle diverse visual scenarios, including varying lighting conditions
and moving objects, which are challenging to simulate accurately in a laboratory
setting~\parencite{yuilleDeepNetsWhat2021}.

\section*{Future Perspectives}\label{sec:future}
Remarkable progress has been made since the advent of the first visual
prosthetic prototypes with even some commercial succes proving the merit of this
incredible technology. The reality however, is that the actual adaptation of an
actual cortical device is still only limited to virtual reality testing via
simulation~\parencite{deruytervansteveninckRealworldIndoorMobility2022}.

\subsection*{Clinical Application}
A caveat is the invasive nature of these still hypothetical cortical devices, is
the required surgical implantation in the brain. The implantation of visual
prostheses, particularly those involving the visual cortex, requires highly
invasive surgical procedures that pose significant risks, including infection,
bleeding, and damage to neural
tissues~\parencite{nurmikkoChallengesLargeScaleCortical2020}. Also the longevity
of the hardware and the safety for users will still take many years to evaluate.
The complexity of these surgeries can limit the widespread adoption of such
systems and make them accessible only in specialized medical centers as was the
case with the ARGUS-II~\parencite{hoLongTermResultsEpiretinal2015}.

Technologically, creating a seamless interface between the prosthesis and the
neural tissue is challenging. The variability in individual neural architecture
means that prosthetic solutions must often be highly customized, which can
increase costs and complicate the development process.

To ensure the long-term efficacy and safety of visual cortical prostheses, it is
imperative to conduct broader and more diverse clinical trials. These trials
should encompass a wide demographic, including various age groups, genders, and
ethnic backgrounds, to determine how different populations respond to the
technology. Such trials will provide comprehensive data on the performance and
reliability of the prostheses over extended periods, identify potential
long-term complications, and help refine surgical techniques and postoperative
care protocols. By addressing these aspects, the medical community can establish
robust guidelines and standards for the safe implementation of these devices.

The variability in neural architecture among individuals necessitates the
development of personalized prosthetic solutions. Customized prostheses that
account for the unique neural and anatomical characteristics of each patient can
significantly enhance the effectiveness and comfort of the devices. Personalized
solutions involve advanced imaging techniques to map the neural landscape,
followed by the creation of bespoke electrode arrays and stimulation protocols.
This approach ensures optimal interfacing with the neural tissue, minimizes
adverse reactions, and improves the overall user experience. While this
customization can be cost-intensive and technologically demanding, it holds the
promise of maximizing the benefits of visual cortical prostheses for each user.

\subsection*{Ethical and Societal Implications}
The development and implementation of advanced neural interfaces raise several
ethical concerns that must be carefully considered. These include issues of
privacy, as the devices interface directly with the brain and could potentially
be used to access or manipulate neural information. There are also concerns
about autonomy, particularly regarding the extent to which individuals can
control or are influenced by the prosthetic systems. Informed consent and the
right to opt-out are crucial ethical considerations, ensuring that users fully
understand the implications of using such devices. Additionally, there is a need
to establish clear regulatory frameworks to prevent misuse and ensure that the
technology is developed and applied responsibly.

The societal impact of visual cortical prostheses extends beyond individual
users to broader social and economic contexts. Ensuring accessibility to these
advanced devices is paramount, particularly for individuals from diverse
socio-economic backgrounds. Strategies to reduce costs and improve the
availability of these devices in various healthcare settings are essential.
Furthermore, public awareness campaigns and educational initiatives can help
integrate individuals with visual impairments into society more effectively,
reducing stigma and promoting inclusivity. Policymakers and stakeholders must
work together to address potential disparities in access and ensure that the
benefits of these technological advancements are equitably distributed.

\section*{Conclusion}\label{sec:conclusion}
In conclusion, significant technological advancements in visual cortical
prostheses, particularly in AI integration, are revolutionizing the field. The
use of advanced AI algorithms, such as CNNs, RNNs, and GANs, has greatly
enhanced visual data processing and optimized phosphene patterns, resulting in
more natural and coherent visual experiences for users. These innovations,
coupled with high-density electrode arrays enabled by nanotechnology and 3D
printing, ensure precise neural stimulation and improved quality of visual
information. Furthermore, the implementation of closed-loop feedback systems and
multi-modal sensory integration allows for dynamic adjustment and a more
holistic sensory experience, closely mimicking natural vision.

Despite the challenges associated with the invasive nature of cortical
prostheses, ongoing advancements promise to mitigate these issues, making the
devices safer and more accessible. Future research should prioritize broader
clinical trials to assess long-term efficacy and personalized prosthetic
solutions tailored to individual neural architectures. By addressing these
areas, we move closer to providing effective vision restoration for individuals
with severe visual impairments, ultimately enhancing their quality of life and
societal integration. The future of visual cortical prostheses, driven by AI
integration, holds immense promise for transformative changes in the treatment
of blindness and severe visual impairments.

\printbibliography%
\onecolumn
\newpage
\section*{Rebuttal}\label{sec:rebuttal}
\noindent \textbf{Reviewer:} Prof.\ dr.\ R.J.A.\ van\ Wezel

\subsection*{General Comments}
\begin{itemize}
      \item Remove key articles that are not central to the discussion.\\
            \textcolor{blue}{\textit{Response: I kept the key articles as bullet
                        points, as I believe this emphasizes the importance of the research and
                        makes it more clear for the reader to identify the main contributions.}}

      \item Clearly articulate the research question and objectives in the text.\\
            \textcolor{blue}{\textit{Response: Removed the bullet points for these
                        sections and wrote them as paragraphs as it was more coherent.}}

      \item Use ``visual prosthetic devices'' instead of ``prosthetic devices'' for comparison.\\
            \textcolor{blue}{\textit{Response: Adapted the text to be more clear about
                        what type of devices were to be compared.}}

      \item Narrow down the discussion of technological advances to focus specifically on how phosphenes are formed and explain how AI improves phosphene resolution.\\
            \textcolor{blue}{\textit{Response: Adapted text in limitations and
                        challenges to go more in-depth on the formation of phosphenes and how AI
                        can be leveraged to improve simulated phosphene vision (SPV).}}
\end{itemize}

\subsection*{Main Focus}
\begin{itemize}
      \item Identify and describe the technological advances that best contribute to improved AI usage, focusing on those with the most significant impact, especially in conjunction with high-density electrode arrays, emphasizing how increased density leads to more phosphenes.\\
            \textcolor{blue}{\textit{Response: Again, this was moved to latter
                        sections as I thought this would be a more natural follow-up to the
                        technological advances and AI integration.}}

      \item Address clinical and ethical considerations of using AI for
            prosthetic vision, including decisions on what is important and issues of
            privacy.\\
            \textcolor{blue}{\textit{Response: This was unaddressed in the draft, but
                        has now been included for the final version.}}

      \item Ensure the structure includes a stronger connection to AI and emphasize the AI-related table.\\
            \textcolor{blue}{\textit{Response: I have added more emphasis on how and
                        why Deep Learning Algorithms can be leveraged to improve the outlook of
                        the development of visual prosthetic devices especially for field
                        of view, spatial- and temporal resolution improvements.}}
\end{itemize}

\end{document}
