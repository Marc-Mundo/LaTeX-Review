\documentclass[twocolumn,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{abstract}
\usepackage{titlesec}
\usepackage[backend=biber,style=apa]{biblatex}% Changed style to apa
\usepackage[hidelinks]{hyperref}
\PassOptionsToPackage{hyphens}{url} % Pass hyphens option to url package via hyperref
\usepackage{fancyhdr} % For custom headers and footers
\usepackage{lastpage} % For page numbering in the footer
\usepackage{xcolor} % For text color
\usepackage{tabularx} % Tabularx package for better table formatting
\usepackage{longtable}% Long table package for tables that span multiple pages

% Set marginparwidth for todonotes
\setlength{\marginparwidth}{2cm} % Adjust the marginparwidth
\usepackage{todonotes} % TODOs
\usepackage{tcolorbox} % For colored boxes
\usepackage{caption} % For custom captions

% Fonts and typography
\usepackage{helvet} % Load the Helvetica font package
\renewcommand{\familydefault}{\sfdefault} % Set sans-serif as the default font family

% Page setup
\geometry{margin=1in}
\setstretch{1.2}
\titleformat{\section}{\bfseries\Large}{\thesection}{1em}{}
\titleformat{\subsection}{\bfseries\large}{\thesubsection}{1em}{}
\titleformat{\subsubsection}{\bfseries\normalsize}{\thesubsubsection}{1em}{}

% Add bibliography file
\addbibresource{references.bib}

% Customization to remove url date and format URLs and DOIs
\AtEveryBibitem{%
  \ifentrytype{online}{%
    \clearfield{urldate}%
    \clearfield{note}%
  }{}%
  \ifentrytype{article}{%
    \clearfield{urldate}%
  }{}%
}

\renewbibmacro*{doi+eprint+url}{%
  \printfield{doi}%
  \newunit\newblock%
  \iffieldundef{doi}{%
    \usebibmacro{eprint}%
    \newunit\newblock%
    \usebibmacro{url+urldate}}%
    {}%
}

% Customize the caption format
\captionsetup[figure]{
    labelfont=bf,           % Bold font for the label
    labelsep=space           % Use a space as the separator
}
\captionsetup[table]{
    labelfont=bf,           % Bold font for the label
    labelsep=space           % Use a space as the separator
}

% Change font size of bibliography entries
\renewcommand{\bibfont}{\fontsize{7pt}{9pt}\selectfont}% Set font size to 7pt, maybe too small. Change to 8pt if needed. Also adjust actual text size?

% Title
\title{State-of-the-Art in Visual Cortical Prostheses: Technological Advances and Future Directions}
\author{
  Marc J. Posthuma\\
  Student Number: 4413105\\
  \texttt{marc.posthuma@ru.nl}\\
  \\
  Radboud University\\
  Supervisor: Prof.\ dr.\ R.J.A.\ van\ Wezel\\
  Department of Neurobiology, Donders Centre for Neuroscience
}
\date{\today}

% Adjust page geometry to balance header and footer
\geometry{
  a4paper,
  left=20mm,
  right=20mm,
  top=30mm,
  bottom=30mm,
  headheight=60.50554pt, % Set the head height
  headsep=10pt, % Space between header and text
  footskip=30pt % Space between text and footer
}

% Custom footrule commands
\newcommand{\blackfootrule}{%
  \color{black}\makebox[\headwidth]{\rule[0.5ex]{\headwidth}{0.3pt}}%
}

\newcommand{\grayfootrule}{%
  \color{gray}\makebox[\headwidth]{\rule[0.5ex]{\headwidth}{0.3pt}}%
}

% Define fancyhdr styles
\fancypagestyle{firstpage}{
  \fancyhf{}
  \fancyhead[L]{\includegraphics[width=5cm, keepaspectratio]{imgs/RU_logo_NL_cropped.png}}
  \fancyhead[R]{\fontsize{10}{12}\selectfont \textbf{Systematic Review in Neuroscience} \\ NWI-BM059}
  \fancyfoot[L]{\fontsize{8}{10}\selectfont \textcolor{gray}{Radboud University}}
  \fancyfoot[C]{\fontsize{8}{10}\selectfont \textcolor{gray}{\thepage\ of~\pageref{LastPage}}}
  \fancyfoot[R]{\fontsize{8}{10}\selectfont \textcolor{gray}{June 2024}}
  \renewcommand{\footrulewidth}{0.3pt}
  \renewcommand{\footrule}{\blackfootrule}
}

\fancypagestyle{rest}{
  \fancyhf{}
  \fancyhead[L]{\fontsize{8}{10}\selectfont \textcolor{gray}{Systematic Review}}
  \fancyhead[R]{\fontsize{8}{10}\selectfont \textcolor{gray}{State-of-the-Art in Visual Cortical Prostheses}}
  \fancyfoot[L]{\fontsize{8}{10}\selectfont \textcolor{gray}{Radboud University}}
  \fancyfoot[C]{\fontsize{8}{10}\selectfont \textcolor{gray}{\thepage\ of~\pageref{LastPage}}}
  \fancyfoot[R]{\fontsize{8}{10}\selectfont \textcolor{gray}{June 2024}}
  \renewcommand{\footrulewidth}{0.3pt}
  \renewcommand{\footrule}{\grayfootrule}
}

% Document
\begin{document}

\pagestyle{plain}% Default plain page style for the list of TODOs
\listoftodos% Remove this line before submission
\clearpage%To make sure the todo list is on a separate page without fancyhdr

\newpage% To make sure the todo list is on a separate page without fancyhdr

% Title and abstract
\twocolumn[
      \maketitle
      \thispagestyle{firstpage} % Apply first page style after title
      \begin{onecolabstract}
            \noindent Visual cortical prostheses represent a revolutionary
            technology within the field of neuro\-prosthetics, aimed at
            restoring vision for individuals with visual impairments through
            direct neural interfaces. This review systematically explores the
            current capabilities, limitations, and future prospects of visual
            cortical prostheses, with a focus on the integration of artificial
            intelligence (AI) to enhance functionality and effectiveness. Key
            topics include the optimization of phosphene patterns, real-time
            image processing, and comparisons with other types of visual
            prosthetic devices. The goal is to provide a comprehensive overview
            of the state-of-the-art in visual cortical prostheses and propose
            future research directions.
      \end{onecolabstract}
      \textbf{Keywords:} Visual cortical prostheses, neuroprosthetics, artificial intelligence, phosphene patterns, real-time image processing
      \vspace{1cm}
]

% Ensure first page style is applied until the first page is full
\thispagestyle{firstpage}
\section*{Introduction}\label{sec:intro}
\subsection*{Background}
Globally, blindness affects millions of people, with estimates rising from over
30 million in 2013 to 43.3 million in
2020~\parencite{stevensGlobalPrevalenceVision2013,
      bourneTrendsPrevalenceBlindness2021}. For certain types of blindness, visual
prosthetics present a promising avenue for restoring rudimentary vision through
electrical stimulation of the visual system. The concept of using bioelectrical
interfaces dates back to the 18th century, with pioneering experiments by LeRoy
in 1755 and Volta in 1800 demonstrating that electrical stimulation of the eye
can induce visual sensations.

The field of neuroprosthetics has witnessed remarkable progress, particularly
with the advent of visual cortical prostheses. These advanced devices offer hope
for restoring vision in individuals with severe visual impairments by
interfacing directly with the brain's visual cortex
(Figure~\ref{fig:schematic}). Visual cortical prostheses work by converting
visual information from the external environment into neural signals that the
brain can process, effectively bypassing damaged visual pathways. The core
technology involves the generation of phosphenes---perceived spots of light
resulting from electrical stimulation of the visual
cortex~\parencite{vandergrintenBiologicallyPlausiblePhosphene2024a}. However,
organizing these phosphenes into coherent and interpretable visual patterns
remains a significant challenge~\parencite{merabetWhatBlindnessCan2005}.

\pagestyle{rest} % Apply rest page style from here

% Schematic figure (Bio-render)
\begin{figure*}[ht!]
      \centering
      \includegraphics[width=0.7\textwidth]{imgs/visual_cortical_prothesis.png}
      \caption{| Functional schematic representation of a visual cortical
            prosthesis. The visual environment is recorded by a wearable camera
            and sent to a (wireless) mobile computer. Electrodes within a brain
            implant are then selectively activated to stimulate neurons in the
            primary visual cortex (V1). By leveraging the retinotopic
            organization of V1, a precise pattern of phosphenes is created,
            forming a coherent representation of the visual
            scene~\parencite{chenShapePerceptionHighchannelcount2020}. (Image:
            BioRender,
            \href{https://app.biorender.com/}{https://app.biorender.com/},
            accessed on 27 May 2024).}\label{fig:schematic}
\end{figure*}

AI has emerged as a pivotal element in enhancing these prosthetic systems. By
leveraging sophisticated algorithms, AI can optimize stimulation patterns to
create more naturalistic visual experiences for
users~\parencite{kriegeskorteDeepNeuralNetworks2015}. AI's role extends to real-time
image processing, allowing the prosthesis to adapt to varying visual
environments and tasks~\parencite{marblestoneIntegrationDeepLearning2016}. This
capability is crucial for developing prosthetic systems that closely mimic
natural vision, providing users with more effective and adaptable solutions. The
integration of AI not only improves the functionality of these devices but also
opens new avenues for innovation in how visual information is processed and
perceived~\parencite{gallettiCorticalConnectionsArea2001}.

This review aims to provide a comprehensive analysis of visual cortical
prostheses, focusing on the role of AI in advancing these prosthetics. By
examining current capabilities, identifying limitations, and proposing future
research directions, this work seeks to contribute to the ongoing development of
more effective and user-friendly visual prosthetic systems. Combining
technological innovation with neuroscientific insights has the profound
potential to enhance the quality of life for individuals with visual
impairments.

\subsection*{Research Question}
This review addresses the following questions:
\begin{itemize}
      \item What are the current technological advancements in visual cortical
            prostheses, particularly in electrode design, signal processing, and
            integration?
      \item How is AI leveraged to enhance visual prostheses, particularly in
            optimizing phosphene patterns and real-time image
            processing?
      \item How do visual cortical prostheses compare with other types of
            prosthetic devices?
      \item What are the functional differences between AI-enhanced prosthetic
            vision and natural visual processing within the human brain?
\end{itemize}

\subsection*{Key Articles}\label{sec:key_articles}
To ground this review, several key articles have been selected that highlight
the current state and advancements in visual cortical prostheses:
\begin{itemize}
      \item Van der Grinten et al. (2024) discuss the simulation of phosphene
            patterns for optimizing visual
            experiences~\parencite{vandergrintenBiologicallyPlausiblePhosphene2024a}.
      \item Farnum \& Pelled (2020) review the advancements in microelectronic
            devices and the integration of AI for enhanced visual
            prostheses~\parencite{farnumNewVisionVisual2020}.
      \item Grani et al. (2022) explore closed-loop stimulation strategies for
            real-time adjustments in visual
            prostheses~\parencite{graniPersonalizedClosedloopStimulation2022}.
\end{itemize}

\subsection*{Objectives}\label{sec:objectives}
The primary objectives of this review are:
\begin{itemize}
      \item To synthesize recent technological advancements in visual cortical
            prostheses.
      \item To evaluate the integration and impact of AI in enhancing these
            prosthetic systems.
      \item To compare visual cortical prostheses with other prosthetic devices
            and natural vision.
      \item To identify current limitations and propose future research
            directions.
\end{itemize}

\section*{Technological Advances}\label{sec:tech_advances}
Recent years have seen significant progress in the development of visual
cortical prostheses, driven by advancements in both hardware and software
systems. These innovations are pivotal in enhancing the functionality,
efficiency, and user experience of these devices.

\subsection*{Advancements in Biomaterials and Electrode Design}
One major area of advancement is in electrode design and fabrication.
Traditional electrodes have been limited by issues such as biocompatibility,
stability, and the ability to generate precise neural stimulation. Recent
studies have introduced novel materials and fabrication techniques that
significantly improve these aspects.

\subsubsection*{Conductive Polymers}
The development of flexible and biocompatible electrodes allows for better
integration with neural tissue, reducing the risk of damage and increasing the
longevity of the implants. These polymers are especially useful for flexible 3D
microneedle electrode arrays and are able to support mesh substrate layers that
can support the curvature of various brain
tissue~\parencite{xiangFlexibleThreedimensionalElectrode2016}. Conductive
polymers have been instrumental in advancing the design and functionality of
these electrodes.

One notable conductive polymer is PEDOT:PSS (poly (3,4-ethylenedioxythiophene)
polystyrene sulfonate), which has been widely used due to its excellent
electrical conductivity, flexibility, and biocompatibility. PEDOT:PSS coatings
on electrodes improve signal transduction and reduce impedance, which enhances
the quality of neural recordings and
stimulation~\parencite{rivnayHighperformanceTransistorsBioelectronics2015}.
Additionally, PEDOT exhibits remarkable stability in physiological environments,
ensuring long-term functionality of neural interfaces. Its ability to form thin,
conformal coatings on complex surfaces allows for seamless integration with
neural tissue, minimizing tissue damage and inflammatory
responses~\parencite{zhangRecentProgressPEDOTbased2022}.

Another significant advancement is the use of polyaniline (PANI), a conductive
polymer known for its tunable conductivity. PANI can be
chemically modified to optimize its electrical properties, making it suitable
for long-term neural interfacing applications. Its use in electrode design has
shown promising results in maintaining stable performance over extended periods
using a silicone matrix~\parencite{almuflehHighlyFlexiblePolyanilineBased2021}.
While PANI electrodes are cheaper to fabricate than PEDOT:PSS, their
biocompatibility and rigidity while implanted are still areas of investigation.
However, this polymer shows promise for future applications using graphene
composites~\parencite{liuBiocompatibleHighPerformanceWetAdhesive2021,fangBiocompatibleElectrodeExoelectrogens2024}.

Polypyrrole (PPy) is another conductive polymer that has been extensively
studied for neural applications. PPy-based electrodes offer a unique combination
of electrical conductivity and mechanical properties that facilitate close
contact with neural tissue. Additionally, PPy can be doped with various
bioactive molecules, such as neurotrophic factors (NGF/BDNF/GDNF) or Heparin to
promote tissue integration and reduce inflammatory
responses~\parencite{zareElectroconductiveMultifunctionalPolypyrrole2021a}.

\subsubsection*{Nanotechnology}
Advances in microfabrication have enabled the creation of high-density electrode
arrays that can stimulate the visual cortex with greater precision, offering the
potential for more detailed and coherent visual
experiences, whilst minimizing adverse effects such as inflammation which causes
glial scarring and encapsulation of electrodes~\parencite{ryuSpatiallyConfinedResponses2020}.

Nanotechnology has introduced several innovative approaches to enhance the
performance and integration of electrodes in visual cortical prostheses. One
such approach is the use of carbon nanotubes (CNTs), which possess exceptional
electrical conductivity and mechanical strength. CNTs can be incorporated into
3D scaffold electrode designs to improve signal transmission and reduce
impedance, thereby enhancing the quality of neural
stimulation~\parencite{alegretThreeDimensionalConductiveScaffolds2018}.
Additionally, these nanotubes can be interfaced with conductive polymers like
PPY to create conjugated polymers that combine the benefits of both to reduce
gliosis, improve adaptability and increase charge-transfer
efficiency~\parencite{sharCarbonNanotubeNanocomposite2023}.

Another promising implementation is the use of graphene, a fairly new
two-dimensional material known for its outstanding electrical and thermal
properties. Graphene-based electrodes, due to their thinness, are incredibly
flexible and highly conductive with a huge surface are. These characteristics
are crucial for long-term implantation and stable neural interfaces.
Furthermore, graphene has proven biocompatibility in multiple biological
scaffolding
applications~\parencite{liThreedimensionalGrapheneFoam2013,sahniBiocompatibilityPristineGraphene2013}.
Thus, graphene could be a unique material that bridges modern requirements of
electronics, biology and
optics~\parencite{luGraphenebasedNeurotechnologiesAdvanced2018}.

Lastly, gold nanostructures have been utilized to enhance electrode performance.
Gold nanostructures refer to nanoscale particles or architectures made of gold,
typically with dimensions ranging from 1 to 100 nanometers. These structures can
take various forms, such as spheres, rods, shells, cages, wires and stars. Gold
nanoparticles and nanowires can be used to modify the surface of electrodes,
increasing their surface area and improving their electrical properties. This
modification can lead to more efficient charge transfer and lower stimulation
thresholds~\parencite{zareGoldNanostructuresSynthesis2022}. The ability to
control the size, shape and surface chemistry can allow for a variety of
different physicochemical properties that are necessary for specific
applications. In combination with graphene, gold nanostructures can be utilized
to provide biosensor functionality in addition to neural stimulation, allowing
for the possibility of also recording neural
activity~\parencite{raufGoldNanostructuredLaserscribed2021}.

These nanotechnology-based advancements are paving the way for the development
of more sophisticated and effective visual cortical prostheses, providing users
with improved visual experiences and greater functionality.

\subsubsection*{3D Printing}
Recent advancements in 3D printing has allowed for unparalleled precision and
customization capabilities, allowing for the creation of complex and highly
detailed electrode arrays that can be tailored to the unique anatomical features
of individual patients~\parencite{guoImplantableLiquidMetalbased2017}.

This technology enables the production of electrodes that conform to the
specific geometry of the cortical surface, improving contact and integration
with neural tissue, thereby enhancing the accuracy of neural stimulation and
minimizing potential damage to surrounding
tissues~\parencite{liuSoftElasticHydrogelbased2019}. Advances in 3D printing
materials, including biocompatible and conductive inks, have improved the
performance and longevity of printed electrodes, providing the necessary
electrical properties while maintaining compatibility with neural tissue.

Additionally, the ability to rapidly prototype and produce electrodes using 3D
printing reduces manufacturing time and cost, facilitating quicker iterations
and refinements in electrode design, which accelerates the development
process~\parencite{zhangClimbinginspiredTwiningElectrodes2019}.

\subsection*{Improved Signal Processing and Integration}
Advances in signal processing and integration enhance the performance and
functionality of software that orchestrate the formation of phosphene patterns
in higher resolutions. This is supported by High-resolution imaging techniques
and sophisticated signal processing algorithms that have significantly improved
the precision and reliability of these devices.

\subsubsection*{High-Resolution Imaging}
High-resolution imaging techniques provide detailed maps of the brain's cortical
structures. These techniques allow for more precise placement and targeting of
electrodes, which is essential for effective neural stimulation and helps
prevent unnecessary damage to surrounding tissue.

Functional Magnetic Resonance Imaging (fMRI) is one such high-resolution imaging
technique that provides high-resolution images of
brain activity by detecting changes associated with blood flow. This imaging
technique is valuable for mapping functional areas of the brain, ensuring that
electrodes are placed in regions that will yield the most beneficial outcomes
for the user~\parencite{landelleInvestigatingHumanSpinal2021}.

Two-photon microscopy allows for deep imaging of living brain tissue with high
spatial resolution. This technique is particularly useful for observing the
interactions between electrodes and neural tissue over time, providing insights
that can guide the design and optimization of electrode
arrays~\parencite{yangIntegratedMicroprismMicroelectrode2024}.

Furthermore, the development of NIR-II semiconducting polymers has enhanced in
vivo high-resolution imaging capabilities. These polymers offer excellent
penetration depth and spatial resolution using near-infrared window imaging,
which are critical for accurate diagnostics and possible therapeutic
applications in neural
prosthetics~\parencite{wangRecentProgressSecond2023,kangNIRIISemiconductingPolymers2023}.

Deep learning techniques have also been employed to enhance the resolution of
confocal fluorescence microscopy. By using generative models, these techniques
improve the learning ability of imaging systems in the frequency domain,
resulting in significantly higher resolution images that are essential for
detailed neural mapping~\parencite{huangEnhancingImageResolution2023}. Some of
the types of deep learning models are elaborated in the next section on how AI
is integrated into visual prostheses.

These high-resolution imaging techniques are integral to the development of more
precise and effective visual cortical prostheses, facilitating better
integration and performance of these devices. In the future these techniques may
allow for real-time monitoring of neural activity through the use of
fluorescence with significant penetration depth into the brain. Thus, these
could allowing more downstream stimulation while tracking the effects of the
implant.

\subsubsection*{Wireless Communication}
Additionally, innovations in wireless technology have enabled the development of
untethered wearable prostheses. Wireless systems eliminate the need for external
wires, which not only improves the comfort and aesthetics of the prostheses but
also reduces the risk of infections and mechanical
failures~\parencite{bruntonOptimisingElectrodeSurface2013}. Advancements in
wireless power transfer and data communication have made it possible to deliver
sufficient power and high-fidelity signals to the implants, ensuring reliable
and efficient operation.

Modern wireless devices, such as the \textit{Gennaris} array described
by~\textcite{rosenfeldTissueResponseChronically2020}, incorporate all necessary
electronics within the implant. This system includes a wireless receiver and an
Application Specific Integrated Circuit (ASIC) encased in a ceramic capsule,
allowing for independent control and power for multiple arrays implanted into
the visual cortex. This design simplifies surgical procedures and reduces trauma
to major cortical blood vessels~\parencite{polikovResponseBrainTissue2005}.

Recent advancements include the development of biphasic quasistatic brain
communication (BP-QBC), a technique that significantly reduces power consumption
while maintaining high data transfer rates. This method leverages
electro-quasistatic signaling to create a low-power, broadband communication
channel between wireless neural implants and external devices, offering a
promising solution for energy-efficient and high-speed data transmission in
neural prosthetics~\parencite{chatterjeeBiphasicQuasistaticBrain2023}.

These advancements in wireless communication technology are crucial in order to
provide a more seamless and reliable neural interface.

\subsection*{Software and Algorithmic Enhancements}
On the software side, the integration of artificial intelligence (AI) has
revolutionized the way visual information is processed and interpreted by
prosthetic systems. AI algorithms, particularly those based on deep learning,
have been employed to optimize stimulation patterns and enhance image processing
capabilities. These algorithms can learn from vast amounts of data to improve
the accuracy and efficiency of visual signal conversion, making the visual
experiences more naturalistic and adaptable to different
environments~\parencite{romeniMachineLearningFramework2021}.

\subsubsection*{Real-Time Data Processing}
Real-time data processing is pivotal for the functionality of a complex
prosthesis that has to generate accurate representations of an environment,
especially while a user is moving. Translation of visual information from the
external environment into neural signals has to be seamless so that they can be
interpreted by the brain's visual cortex.

A key aspect of real-time data processing involves the integration of high-speed
computing systems capable of handling large volumes of visual data with minimal
latency~\parencite{nurmikkoChallengesLargeScaleCortical2020}. The processing
pipeline typically includes capturing visual information via cameras,
preprocessing the data to reduce noise and enhance relevant features, and
converting this data into neural stimulation patterns based on the resolution of
the phosphene pattern.

Edge computing plays a crucial role in this pipeline by performing data
processing closer to the data source. This reduces latency and enhances the
responsiveness of the prosthetic system, which is particularly important for
real-time applications such as navigation in dynamic
environments~\parencite{wangDeepLearningEdge2020}. By offloading computational
tasks from centralized servers to local devices, edge computing ensures that
visual data is processed swiftly, enabling immediate feedback to the user.

Another important component is the use of adaptive algorithms in the form of
deep learning models that can dynamically adjust to changes in the visual
environment. These algorithms leverage feedback from the user's interactions
with the prosthetic system to continuously improve accuracy and
effectiveness~\parencite{pio-lopezVisualCorticalProsthesis2021b}. For example,
real-time adjustments can be made to the stimulation patterns based on
environmental factors such as lighting conditions and the presence of moving
objects, ensuring that the visual output remains consistent and
coherent~\parencite{fylstraHumanprosthesisCooperationCombining2022}.

Additionally, advancements in sensor technology have significantly contributed
to real-time data processing capabilities. High-resolution cameras and depth
sensors provide detailed visual information, which is essential for generating
precise and informative neural signals. These sensors can capture a wide range
of visual cues, including color, depth, and motion, which are then processed to
create a comprehensive visual experience for the
user~\parencite{rueckauerExperiencingProstheticVision2022}.

Real-time data processing also benefits from the constantly improving development of specialized
hardware accelerators, such as Graphics Processing Units (GPUs) and Field
Programmable Gate Arrays
(FPGAs)~\parencite{springerOnDeviceDeepLearning2021,fengDesignOnlineBrainComputer2020}.
These devices are optimized for parallel processing tasks and can handle the
intensive computational demands of real-time visual data processing. By
utilizing these hardware accelerators, visual cortical prostheses can achieve
the necessary processing speeds to provide immediate and accurate visual
feedback.

In summary, real-time data processing in visual cortical prostheses involves a
combination of high-speed computing, edge computing, adaptive algorithms,
advanced sensors, and specialized hardware accelerators. These systems work
together to ensure that visual information is processed and transmitted to the
brain without noticeable delays, creating a natural and effective visual
experience for users. This seamless integration of hardware and software
components is crucial for the ongoing development and enhancement of visual
prosthetic systems.

% Add the summary box at the end of the Technological Advances section
\begin{figure*}[ht!]
      \begin{tcolorbox}[
                  title=Technological Advances in Visual Cortical Prostheses,
                  colframe=gray!30, % Border color
                  colback=gray!20, % Background color
                  coltitle=white, % Title color
                  colbacktitle=gray!50, % Title background color
                  fonttitle=\bfseries,
                  sharp corners=all,
                  width=\textwidth,
                  boxrule=1.5pt % Border width
            ]
            \fontsize{8pt}{10pt}\selectfont % Set the font size directly
            \begin{itemize}
                  \item \textbf{Advancements in Biomaterials and Electrode Design}
                        \begin{itemize}
                              \item \textbf{Conductive Polymers:} PEDOT:PSS, Polyaniline (PANI), Polypyrrole (PPy)
                              \item \textbf{Nanotechnology:} Carbon Nanotubes (CNTs), Graphene, Gold Nanostructures
                              \item \textbf{3D Printing:} Customizable and high-precision electrode arrays
                        \end{itemize}

                  \item \textbf{Improved Signal Processing and Integration}
                        \begin{itemize}
                              \item \textbf{High-Resolution Imaging:} Functional Magnetic Resonance Imaging (fMRI), Two-photon microscopy, NIR-II semiconducting polymers
                              \item \textbf{Wireless Communication:} Biphasic Quasistatic Brain Communication (BP-QBC)
                        \end{itemize}

                  \item \textbf{Software and Algorithmic Enhancements}
                        \begin{itemize}
                              \item \textbf{Real-Time Data Processing:} Edge computing, adaptive algorithms, advanced sensors, hardware accelerators (GPUs and FPGAs)
                        \end{itemize}

                  \item \textbf{Other Functional Improvements}
                        \begin{itemize}
                              \item \textbf{Closed-Loop Feedback Systems:} Dynamic adjustment of stimulation parameters
                              \item \textbf{Multi-Modal Sensory Integration:} Incorporation of auditory and tactile feedback
                        \end{itemize}
            \end{itemize}
      \end{tcolorbox}
      % \caption{Summary of key technological advancements in the development of
      %       visual cortical prostheses, highlighting improvements in biomaterials,
      %       signal processing, software, and functional
      %       integration.}\label{fig:advances_vcp}
\end{figure*}

\subsection*{Other Functional Improvements}
\subsubsection*{Closed-Loop Feedback Systems}
Another significant advancement is the implementation of closed-loop systems in
visual cortical prostheses. These systems continuously monitor neural feedback
to adjust stimulation parameters in real-time, thereby enhancing the precision
and effectiveness of visual restoration. Closed-loop systems mimic the natural
feedback mechanisms of the human visual system, providing a more responsive and
user-friendly experience. Recent research has demonstrated the efficacy of these
systems in improving the visual outcomes for users, as they can dynamically
adapt to changes in the environment and the user's neural
responses~\parencite{leviEditorialClosedLoopSystems2018}.

\subsubsection*{Multi-Modal Sensory Integration}
The integration of multi-modal sensory input is another promising development in
this field. By incorporating inputs from other senses, such as auditory or
tactile feedback, visual cortical prostheses can provide a more holistic sensory
experience. This multi-modal approach leverages the brain's ability to integrate
information from different sensory modalities, potentially enhancing the overall
perceptual experience and aiding in the interpretation of visual
scenes~\parencite{wanArtificialSensoryNeuron2020}.

\section*{AI Integration}\label{sec:ai_integration}
The integration of AI in visual prosthesis systems is focused on how deep
learning algorithms enhance visual data processing, optimize phosphene patterns,
and emulate normal brain processing. Figure~\ref{fig:simulator_framework}
provides an overview of a Visual Prosthesis Simulation Framework based on the
work by~\textcite{deruytervansteveninckEndtoendOptimizationProsthetic2022}. This
framework employs AI to simulate and predict how users perceive visual
information through a prosthetic device. By integrating deep learning
algorithms, the system can accurately replicate and enhance visual experiences.

The functional process of a visual cortical prosthesis in this framework is an
end-to-end process that includes three main components: an encoder, a phosphene
simulator, and a decoder. The encoder processes the input image to generate a
stimulation protocol, which determines the intensity of stimulation for each
electrode. The phosphene simulator translates this protocol into a simulated
phosphene vision (SPV) representation, incorporating factors like distortions in
phosphene positions and brightness variations. Finally, the decoder reconstructs
the input image from the SPV representation, ensuring accurate interpretation of
the encoded information.

Optimization is a critical aspect, involving automated and tailored adjustments
to achieve the best visual reconstruction. Task-specific optimization is
implemented by using different loss functions, guiding the network to preserve
relevant information. Constraints such as sparsity can be incorporated to
minimize adverse effects of electrical stimulation. The modular design allows
the system to adapt to practical, medical, or biophysical limitations. Some
designs, such as the one
by~\textcite{deruytervansteveninckEndtoendOptimizationProsthetic2022}, have been
made open-source to facilitate collaboration and further development.

% Diagram figure (inkscape)
\begin{figure*}[ht!]
      \centering
      \includegraphics[width=0.6\textwidth]{imgs/block_diagram_vis_prost.png}
      \caption{| Overview of a Visual Prosthesis Simulation Framework. The
            simulator is initialized with electrode locations on a visuotopic
            map of the visual cortex (V1), representing the spatial organization
            of the visual field. For each frame, it processes stimulation
            parameters such as amplitude, pulse width, and frequency for each
            electrode. Using these parameters and electrode locations, it
            estimates phosphene characteristics, which are rendered on a visual
            field map considering cortical magnification and activation
            thresholds. Individual phosphene renderings are summed to produce
            the simulated prosthetic percept. Temporal dynamics, including
            delayed onset and offset of perception, are modeled using a leaky
            integrator. The simulator's modular and open-source design,
            implemented in Python with PyTorch for example, allows for fast GPU
            computations and easy integration with external
            software~\parencite{deruytervansteveninckEndtoendOptimizationProsthetic2022}.
            It is validated through computational and behavioral experiments,
            incorporating neurophysiological and clinical findings to ensure
            biological plausibility.}\label{fig:simulator_framework}
\end{figure*}

\subsection*{Deep Learning Algorithms in Prosthetic Vision}
An innovative approach is the use of feed-forward neural networks to improve the
control of brain-machine interfaces. This simpler neural network architecture
enhances the speed and accuracy of prosthetic control by more closely mimicking
the natural communication pathways between the brain and the body. Such improves
the functionality of prosthetic devices and enhance their usability for
individuals with paralysis or limb
loss~\parencite{willseyRealtimeBrainmachineInterface2022}. However, these
``simpler'' networks are not suitable for more complex image generation tasks
and require on-the-fly learning capability. This is where more sophisticated so
called deep learning models come into play, a model that learns to perform
classification or regression tasks directly from (image) data.

So why are AI algorithms essential for the development of prosthetic vision?
These algorithmic models are in principle, designed as solutions to low sampling
resolution. The optimization of phosphene patterns are an area that benefits
significantly from preprocessing optimizations of image quality. An example of a
spiking neural network is the NeoCube architecture for obstacle-avoidance
by~\textcite{guoOptimizationVisualInformation2018}. This architecture is a prime
example of how an AI system can enhance the user experience by adding increased
stability and accuracy to the prosthetic system, without the addition of
additional hardware.

Deep learning models are different kinds of neural networks that are used to
predict and interpret visual inputs without providing environmental context.
This is known as saliency mapping, which is an important technique used in deep
learning to identify and visualize the regions of an input that most
significantly influence the model's predictions. Within the deep learning domain
there are however several types of neural networks that are used to enhance the
capabilities of models in different ways.

Various types of neural networks exist, including Convolutional Neural Networks
(CNNs) for image recognition, Recurrent Neural Networks (RNNs) for temporal data
processing, Generative Adversarial Networks (GANs) for generating realistic
visual patterns, and Graph Neural Networks (GNNs) for understanding complex
spatial relationships, that collectively enhance capabilities in image
translation, object recognition, and scene interpretation. These key deep
learning algorithms are crucial in predictive modeling, with each contributing
uniquely to improving the functionality and performance of visual cortical
prostheses.

\todo[inline]{Check if the citations are in the right spots.}

\subsubsection*{Predictive Modeling}
Predictive modeling plays a crucial role in prosthetic vision by leveraging
various deep learning algorithms to enhance visual perception for users. These
models are designed to predict and interpret visual inputs, creating a seamless
and coherent visual experience. By utilizing large datasets and advanced neural
network architectures, predictive modeling enables the prosthetic system to
anticipate and adapt to dynamic visual environments. Aforementioned key deep
learning algorithms are employed in predictive modeling, these include CNNs,
RNNs, GANs, and Multidimensional GNNs. While not all of these model types have
been explicitly used in visual prosthetics yet, they have significant potential
to enhance the capabilities of these systems.

\todo[inline]{Check the table contents}

\begin{table*}[ht!]
      \centering
      \fontsize{8pt}{10pt}\selectfont
      \caption{| Comparison of Different Deep Learning Algorithms in Prosthetic Vision Systems}\label{tab:dl_algorithms_prosthetic_vision}
      \begin{tabularx}{\textwidth}{|X|X|X|X|X|}
            \hline
            \textbf{Algorithm}                                                                                                                                                                           & \textbf{Input} & \textbf{Processing} & \textbf{Output} & \textbf{Benefits} \\ \hline

            \textbf{Convolutional Neural Networks (CNNs)}                                                                                                                                                &
            Receives raw sensory data from the external world, possibly through a camera or other sensors.                                                                                               &
            Extracts relevant features (edges, textures, shapes) and identifies objects in the scene.                                                                                                    &
            Generates a pattern of phosphenes that correspond to recognized objects, translating into a simplified image with phosphene ``dots'' representing different objects or regions of the scene. &
            Excels at recognizing objects and spatial relationships. Provides
            basic visual information like identifying objects, their locations,
            and general scene understanding.\
            \\ \hline

            \textbf{Recurrent Neural Networks (RNNs)}                                                                                                                                                    &
            Receives continuous streams of data from the CNN, representing the changing visual scene.                                                                                                    &
            Maintains temporal continuity and tracks moving objects.                                                                                                                                     &
            Modifies the phosphenes to reflect the movement of objects, allowing the user to perceive dynamic aspects of the world.                                                                      &
            Allows for smooth tracking of movement and prediction of future
            events. Crucial for perceiving the world as a dynamic environment
            rather than a static snapshot.\
            \\ \hline

            \textbf{Generative Adversarial Networks (GANs)}                                                                                                                                              &
            Trained on large datasets of real-world images.                                                                                                                                              &
            Learns to generate realistic and diverse phosphenes resembling actual visual patterns.                                                                                                       &
            Produces highly realistic phosphenes for displaying processed visual information.                                                                                                            &
            Enhances perception by creating natural and vivid visual
            experiences. Generates realistic phosphenes resembling natural light
            patterns, making prosthetic vision less ``artificial''.\
            \\ \hline

            \textbf{Multidimensional Graph Neural Networks (GNNs)}                                                                                                                                       &
            Receives spatial information from the CNN, representing relationships between objects in the scene.                                                                                          &
            Analyzes spatial relationships, understanding context of visual input.                                                                                                                       &
            Modifies phosphenes to represent objects and their spatial arrangement and potential interactions.                                                                                           &
            Enhances spatial awareness and navigation. Understands complex
            relationships between objects.\
            \\ \hline

            \multicolumn{5}{|p{\dimexpr\textwidth-2\tabcolsep}|}{
            \textbf{How These Algorithms Work Together:}\newline
            \textbf{CNN:} Acts as the core object recognition system, identifying objects and basic scene features.\newline
            \textbf{RNN:} Adds temporal information, allowing the user to perceive movement and changes in the scene.\newline
            \textbf{GAN:} Ensures that the output phosphenes are realistic and visually appealing.\newline
            \textbf{GNN:} Adds a deeper level of understanding by representing spatial relationships between objects.
            }                                                                                                                                                                                                                                                                         \\ \hline
      \end{tabularx}
\end{table*}

\subsubsection*{Convolutional Neural Networks (CNNs)}
CNNs are employed to process and classify visual inputs, enhancing the ability
of the prosthetic system to interpret complex visual scenes and improve object
recognition capabilities. CNNs are particularly effective at identifying spatial
hierarchies in images through layers of convolutions that capture features like
edges, textures, and shapes. By training on large datasets, CNNs learn to
recognize a wide range of objects and scenes, enabling the prosthetic system to
provide users with detailed and accurate visual
information~\parencite{petrosyanDecodingInterpretingCortical2021a}. This
improves the user's ability to navigate and interact with their environment by
providing clearer and more recognizable visual
cues~\parencite{maheswaranathanInterpretingRetinalNeural2023}. An example of
such a system was used in one of the key articles by
\textcite{deruytervansteveninckRealworldIndoorMobility2022}, where they used
SharpNet predictions to create a surface boundary mask. SharpNet is a CNN-based
model that allows for estimation of depth and surface normals, which is
essential for the formation of meaningful phosphene vision patterns.

\subsubsection*{Recurrent Neural Networks (RNNs)}
RNNs, including LSTM (Long Short-Term Memory) networks, are used to handle
sequential data, making it possible to maintain temporal continuity in visual
perception and improve the user's ability to track moving objects. Unlike CNNs,
which focus on spatial relationships, RNNs excel at processing temporal
sequences. They retain information over time, allowing them to predict future
frames based on past visual data. This capability is essential for maintaining a
continuous and stable visual experience, especially when tracking dynamic scenes
or moving objects, thereby enhancing the user's perception of motion and
improving their ability to react to changes in their
environment~\parencite{nayebiRecurrentConnectionsPrimate2022,
      liaoBridgingGapsResidual2016}. RRNs in the form of LSTMs have been explored for
the use of special conditions such as low-light environments, by enhancing the
visual inputs and provide greater image
clarity~\parencite{renLowLightImageEnhancement2019}. In addition, these same
specific networks show excellent performance in gesture recognition~\parencite{nguyen-trongGestureRecognitionUsing2021}, which is an
important aspect of human interaction which can be facilitated via a prosthetic.

\subsubsection*{Generative Adversarial Networks (GANs)}
GANs can be utilized to generate realistic phosphene patterns by training on
large datasets of visual scenes, improving the fidelity and natural appearance
of the visual output. A GAN consists of two neural networks, a generator and a
discriminator, which are trained together in a competitive process. The
generator creates synthetic images that the discriminator attempts to
distinguish from real images~\parencite{ledigPhotoRealisticSingleImage2017}.
Through this adversarial training, GANs learn to produce high-quality, realistic
images that can be used to simulate phosphenes—patterns of light perceived by
the visual
cortex~\parencite{goodfellowGenerativeAdversarialNetworks2020,elnabawyPVGANGenerativeAdversarial2022}.
This enhances the naturalness and coherence of the visual scenes presented to
the user, making the prosthetic vision more similar to natural sight.

\subsubsection*{Multidimensional Graph Neural Networks (GNNs)}
GNNs are leveraged to model and interpret complex relationships within
multidimensional data, enhancing the system's ability to understand and process
spatial and relational information. GNNs extend traditional neural networks by
operating on graph-structured data, which can represent the spatial
relationships between objects in a scene. This allows the prosthetic system to
better understand the context and interactions within the visual input. By
capturing these intricate relationships, GNNs improve the prosthetic's ability
to recognize patterns, structures, and spatial hierarchies, leading to more
accurate and context-aware visual perception. This is particularly useful in
complex environments where understanding the spatial arrangement of objects is
crucial for navigation and
interaction~\parencite{subramanianGraphConvolutionalNetworks2020,wuComprehensiveSurveyGraph2021}.

Moreover, multidimensional GNNs have been employed to optimize wireless
communication policies in neural prosthetics. These networks use graph-based
representations to manage complex data transmission scenarios, improving the
efficiency and reliability of wireless communication between implants and
external devices~\parencite{liuMultidimensionalGraphNeural2024}.

\section*{Comparison with Other Visual Prosthetic Systems}\label{sec:comparison}
Cortical prosthetics present a distinct and innovative method for restoring
vision, setting them apart from earlier retinal and optic nerve implants.
Devices such as the PRIMA and IRIS systems by Pixium-Vision, as well as the
FDA-approved Orion and ARGUS II by Second Sight Medical Products Inc, have
demonstrated their effectiveness. The PRIMA and IRIS systems focus on subretinal
and epiretinal placements, respectively, to stimulate remaining retinal cells,
making them suitable for specific retinal degenerative
conditions~\parencites{muqitProstheticVisualAcuity2023,hoLongTermResultsEpiretinal2015}.

In contrast, the Intracortical Visual Prosthesis (ICVP) and the Utah Electrode Array exemplify advancements in cortical prostheses. The ICVP uses microelectrode arrays implanted in the visual cortex to provide visual information to blind individuals, offering fine-grained control over neural activation~\parencite{troykIntracorticalVisualProsthesis2005}. The Utah Electrode Array employs high-density microelectrodes to evoke visual perceptions by stimulating the visual cortex directly, allowing for the creation of more complex visual patterns~\parencite{normannClinicalApplicationsPenetrating2016}.

These cortical prostheses are uniquely advantageous due to their ability to bypass both retinal and optic nerve impairments and stimulate the visual cortex directly. This downstream positioning is particularly beneficial for individuals with severe visual impairment where other prostheses are ineffective. Additionally, cortical implants offer the longest therapeutic intervention window, leveraging compensatory plasticity mechanisms that recruit neurons from other cortical regions. This enables effective stimulation and rehabilitation long after the onset of injury or disease, significantly enhancing their rehabilitative potential~\parencite{tzekovGabelEdArtificial2020, beyelerLearningSeeAgain2017}.

\begin{table*}[ht!]
      \centering
      \fontsize{8pt}{10pt}\selectfont
      \caption{| Comparison of Cortical, Retinal, and Optic Nerve Prostheses}\label{tab:prostheses_comparison}
      \begin{tabularx}{\textwidth}{X X X X}
            \hline
            \textbf{Feature}                             & \textbf{Cortical Prostheses}                                                        & \textbf{Retinal Prostheses}                                                    & \textbf{Optic Nerve Prostheses}                                 \\ \hline
            \textbf{Target Area}                         & Visual cortex                                                                       & Retina                                                                         & Optic nerve                                                     \\ \hline
            \textbf{Surgical \newline Invasiveness}      & Highly invasive (brain surgery)                                                     & Moderately invasive (eye surgery)                                              & Moderately invasive (requires access to the optic nerve)        \\ \hline
            \textbf{Applicability}                       & Suitable for severe visual impairment with retinal or optic nerve damage            & Best for retinal degenerative diseases with some functional retinal cells      & Suitable for optic nerve damage with functional retinal cells   \\ \hline
            \textbf{Mechanism}                           & Direct stimulation of the visual cortex                                             & Stimulation of remaining functional retinal cells                              & Stimulation of the optic nerve fibers                           \\ \hline
            \textbf{Therapeutic \newline Window}         & Longest, can be effective long after onset of blindness                             & Requires some residual retinal function                                        & Depends on the extent of optic nerve damage                     \\ \hline
            \textbf{Technological \newline Complexity}   & High (phosphene organization and neural plasticity)                                 & Moderate (retinal cell stimulation)                                            & High (complexity in targeting optic nerve fibers)               \\ \hline
            \textbf{Advantages}                          & Broad applicability, effective for extensive damage, leverages cortical plasticity  & Less invasive, established success in specific diseases, direct visual pathway & Can target optic nerve damage directly, bypasses retinal issues \\ \hline
            \textbf{Disadvantages}                       & Highly invasive
            surgery, complex visual pattern organization &
            Limited to retinal functionality, less effective with severe damage
                                                         & Invasive, technical challenges in precise nerve stimulation                                                                                                                                                                            \\
            \hline
            \textbf{Example Devices}                     & Orion (Second Sight), ICVP (Illinois Institute of Technology), Utah Electrode Array & Argus II (Second Sight), Alpha IMS (Retina Implant AG), PRIMA (Pixium-Vision)  & Epi-Ret3, Experimental Optic Nerve Stimulation Systems          \\ \hline
      \end{tabularx}
\end{table*}

\subsection*{Comparison with Retinal Prostheses}
Retinal prostheses, such as the Argus II and the Alpha IMS, focus on stimulating the remaining functional cells within the retina to restore vision. These devices provide visual perception to individuals with retinal degenerative diseases, such as retinitis pigmentosa. The Argus II, for example, employs an epiretinal approach, placing electrodes on the surface of the retina to evoke visual sensations. The Alpha IMS, on the other hand, uses a subretinal approach, inserting the implant beneath the retina to directly stimulate photoreceptor cells~\parencite{stinglArtificialVisionWirelessly2013}.

While retinal prostheses have demonstrated significant success in patients with some remaining retinal function, their applicability is limited for those with extensive retinal damage or complete retinal degeneration. In contrast, cortical prostheses offer a broader applicability by bypassing the damaged retinal cells and directly stimulating the visual cortex. This capability allows cortical prostheses to be effective even in cases where retinal prostheses are not viable. Furthermore, the position of cortical implants downstream in the visual pathway leverages the brain's plasticity, potentially offering a longer therapeutic window and enabling rehabilitation well beyond the onset of retinal degeneration~\parencite{tzekovGabelEdArtificial2020}.

\subsection*{Comparison with Optic Nerve Prostheses}
Optic nerve prostheses, such as the Epi-Ret3 device and other experimental optic nerve stimulation (ONS) systems, aim to stimulate the optic nerve fibers directly. These devices are particularly beneficial for patients with optic nerve damage, allowing for the bypass of retinal issues. However, the technological complexity involved in precisely targeting optic nerve fibers and the invasive nature of the implantation procedure present significant challenges. The Epi-Ret3 device, for example, has shown potential in preliminary studies but requires highly precise stimulation to be effective~\parencite{trieuImplantsEpiretinalStimulation2009}.

In comparison, cortical prostheses, such as the Orion Visual Cortical Prosthesis
and the Intracortical Visual Prosthesis (ICVP), offer distinct advantages by
bypassing both the retina and optic nerve. This direct stimulation of the visual
cortex enables broader applicability for a wide range of visual impairments,
including those resulting from severe optic nerve damage. Additionally, cortical
implants benefit from the brain's compensatory plasticity mechanisms, allowing
for effective stimulation and visual rehabilitation long after the onset of
injury or disease. This extended therapeutic window, coupled with the ability to
leverage cortical plasticity, underscores the substantial rehabilitative
potential of cortical prostheses for individuals who are blind or visually
impaired~\parencite{beyelerLearningSeeAgain2017}.

\subsection*{Comparison with Natural Vision}
The PRIMA system, as demonstrated in the study
by~\textcite{palankerSimultaneousPerceptionProsthetic2022}, represents a
significant technological advancement in visual prosthetics, providing a means
to restore central vision in patients with geographic atrophy due to age-related
macular degeneration. Unlike natural vision, which relies on the complex and
highly efficient biological processes of the retina and visual cortex, the PRIMA
system uses a subretinal implant to convert images projected from video glasses
into electrical signals that stimulate the remaining inner retinal neurons. This
artificial method of vision restoration, while impressive, results in visual
acuity levels that are still substantially lower than those achieved through
natural vision. For example, the best prosthetic acuity achieved in the study
was 20/460, compared to the near-perfect acuity of 20/20 in natural vision.

Natural vision benefits from the intricate network of photoreceptors, bipolar
cells, and ganglion cells within the retina, which work in concert to process
visual information with high spatial and temporal resolution. The PRIMA system,
on the other hand, must rely on the brain's plasticity and the ability to adapt
to and interpret the new, less refined visual signals in the form of phosphenes
generated by the implant. While the study showed that patients could achieve
functional vision with the PRIMA system, including the ability to recognize
letters and basic shapes, this prosthetic vision is limited by the current
technology's pixel density and the spatial resolution it can provide.
Nonetheless, systems like PRIMA offer a crucial alternative for individuals who
have lost their natural vision.

\section*{Limitations and Challenges}\label{sec:limitations}
\subsection*{Quality of Prosthetic Vision}
Cortical prosthesis systems, while showing great promise for several types of
blind
individuals~\parencite{deruytervansteveninckRealworldIndoorMobility2022,deruytervansteveninckEndtoendOptimizationProsthetic2022,kucukogluOptimizationNeuroprostheticVision2022},
artificial vision is far from fully functional. The limits of artificial vision
are both due to technological and biological constraints.

\todo[inline]{update these parts}

\subsubsection*{Field of vision}
For real-world applicable prosthetic, a wide field of view is essential.
Otherwise the user will have trouble to map and interact with the environment.

\subsection*{Impact of Electrode Count on Visual Resolution}
The number of electrodes in a visual prosthesis is a critical factor in determining the resolution and quality of the perceived image. More electrodes can potentially provide a higher resolution, as each electrode can stimulate a different area of the visual cortex or retina, producing a more detailed phosphene map. However, increasing the number of electrodes also introduces significant challenges, such as maintaining precise control over each electrode, ensuring stable long-term performance, and avoiding crosstalk between electrodes. For instance, while the Utah Electrode Array uses high-density microelectrodes to evoke more complex visual patterns, it faces issues related to the precise organization and interpretation of these patterns by the brain.

\subsection*{Biocompatibility Issues}
Biocompatibility remains a major challenge in the development and deployment of visual cortical prostheses. The introduction of foreign materials into the brain or eye can trigger immune responses that may lead to inflammation, scar tissue formation, and eventual device failure. Materials such as PEDOT and graphene have shown promise due to their electrical properties and compatibility with neural tissues, but long-term biocompatibility and stability are still under investigation. Additionally, flexible and biocompatible electrodes, while reducing the risk of damage, still need to address issues related to integration with the neural tissue and maintaining performance over time.

\subsection*{Surgical and Technological Complexities}
The implantation of visual prostheses, particularly those involving the visual cortex, requires highly invasive surgical procedures that pose significant risks, including infection, bleeding, and damage to neural tissues. The complexity of these surgeries can limit the widespread adoption of such systems and make them accessible only in specialized medical centers.

Technologically, creating a seamless interface between the prosthesis and the neural tissue is challenging. The variability in individual neural architecture means that prosthetic solutions must often be highly customized, which can increase costs and complicate the development process.

\subsection*{Limitations in Current AI and Processing Technologies}
While AI and advanced processing have greatly enhanced the potential of visual prostheses, they are not without limitations. Real-time data processing requires significant computational power, and delays in processing can lead to a disjointed visual experience. Moreover, the algorithms used to optimize phosphene patterns and visual interpretations need continuous improvement to better mimic natural vision and adapt to various visual environments.

\section*{Future Perspectives}\label{sec:future}
Provides a comprehensive overview of the current state and future potential of
visual cortical prostheses, highlighting technological capabilities, AI
integration, and challenges.

\todo[inline]{Maybe omit the next two subsections?}

\subsection*{Clinical Applications}
A caveat is the invasive nature of these cortical devices, which require
surgical implantation.

\begin{itemize}
      \item Broader and more diverse clinical trials to assess long-term efficacy
            and safety.
      \item Exploration of personalized prosthetic solutions tailored to
            individual neural architectures.
\end{itemize}

\subsection*{Ethical and Societal Implications}
\begin{itemize}
      \item Considerations of the ethical implications of advanced neural
            interfacing.
      \item Societal impact and accessibility of such technology for individuals
            with visual impairments.
\end{itemize}

\section*{Conclusion}\label{sec:conclusion}
In conclusion, the technological advancements in electrode design,
microfabrication, artificial intelligence, closed-loop systems, wireless
technology, and multi-modal sensory integration are significantly advancing the
field of visual cortical prostheses. These innovations are crucial for
developing more effective, reliable, and user-friendly devices that can better
restore vision for individuals with severe visual impairments. Continued
research and development in these areas promise to further enhance the
capabilities and accessibility of visual cortical prostheses, paving the way for
their widespread clinical application.


\printbibliography%

\end{document}
